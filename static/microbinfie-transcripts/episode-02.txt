Hello and thank you for listening to the MicroBinfeed podcast. Here we will be
discussing topics in microbial bioinformatics. We hope that we can give you some
insights, tips, and tricks along the way. There's so much information we all
know from working in the field, but nobody really writes it down, there's no
manual, and it is assumed you'll pick it up. We hope to fill in a few of these
gaps. My co-hosts are Dr. Nabeel Ali Khan of Enterobase, GrapeTree, and
BrakeFame, and Dr. Andrew Page of such works as Plasmatron 5000, Rory, and
Gubbins. I am Dr. Lee Katz and you might know me from my Tree Making Pipeline
Mastery or my SNP Pipeline Live Set. Both Nabeel and Andrew work at the Quadram
Institute in Norwich, UK, where we work on microbes in food and the impact on
human health. I work at the Centers for Disease Control and Prevention and am an
adjunct professor at the University of Georgia in the US. So in terms of
metagenomics, there's a huge amount of interest in that at the moment and a lot
of people are running algorithms. In particular, I just want to first of all say
that if you're doing 16S, like V1, V2, or V4, this kind of thing, you're
probably doing pretty poor science. There's very few use cases these days in
proper international world-leading science where 16S will actually give you
something useful. You've got to be doing long-read sequencing, metagenomic
sequencing, or something really interesting with, say, short-read metagenomics,
say, creating mags or something about metagenomic assemblies. So yeah, 16S is
dead. Please do not do any more tools for it. Although it is quite an important
little sequence. One thing to add with 16S I learned the other day. 16S has one
advantage in that you will get more OTUs on your 16S than you probably will with
your shotgun. That's because you're amplifying and you'll get better coverage of
the abundance of species there. But that's about it. Yeah, but more of what?
What's it telling you? If you get an OTU which is 90% away from anything that's
been seen before, what does that tell you? You don't know the recipe. You don't
have to grow a bug. You don't know what the bug does. You don't know what genes
it has. You don't know anything about it. It's just a bug, whereas at least if
you use shotgun, you've got a general idea of, okay, I've got something here.
It's kind of like salmonella, but it's not. But even in the whole genome shotgun
space, there's a lot of tools out there. If we're talking about taxonomic
classification, where you've just got a set of reads and we're answering this
question, what is in the sample? You've got approaches like Megan or Kraken or
Sigma or Midas or Metaflan or Motus. All of these are doing very different
methods. Some are using fixed, conserved housekeeping genes. Some are using
unique markers. Some are using whole genomes as references in their databases.
There's really not that much scope for someone else to come in and write a new
tool using shotgun metagenomics. Although they do all give you different
answers. Maybe if someone could write a tool to give you the one answer. Meta,
Metaflan. A tool that actually gave you the right answer. Yeah, that would be
great. People have done a great job with all these different tools. There's some
amazing tools out there and some amazing work out there. It would take you a lot
of work to break into this area with a brand new tool. I would say just consider
doing things like coming up with better databases to feed into these tools. Lee,
you had the Calamari. Yeah, thanks for asking about it. I had the Calamari. With
metagenomics, we have software that we shouldn't be rewriting because that field
is saturated, but it turns out that the databases can definitely use a lot of
fixing. I've been working on a project called Cracking with Calamari. It's going
to have some really good optimizations. I described it on my poster, which is on
my GitHub. I think that we can post that in the show notes too. It does let you
have a lot of unclassified reads, but at the cost of it being really specific
and you don't get a lot of false hits. There is also a problem. I think that
Adam Filippi's lab did a study a few years ago showing that if you saturate your
database, multiple assemblies per species, you actually get a problem in
cracking where each camera is just found across the board and you get hits that
are just specific for a genus instead. You start getting worse and worse
results, ironically. That's crazy. There's definitely an issue of sample bias in
your metagenomic databases you have to take care of. With the Kraken though,
they have made a lot of changes from Kraken to Kraken 2. They have added a
sanity check with Bracken, which is doing some Bayesian magic to tidy up that
report you get out of Kraken. That's my favorite at the moment though. I really
like the output from Bracken for that. It's much simpler, much more sensible
than what it used to be. On to assemblers, metagenomic assemblers. There's a lot
of them and some of them have been around for a few years, but again,
fundamentally, a lot of them are doing similar stuff. Now, in many cases, you
can get better assemblies with higher depth data and that's really all you need
to get better assemblies. There are some very clever things out there later on
for binning and this kind of thing for splitting these out. Of course, when
you've got better bins, you can do better assemblies. That is important. Of
course, ultimately, if you put in better quality DNA, it's going to be a better
result. What's really exciting for me is long read metagenomics because the long
read metagenomics is where we can make the best possible input into science
because you get things coming out in one big chromosome, or you get full
plasmids, or you can separate things out a lot better, or you can just put
together all of these teeny tiny little bits that you get from short read
sequencing into bigger pieces and you get a bigger idea of what's going on, a
better idea of what's going on. I've seen some recent papers that are quite good
where people are using, say, the methylation patterns to try and reassemble
metagenomic data, which is super cool, or then you obviously get high C, and
that seems to be doing quite well. Then you have more modern technologies like
long ads, which is using a really funky way of putting in mutations and then
doing assemblies. There's lots of good things in this space, but very few of
them involve writing new tools. It's really about changing how the data is
processed fundamentally in the lab. For AMR databases, AMR has just been,
there's such a need for a good database, and also, I feel like, paradoxically,
it's been done to death. I don't know how you guys feel, but there's just so
many databases, and maybe they need to get more synchronized. To that end, I
really appreciate what you all did at the hackathon recently. I think, if I put
a date on it, it was June 1st of this year. Is that right? Yes. Okay, and those
URLs in the show notes, you guys did a great job of compiling the different
genes from different databases and seeing if you can get something more
streamlined, something more, I guess you're streamlining the naming schemes.
Because it's all over the place at the moment. Okay, so the problem introduces
another problem. Yeah, but the problem with AMR databases is that there's so
many competing databases, and some of them are well curated, some of them are
not, and some of them have been abandoned, and they store data in a different
way. Some of them have not been actually validated in the lab, and that's a
problem. It's garbage in, garbage out in some cases where people really are just
following the herd and saying, oh, well, this makes you resistant for
quinolones. It must be right when maybe there's no evidence for that. Yeah, I
feel like, I think you touched on a good point that it really takes a consortium
or a lot of different groups of organizations to really actually get something
agreed upon. To that end, there are certain organizations out there, I know that
you might have mixed feelings about it, but consortiums like GMI, the Global
Microbial Identifier, or domestically in the U.S., we have GenFS, where USDA,
NCBI, CDC, FDA, we all came together to see if we can agree on certain things.
And even before GenFS, we had the NORMS group, which is a consortium between
FDA, USDA, and CDC, where they are trying to agree upon antimicrobial resistance
naming and software techniques to use. It's more fundamental than that, though.
can't even agree on the names of the antibiotics or the shorthand information to
use or what an MIC is. In some countries the values are different to other
countries and that can be a problem. Yeah, I agree with that. I wish that were
better solved. Yeah, and what does intermediate mean? Intermediate resistance.
Somewhere between some and a lot. Yeah, it's definitely a major problem that
hasn't been solved, even though there's a huge amount of money available
internationally for AMR. It's just one of these black holes. No one has taken
the lead, it seems, to actually solve it once and for all internationally at a
global scale because ultimately it is a global problem. But in terms of actually
synchronizing and getting some consensus on AMR definitions, there is a push. I
think it was started out by the guys who set up CARD, which is one of the bigger
databases, but I might be wrong. But this is one consortium that's just trying
to do part of what we're talking about and I think that's the best way in the
future of actually getting some consensus. Now this is a group that's involving
NCBI, Public Health Agency Canada, the guys doing RESTfinder, and quite a few
other databases, and they're trying to find some consensus over AMR definitions.
But regardless of whether that succeeds or not, there definitely doesn't need to
be another group coming up with a rival set of databases. I would strongly
recommend anybody who's interested in this space to try and actually contribute
to an existing repository or help curate an existing repository. And there's a
lot of tools as well out there, you know. You've got tools working from
assemblies like your Apricate, and then you have tools working from raw reads
like Ariba and so on. So there's like a million and one different tools, so
pretty much identical things. While some of them actually don't do as much, some
tools don't find point mutations which cause anti-threat resistance like gyrate,
and others, you know, just do a quick scan for genes. And if you've got 90% of
an antibiotic resistance gene, is that really antibiotic resistant or not? I
mean, I'd say maybe, but who's to know? Well, because most of these may not have
been tested empirically, we don't necessarily know. Yeah, so Lee, what about
yourself? You know, in a public health context, what would you say is antibiotic
resistance if you're looking at genome level? Oh my gosh. I'll just say
something generic because so many other people take care of this stuff, and I
don't want to misrepresent them, but I can say that some tools that we've used,
the Royal We, are things like AMR Finder, Star Finder, Res Finder, all the
finders, and several points or another people have also tested. I don't know if
they're currently using CARD, or there's another one called Argonaut. I don't
know. I think that's a, I think that's one that might have come and gone, but
I'm not sure. It's really tough to nail down like what the best one is. And then
also, I appreciate what NCBI is doing. They are applying their software using
NARMS annotations and applying those genotypes online so that you can see at
least a first-pass analysis, or maybe it is a really good analysis. I haven't
been able to ascertain it for myself. Cool. So Lee, what should people actually
be writing in terms of antibiotics tools? Yeah, I think this is, this was a
really good podcast on just why the field is saturated in certain places and
what to avoid rewriting software on. So I think we did a good job of describing
things like don't write your own AMR tool, your own aligner, don't write another
assembler, don't write another variant caller. Oh my gosh, what else did we talk
about? Metagenomics tool. But I would say that we did go over some things that
we should be doing, which is take the existing tools and seeing how you can
modify it. I think that Nabil had a great point on if you have a good variant
finder, you should tweak it to what you need. Or I thought that Andrew had a
really good point. If you have a metagenomics analysis, you can tweak it. You
can even add your own database and make it better. Or one more point you made
also with metagenomics is new chemistry. New chemistry can reinvigorate these
algorithms. So don't write a new algorithm, do tweak it to what's happening
right now. Well I'd say the exception is we should rewrite everything for long
reads. So if you really want to do something, do it for long reads or for fully
complete assembled genomes. Yes, absolutely. Very good point. And as a computer
scientist, I think porting everything over to GPUs or FPGAs is great. So we've
been in business for years, you know. Because you fundamentally need to change
how you think and you have to write things from scratch in a very different way.
You can't just take a dodgy browse script, you know, and drop it in. It's not
going to work. Yeah, that's a completely different way of programming and that's
definitely a new exciting way of answering problems. Some problems may
fundamentally not really be portable, but that's something we need to explore. I
don't think that's clearly defined. In terms of long reads, I think long reads,
when you're working with short reads, your key issue is you cannot necessarily
get out insertion sites for mobile genetic elements or even recover the
incomplete phage, prophage in a genome. And long reads are suddenly going to
allow us access to the mobile genome. And that's something that's suffered in
the field. And that's going to tell us a lot about, because that being a key
driver of virulence, that's going to tell us a lot. A lot of questions we've had
for a long time. And I think getting behind that is definitely the kind of tools
people should write. And also using things like epigenetic modifications, you
know, there's so much information there that we can apply in ways that we
haven't even thought of yet. And I think that's going to be really exciting in
the years to come. Yeah, we've got a lot of epigenetics that we can borrow from
in the eukaryote space and the human space that hasn't necessarily filtered at
the microbial space. And that's actually now something we can start thinking
about. But one of the other things that's definitely going to happen is
everyone's data sets are going to get very big. It's no longer 50 genomes, 100
or 10 or 20, we're talking thousands upon 10s of thousands of genomes. And we
sort of touched on the question of whole genome alignment. And I don't think
there's much scope for whole genome alignment tool anymore, except that it would
have to be a whole population alignment tool, where you're taking an entire
species and saying what is actually conserved, and how does it vary? And how
does it be arranged or insert across an entire species? And then visualizing
that. Well, you need graphs for that then, you know, and that's hard for
computer science. Yay. And everything was solved in the 70s. So we're fine.
There are definitely some people working in the space using all of the graph
stuff. It's, it's not as trivial as you'd think, because our, because biology is
messy. But yeah, I think that's definitely the way forward with that. So maybe
another answer to your question is what should be on what should people write is
good visualizations. Graphics are very important. True, yeah. But you have to
make sure it hasn't been done before, because I don't want to see yet another
website that's going to kind of come and go. And that's it, you know, to have
something really cool. But then it disappears because it's unmaintained, and
people haven't given you the source code. That's a book bear mind where you get
papers published, they link to web services, but they don't give you the code to
run it. And so when that little PhD or postdoc project ends, that's it, it's
gone. That's right. No, I'd like to see visualization that are incorporating
these large data sets and thinking more of mixed populations or metagenomes or
populations. I don't think you can just scale back to Artemis comparison tool
and just keep making bigger and better versions of that. I think we have to
fundamentally change the way we think about our data and the way we look at our
data. I guess we have a lot to learn from people like Florence Zernigale, you
know, she's able to take huge amounts of data and then display it in a way that
anyone could understand. And we need fundamentally new figures and ways of
thinking of data and displaying data. So that can come across to people who
aren't mathematical geniuses, you know, what exactly is going on here. So are we
thinking artificial intelligence? That's the buzzword? It's a buzzword, but I
think most people who use the word don't actually understand what it actually
means. Machine learning, I think, is a better way of thinking about it. And I
think, yeah, you know, we can get a lot out of this. But ultimately, you need
good quality data going in. Otherwise, we'll just get garbage out. You can find
a signal in any piece of data. But whether it's a real signal is another
question. So ultimately, we're saying, don't write better tools, just do better
science. Well,  No, actually, I think there is an exception here, right? If
there are lots of tools out there, and you run a tool which is easy to install,
and well-documented, and easy to maintain, then I think people will use that,
you know? Versus some of these tools where you have to change a line 52 in a
makefile, or where you have to go through 20 different documents to figure out,
if there is any documents, to figure out what's going on, and then install
particular dependencies that are out of date. If something is trivial to
install, true Conda, or true Docker, then I think you're onto a winner there.
♪♪♪ Thank you all so much for listening to us at home. If you like this podcast,
please subscribe and like us on iTunes or Google Play. And if you don't like the
podcast, please don't do anything. This podcast was recorded by the Microbial
Bioinformatics Group. The opinions expressed here are our own and do not
necessarily reflect the views of CDC or the Quadrant Institute. ♪♪♪
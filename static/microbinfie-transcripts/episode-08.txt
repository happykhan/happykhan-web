Hello, and thank you for listening to the MicroBinfeed podcast. Here we will be
discussing topics in microbial bioinformatics. We hope that we can give you some
insights, tips, and tricks along the way. There's so much information we all
know from working in the field, but nobody writes it down. There is no manual,
and it's assumed you'll pick it up. We hope to fill in a few of these gaps. My
co-hosts are Dr. Nabil Ali Khan and Dr. Andrew Page. I am Dr. Lee Katz. Andrew
and Nabil work in the Quadram Institute in Norwich, UK, where they work on
microbes in food and the impact on human health. I work at Centers for Disease
Control and Prevention and am an adjunct member at the University of Georgia in
the U.S. So it's the end of 2019, and we thought we'd like to pause and look
back at what we were working on, what resonated with us, and where we think the
microbial field will go in the new year. What have you all learned in 2019, and
what did you work on in 2019? Well, something I've learned over 2019 is how to
use Galaxy. I know it's a really old project, but actually getting to group
school has meant that it saved me a huge amount of work. I'm no longer bashing a
keyboard now, I can just click a mouse, you know, and since we have a lovely
Galaxy system set up here, it's made my life very, very easy. I can point and
click, and what's better is I can just share that with different researchers
around my institute here quite easily, and they can do the same thing as well,
you know, there's no need to learn how to program, that kind of thing. I think
it is a really useful skill. A little plug for FDA in the U.S. is they've really
gone full-on with Galaxy Tracker, and they're doing a great job with the Galaxy
interface and letting our state and local partners use that interface and do
some amazing work, so it's never too late. Another thing that I found really
cool was Kraken 2 that's come out through the year, and that is just
phenomenally good. I know with Kraken 1, they had a huge problem with memory
usage, and, you know, you'd need like a gazillion gigabytes of memory to make
something, but now it's just fantastic. It's faster, uses less memory, and I
think it's more accurate as well. What do you think, Nabil? Yeah, I think Kraken
2 is definitely my bioinformatics tool of the year. I think the paper just came
out very recently in Genome Research for 2019, and it has become a mainstay tool
for a range of different applications. So even your basic QC for sequencing from
cultured isolates, you're using it all the way up to looking at complex
microbial ecology questions. It definitely has improved with the classification
results. There used to be a lot of false positives, now it's a lot cleaner. And
another tool, Bracken, has been also another favorite that's related to Kraken
2. Also the paper came out in 2017, but it's had some iterative improvements
over the last couple of years, and I've been using it a lot this year. And this
is taking that improved information from Kraken 2, and where Kraken is
classifying the reads to the best matching location in the taxonomic tree, it
doesn't estimate the abundance of a specific species. And this tool, Bracken, is
actually doing that extra step. So you now get this really nice table of just
saying how much E. coli is in my sample, not taxonomically with all of the
different hits, but just which species are there and to what degree are there in
the sample. And that's really, really... Two years ago would have been really
difficult to do out of the box. That would have needed a lot of manual work. And
it's great to see that those tools in that field have moved along so quickly.
Actually, I found my favorite database now with Kraken 2 is GTDB. It's just
phenomenally good. It's better than all the other databases out there. Have you
used that, Lee? Yeah, I love it. And it is really good. Every single taxon has
either been better established or just kind of redefined as it dives into every
genome available to it. And it is extremely comprehensive. In fact, Hankenbacher
and I made a Kraken database from it, and I think it's now being used by a
variety of people. Although, it's tough to really get a headcount of how many
people are using a tool on a command line. We're using it. Yeah, we use it.
Awesome. Yeah. Yeah. So GTDB also came out, I think that's a 2018 paper when it
came out, but it was like December 2018. So it kind of counts for 2019, I think.
The paper itself, so the reference database is amazing, but also the paper that
describes it was really powerful, where they define a set of 120 ubiquitous
single copy proteins, and then they build this phylogeny of 94,000 bacterial
genomes. And about 14,000 of those were from uncultured organisms. Their new
definitions is really trying to capture life, including that which is coming
from metagenomic assembly, which I think has been used, but not to this level.
And so it's an interesting paper, and it really pushed a quantifiable consistent
classification scheme that contradicts a lot of the current definitions.
Basically, they've redefined what a species is. Basically, yeah. And it's in a
systematic way that we can just pick up and use. So it's really good, like from
front to finish, the new theory that they put out and the implementation is just
great. About the same time, I went ahead and started releasing my own database,
Calamari, and it's difficult for me to see where it is in the space of things
with GTDB, because it is so comprehensive. I think I'm being a little bit more
careful now that I see this other database out there, and I'm just trying to see
Calamari for maybe a subset of genomes that we care about more in public health,
and looking at maybe only completed genomes to really remove any contamination
in it. So it might still have a space. I'm still going to go forward with it,
but that was a big push in 2019 for me. The downside of GTDB is that it's about
tens of gigs. Oh yeah, like it takes forever to run, but it's really, really
good. It's fantastic when you just shook a metagenomic assembly, or even just
reads from a metagenome sample. But yeah, there is a case, I think, for a more
focused, targeted public health question as well. So I think things like
Calamari are definitely still relevant, even with such great resources being
developed alongside it. And just a note to say that I've been doing a lot of
long-read metagenomic assemblies and stuff like that, and GTDB has been just
indispensable for figuring out all that stuff. So that's really good for the
long-read metagenomics, you're saying? Yeah, Promethean. Oh, that's awesome. And
that's good to know for us, too. I'll actually take that back with me to the
lab. You guys came out with SoCrew. I thought that was really interesting. Yeah,
thanks a million. We're still trying to get it published somewhere. We have
shopped around a lot of journals, and the editors keep shoving it back at us
without sending it out for review. So we're a bit bitter about that, not being
able to get it out so quickly, but hopefully we'll get it into a journal
sometime soon. If you know any editors out there, please let us know. But for
those of you who don't know, SoCrew is just a way of taking in a bacterial
assembly that's fully circularized, and then working out the major structural
variance in it between the rRNA operons. You actually do see this strange, not
strange, but you do see these rearrangements of the chromosome on a large scale,
which seems to be linked with a niche adaptation. You see a lot in typhi, and we
all know typhi, it can be in a person, then it goes into water, and then
suddenly it's unculturable, then it gets back into a person, and it looks
identical. So what's happened in between? We don't know, but maybe this is one
extra step towards that. Very cool. And speaking of that, did I pronounce it
right? SoCrew, yeah, it's an Irish word. And I just think this is probably a
good time to address a problem that I've had this whole time on this podcast,
addressing your city. You mean Norwich? Norwich. Norwich. Did I say it right?
Yeah, that's right, yeah. Okay. That's been bugging me. Norwich. Yeah, you don't
pronounce it how it's spelled. And in my city, a lot of the locals say Atlanta.
Anyway, just getting that out there, I guess. Have you guys been using
containers a lot, also? Like singularity? Oh yeah, big time. Well, singularity
in Docker depends on the actual requirement we have, but I know on our cluster
here, we use singularity a lot. And we use singularity on our Galaxy system as
well. But on my own laptop, I'd always use Docker because it's just a bit
easier. And for all of our tools, we provide Docker containers as well and put
them up onto Docker Hub. We use a lot of containers now too, or we're trying to
get into it. And unfortunately, like in a professional HPC environment where
hundreds of scientists at CDC are sharing it, Docker just becomes not a great
idea. And we've been relying a lot more on singularity. And that's been going
great. Just in terms of having a space where something is installed and you have
all the dependencies resolved for you and you don't have to sit there bashing
your head why this particular thing won't compile, it probably saved me a lot of
time this year. It sort of reminds me of the first time when you start playing
around with virtual environments in Python or something like that, and you just
install it and it's the same state as what you expect it to be. And does anyone
remember trying to do that system level Python, the first time you start playing
around with it and you put all your modules and then they start conflicting and
everything breaks? Oh yeah, that's classic. Yeah. And then you switch to a
virtual environment like, oh my God, this is great. I can work on every single,
all of my different packages if none of them are touching.  each other so for me
containers provide that level of relief it's not perfect though I did run into a
couple of instances where it's sort of what the underlying hardware still has an
effect on what's happening in the container so it's not truly contained but in
majority of cases like you know most practical applications you are pretty much
getting this nice little black box that has everything specified the way that
you expect it to be and other things aren't going to influence it that's really
really powerful so what I love is when you put on to docker hub for other
researchers download you know they're going to get exactly the software you
built and it'll you know it's going to work out of the box but then you can link
it into Travis and you can run all of your tests then using that same docker
container so actually you're guaranteeing that I know the test run on this
docker that I'm giving out to people so it's great for being sure that you have
something that works just magically out of the box. And our state health
bioinformaticians who affectionately call themselves staff B, state health
bioinformaticians, they've been making a lot of really good images online and
have a really nice collection of bioinformatics tools now and they're still
adding on to it. One more amazing thing I like that you mentioned Travis they've
been starting to get into unit testing also and it just kind of assures that
everything works correctly I really like this new future of continuous
integration for us which I know it's probably the past for a lot of people but
it's really taking off for us. I think year to year you don't see a real
fundamental shift in the way people work very quickly but things take time and
things change over time but I'm seeing that same trend that very quickly like if
I think about this time last year this time the year before this was something
that people just talked about in a meeting about having oh yeah it would be
great if we had things in containers, it would be great if we could have all the
CI's set up and now it's just sort of it's quite passe to have it there. It's
just like okay yeah this is it's just part and parcel of writing in the paper
yeah it's up on GitHub and there's a Docker container. For Mastertree also
especially I created like this Perl package right and and I'm still on a high
that it was just published in the Journal of Open Source Software and the Staff
B group actually containerized it and I think someone else put it into the Conda
environment and all this stuff happened without me knowing about it but it was
all this really helpful stuff that a third party could just do to make the
package wonderful and when the reviewers for the Journal of Open Source Software
saw that they were containerized even though I didn't do it I got a pat on the
back so I it felt a little awkward but also like great job community like thank
you so much for helping this whole process out. Yeah I don't know if it counts
for this year but maybe it was at the start of this year but we did have that
for GrapeTree where someone just out of the blue put it we had it on we got it
on to PIP at least and then someone just got into Bioconda and it was just done.
Wow. Oh okay they sent this pull request oh you need to change this so that it
works better. All right this was not something we could think we could talk
about like a few years ago where someone's code was such that it could be
packaged and by a third party and being made easily available I mean a few years
ago it was like you couldn't even read people's code it was just the state of
the maturity of our programming what has definitely changed or improved greatly.
So you're saying bioinformatics is growing up? Bioinformatics is growing up I
think we've had to grow up because now the people who ask us to do work want
these reliable version controlled packages tools applications so having having
to provide that that provenance means we've had to grow up along the way. It's
true so speaking of I mean being professional and just growing up I see on your
notes also you be getting into things like SnakeMake and Flowcraft and I think
that may be that might be a huge change for 2019 too for bioinformatics. I think
workflow managers I did play around with SnakeMake in the past but I've had to
use I've had I've been dabbling a lot more with workflow managers this year and
SnakeMake and NexFlow definitely change the way you do your bioinformatics. I
wrote a workflow in NexFlow it took me like on the weekend it took me a couple
of hours and I remember that I did the same sort of procedure in my PhD like
having something that would spin up jobs and check if they're done and then run
something else then do something else and check if it failed or not and that
took me months I mean yeah I was a weaker programmer then but that took me
months to set up and now if I was a student starting it would probably take me a
weeks less days to get the same sort of workflow up and running because we have
such powerful boilerplate workflow managers that allow us to get to so much of
what we used to just spend ages trying to optimize. There is a note of caution
though for the community where we have so many workflow managers now and most of
them you know don't necessarily work fully with CWL that we may be in a position
where we've just too many that are totally incompatible and we're back to square
one. But I will give a shout out to Flowcraft as well assembler flow of
Flowcraft which is built on top of NexFlow and provides this dynamic workflow
management of genome assemblies and then downstream analysis as well that's an
excellent excellent tool that came out more or less this year as well. I know
the big thing this year has been machine learning where every single CV I've
seen in every grant application and call for funding seems to mention machine
learning somewhere which is interesting. Or blockchain. No well as last year.
Last year was blockchain. This year is machine learning everywhere in AI and for
the most part is people just repackage standard stats and whatever as machine
learning or you know they throw something into R and say it's machine learning
but actually you know there's a bit more to it than that. Do you have the same
thing in the US? In the US I would say that a lot of people are trying to get
into machine learning for sure. I've heard some talks that might have been
internal only at CDC so I won't go too much into them but people keep trying to
do more and more in them. However the stuff that I do see coming out from CDC
and partners everybody like the more successful things are still outside of
machine learning so I think it still shows promise but right now it's not
amazing awesome yet. I've read a couple of publications this year and seen a
couple of talks in the machine learning space where it looked like they knew
what they were doing and they were very targeted specific studies but they did
get a result that made sense and started making the technology look something
you know actually practical and actually accurate and that's very reassuring so
it's moved I think it's going to start moving away from the buzz wordiness. So
next year are you saying that it's gonna go either it's gonna go out of fashion
or it's going to actually live up to its promise? I think a few years before it
lives up to its promise and by then the buzz will have gone out of it but
actually there'll be real results in it. I think there's one more major topic
that we haven't touched on yet which is long reads right? Long reads are getting
better and better and I think that you mentioned earlier briefly Andrew just
that long reads are helping you with metagenomics. Is there any other avenue?
Yes so I'm finding these days that most of what I do is with long reads either
from PacBio or from Nanopore and so most of my tools recently and software and
scripts and whatever have been just focused on analyzing long read data or maybe
assemblies that you can get previously from Illumina. So it is the future I
don't see myself going backwards certainly into short reads much more. If you
look at say PacBio or Nanopore you can do realistically with the yield you can
get out of them you can do huge levels of multiplexing for bacteria isolates. So
I'd imagine in the next year or so you're going to have you know 96 bacteria on
a single flow cell or 384 on a single sequel to smart cell. So all of that means
cheaper better quality assemblies for bacteria and we can do a lot more and
quite different science you know once you start out having a full complete
picture you know think of all the things you can do. Yeah so this is something
I've seen in conferences and in the literature that a lot of people have been
digging into antimicrobial resistance finding that a lot of it is obviously
driven by mobile genetic elements and the placement of that mobile genetic
elements are recovering the entire chromosome and the entire plasmid sequence is
really important but that's and that's always been the case with with shorts
from the beginning but now people are actually able to follow up on that. I see
more and more papers actually saying yeah we found this plasmid it was
interesting and we did long read sequences and we recovered it. Before that was
you'd throw your hands up and say well we don't know. So more and more more and
more this year I've been seeing that perspective in papers I think people are
going to as the technology improves that's going to definitely become a research
focus if not already. We're very lucky now we have great tools like fly and you
can just throw in a load of long reads like huge data sets and you get like
awesome assemblies out like I put I had a metagenome assembly the other day and
I got some fully complete circularized bacteria at the other end which is just
insane without doing any special work you know you press the button and it
magically comes out  Yeah, no need for Binon. Yeah, I mean there is a bit of an
arms race with the longlead assemblers. They seem to keep one-upping themselves,
which is really good for us as consumers of these tools. So yeah, Fly came out,
made a big splash this year, and then I think other ones have sort of caught up.
I don't know who's the best at the moment. Was there Red Bean as well? Yeah. Was
it WTGDB2? Well, that's Red Bean there. Red Bean. Yeah, and then there's other.
Ra. Ra. Yeah, Ra. What's that old one? I think... Is it an old one? I don't
know. But we can check. And of course Canoo. Canoo. Canoo. And then people are
still using Unicycler as well. So a lot of different options there for the
longlead assembly, and it's good to see. That can only get better in the years
to come with so much competition there in that space. I'm trying to remember,
did you also come up with your longread mapper this year too? So last year I had
a program called Crocus and a program called Tiptoft, and those were taking in
longreads, and in real time you can work out what plasmids are there or what the
MLST is, which has been quite useful. And I know some groups have used, say,
Crocus for detecting MLST in outbreak situations and are able to get the ST
very, very rapidly, which is quite nice. Well I guess along the lines of
longreads, we have a MinION users group at CDC, and so far nobody has come up
with the unified workflow, and in part that's because the technology moves so
fast. And another reason is because we work on so many different things from
mycotics to viruses to bacteria, everything, to much more than I've even
discussed. So it's just hard to unify, but one innovation that we have come up
with is a nanopore workflow from our lab in Foodborne, and so this is available
on GitHub right now, we just call it nanopore workflow. A module for cleaning
and base calling, and a module for this, a module for that, and then there's a
separate directory with just workflows, and you pick and choose which of your
plugins to use, which of your modules to use to create a workflow. And I think
that we're pretty close to polishing it off. Curtis Kapsack in our lab is
leading that. Moving on from that, any super cool publications or tools that
either you've been using just by the by? Well, I'll say something that's a
little outdated again, but one publication that just blew my mind this last
year, even though it was published in 2018, was the one dealing with the
transfer bootstrap expectation. Do I have that title in front of me? It's called
Renewing Felsenstein's Phylogenetic Bootstrap in the Era of Big Data. And I
thought it was sort of transformative to me. So just for people who don't know
what that is, it's the transfer bootstrap expectation is this newer way to
calculate confidence values on your phylogeny. And normally a bootstrap value is
how many of your random trees agree with the main tree on every single ancestor
node, and you get a percentage. But transfer bootstrap expectation takes that
idea and turns it from a black and white, like either it's the same clade or
it's not, to how many of the descendants appear under that node. And you get a
slightly more reflective confidence value at each node. And that really struck
me. So I've been trying to use it more. I need to get more into it, to be
honest, but I really like it. One of the papers that really stuck me, I mean,
this came out, this is December 2018, was the backdating paper from Xavier
Didleau and others. And that is a new tool that allows you to do Bayesian
inference of ancestral dates on bacterial phylogenies. And that is very easy to
use, it's in our package, and I've been using it throughout the year, just
playing around with it. It's very handy. It has all of the little tools you need
to assess whether your tree has converged, whether it's correct, whether it's
supported, whether there's enough backend data to actually support the, there's
any real temporal signal in your tree and so on. And so that's been a real
pleasure for me to work with. Something that, you know, you just install it and
you can start using it and playing around with it. That's really cool. Have you
used it on anything more public healthy yet? Or are you still playing with that?
Maybe. Oh, okay. Oh, I'm looking forward to 2020 when we see what happens. So
what about looking forward for the year or years ahead? I think for all three of
us, maybe we're biased, but the obvious thing is the promise of longweeds in the
years to come. I mean, it's changed a lot in the last year, but what are the
current limitations now for longweeds as it stands? I think quality is getting
better, you know, obviously, as it always is with the, say the 10.3 flow cell
that's coming out. That should be quite good for Minion. And it's getting
cheaper and cheaper and cheaper all the time. And the yield is going up, you
know, it's all going in the right direction and it's competing massively with
Lumina now. So I think we've reached the point where you should be seriously
considering any future grants you put in, you know, focusing only on longweeds
if it is suitable for your experiments. I'm still getting into it personally,
but I mean, across CDC, it's transformative, especially with Minion. It's less
expensive. Every branch, every team wants to have one, and they're just seeing
how it can apply to their projects. I can just imagine if we had Minion, for
example, for the Haiti cholera outbreak, we could have sent some microbiologists
to Haiti and sequenced on the spot right there, and that would have been
amazing. So we're currently sending a team out to Bangladesh to do sequencing,
Minion sequencing, out in the country, setting up a lab there. Samples will be
collected locally for a couple of bacteria that we process and whatever. So it
means that it's kind of building capacity locally there. And then we can get a
copy of the data and bring it back and do some analysis and develop some
methods. But that's really, really awesome for them because they're kind of
leaping forward over technology with longweeds. Yeah, I'd love to see things
like this integrated into schools. That would be a fantastic biology class.
Well, I do know some people have gone out, like Kim George, who's gone out to
schools and was doing sequencing in a school, and that's pretty cool, isn't it?
Tell me more about that. That sounds interesting. Well, I recall she was doing,
well, it was like outreach. So instead of having an incubator, you'd warm your
stuff in your hands by rolling the tubes and basically all the little things you
can do to try and cut down the amount of lab equipment you need so you can
actually go into a school or you can go into wherever and do some sequencing.
And I suppose you've seen people like Nick Loman sequencing in an airport and in
a hotel room, whatever, and it is that easy to do with longweeds. So I can
imagine your example of cholera in Haiti, people actually being able to do rapid
diagnostics in the field. But of course, the next big push will be for culture-
free diagnostics. I think the step change for me this year in terms of the
longweed space is also the tools behind it have gotten that much better. If
you're doing a hybrid assembly, it's almost fire and forget at this stage. And
it's really easy to start interrogating your longweeds directly with different
mapping tools like Minimap2 and so on. That's also another side of the coin,
like once you've got the data, how do you process it? But that's also moving at
an incredible speed as well. And it helps to have superstars like Ryan Wick out
there as well, you know, just pumping out tools and analysis and comparison.
Yeah. Is he another robot? Is he real? That's what you get when you hire someone
who's like a professional software developer to do, you know, this kind of job.
Well, I think he's Vaporware Lee. I think he's Vaporware Lee. He's like Heng
Lee. There's these magic bioinformaticians who just do so much, they can't
possibly be real. That's what I'm saying. Exactly. So one of the things that I
was introduced to this year was WebAssembly by Will Rowe. And this is taking
compiled languages. So things like Rust or Go or C++ and compiling it down so it
will run in your web browser. So the obvious example that Will showed was he
took his tool group, which does some min hashing and has that running directly
in a browser. I've seen another one which has the SAM tools that runs in the
browser so you can do your view sort filtering right there without installing
anything, without needing, and it will run on every platform because all of the
browsers are basically acting like this self-contained environment. What I
didn't find was Blast, Blast having any sort of local alignment tool available.
But something like that would be really amazing because all of a sudden you can
do most of your boilerplate basic work, looking for a set of genes you want,
MLST typing, looking for genotyping, whatever, in your browser.  And any person
can just go to that website and do it. So here's a naive question. How is this
different than JavaScript? So JavaScript is its own language. The idea here is
that you have, with some tweaks, you have a workflow where you can take your
compile code and move it into bytecode that will run on the browser. The other
thing is that this is, I don't know whether this holds true, but the argument is
that this runs lightning fast, as fast as your compile code will run. But you
could, in principle, probably write a genome assembler in JavaScript. I know
people have tried to do all sorts of things like that in JavaScript. No, don't
do that. That's just crazy, isn't it? Okay, here's some more naive questions.
How do we find WebAssembly tools out there? Is someone compiling the
Bioinformatics WebAssembly tools somewhere? To my knowledge, I think it's quite
immature with WebAssembly for Bioinformatics at the moment. But there isn't that
much WebAssembly content out there at all to begin with. So just going through
all of it, you will find all the Bioinformatics stuff really easily. It's not a
big amount of information to process. So I'll tell you why this is really
amazing to me. I don't know much about this at all, but we have kind of a
challenge to make software and make it available to those who need it. And,
okay, I might make something like MASHtree, or you guys might make something
like SawCrew, and people can run that on the command line, but what if you're
somebody who's really good at genome sequencing and you don't really know Linux?
This makes things available to everyone, potentially. Yeah, I mean, the thing
is, though, is that you still need to have the front end regardless. I mean, you
could provide that tool by having the backend computation being run through
Node.js or running good old Perl CGI. I mean, it doesn't matter what's happening
in the backend. And you can have all of these processes being run and then just
showing that data back to the user. So in that case, as far as a user's
concerned, that you can accomplish in a lot of different ways. But the part that
makes me excited for WebAssembly is you're now scaling out your computation
problem because the person's browser, the person's own computer, is doing all of
the calculations required. So you can have the entire world running the package
at once, and you don't have to put up the overhead to do that for them, which is
the kind of problem that you run into when you have large centralized databases
that are trying to do analysis for the entire world. It's inherently scalable.
Amazing. And I guess if it's in a browser, it's also compatible with any
computer that runs a browser? Yes, so WebAssembly, I think, is now a standard
that is implemented by all major browsers now. So it should be cross-compatible
across all of the different browsers, and then by extension, all the different
operating systems. Wow. So if anyone listening is really into this, I think if
we had a bioinformatics repo for WebAssembly or if someone wrote up an
instruction manual for this, that might be very transformative, right? Yeah, I
mean, I will add the caveat. Don't get too excited. It's not as easy as just
copying a code in one thing, compiling it, and getting out the product. There is
a fair bit of work involved, tweaking it so that it runs in that particular
environment. But yes, I think this sort of technology is where it's going to go.
In terms of the community, there is Phage, which is just kicking off now. That's
the Public Health Alliance for Genomic Epidemiology, I think. We should know.
We're all committee members now, I think. Yeah, we're all in some of the working
groups. In the working groups, yeah. I mean, the idea of that is actually
following on a bit from the WebAssembly discussion where they're trying to set
up standard protocols for public health epidemiology. It's a really R-led world.
But it touches so many people. Absolutely, yeah. I mean, this is the kind of
stuff that eventually you would be interacting with if you go to a GP. So this
is, I suppose, the microbial informatics version of GA4GH, which is more the
human alliance. Yeah, I think I see Phage having a really nice niche where I
really like how it recognizes that there's a bunch of people around the world,
almost like a federation, just doing their thing, but they need to be glued
together somehow. So it's looking at some important, but not necessarily sexy
things like standardizing metadata or standardizing how platforms might
communicate with each other. But it's so incredibly important. This was a good
conversation. We talked about what we've done and looked at over the last year
and what software and what publications have caught our eye and what the future
might hold in 2020 for bioinformatics. So thanks for a good conversation. And
thanks, everyone, for listening. Thank you all so much for listening to us at
home. If you like this podcast, please subscribe and like us on iTunes, Spotify,
SoundCloud, or the platform of your choice. And if you don't like this podcast,
please don't do anything. This podcast was recorded by the Microbial
Bioinformatics Group and edited by Nick Waters. The opinions expressed here are
our own and do not necessarily reflect the views of CDC or the Quadrant
Institute.
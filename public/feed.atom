<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Happykhan.com - Nabil-Fareed Alikhan</title>
  <id>https://happykhan.com</id>
  <link rel="alternate" href="https://happykhan.com"/>
  <link rel="self" href="https://happykhan.com/feed.atom"/>
  <updated>2023-08-17T00:00:00.000Z</updated>
  <author>
    <name>Nabil-Fareed Alikhan</name>
  </author>
  <entry>
    <title>Five lazy tips for grant writing</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/five-lazy-grant-tips"/>
    <id>https://happykhan.com/posts/five-lazy-grant-tips</id>
    <published>2023-08-17T00:00:00.000Z</published>
    <updated>2023-08-17T00:00:00.000Z</updated>
    <summary type="text">I&apos;ve been meaning to write a comprehensive guide to grant writing but it&apos;s a tall ask. Here&apos;s a lazy &quot;5 tips for better grant writing&quot;.</summary>
    <content type="html">I&apos;ve been meaning to write a comprehensive guide to grant writing but it&apos;s a tall ask. Here&apos;s a lazy &quot;5 tips for better grant writing&quot;.  

## Do not bullshit 
Just don&apos;t. We can tell. Anyone who has been involved in a research project (so anyone who has 2+ years research experience) understands what makes the essence of a research project, and while they might not be able to explain what is wrong with a proposal they will know when something is amiss or incomplete. Regardless of how many exotic techniques and marvellous machines at your disposal, you must answer the fundamental question of feasibility and purpose. And we know what a feasible research project looks like. We need to know the research aim or question, how data will be collected, how it will be interpreted, and how will you know that your interpretation is not an artefact of your method. People often fail to explain the last part. Ideally, you will use multiple approaches to cross check your findings. As long as this is assured to us, as the reviewer, we do not need to fully understand the specifics around the method used. 

## Follow the brief 
The easiest way to dismiss a proposal is to determine it is out of scope. There is usually a clear specification provided by the funding body and reviewers can lean on that if needed. In a decision where two proposals are equally good, it can be difficult to argue that one is more important or more likely to succeed than the other. It is easier to prefer one that is clearly a better fit for the scope of the call.

So read the description of the call very closely. Try to read between the lines, there is usually a single ideal project they really want to see and a spectrum of other projects they will entertain. For instance, they might write in the initial blurb that they will fund projects “with a clear translational impact but will also welcome proposals focusing on fundamental science.” These mixed messages are common. If we submit a project that leans more toward fundamental science, how welcoming would they be? In this case, I would have a look at the guidance of what to include in proposals and how proposals will be assessed. It is not a good sign if the guidance has lengthy explanations of what they consider societal impact with detailed examples. This does not mean that we shouldn&apos;t submit the proposal, but the idea had better be a good one. 

## Clearly signal your intent and link different sections together
Research proposals can be complicated and difficult to follow. While reading about details of what work will be done, it&apos;s easy to lose track of the original motivation. Your proposal should include a concise, straightforward statement that captures the essence of what the project is about, serving as a quick reference point for reviewers. Opinions vary whether this should be the first lines of the proposal, or whether it should be after some background information. 

The overall aim will be broken down into objectives, which have a series of tasks that will meet those objectives. There are many ways to make it clear how these interconnect. It can be as easy as good headings/subheadings, or a diagram. One implicit trick is to have the same number of objectives as the number of tasks, and make it clear that objective 1 is served by task 1 and so on. Three is generally a good number of objectives and tasks. 

The proposed work should follow a clear trajectory. For instance, the initial two objectives could focus on characterising a mechanism in the laboratory, leading to the final objective of investigating its broader applicability in natural settings. Although, this does raise the question of risk migration - if objective 2 depends entirely on results from objective 1, what will you do if objective 1 fails? - and do not say it won&apos;t fail because you are just *that* good. The trajectory does not have to be a single line, it can diverge or run in parallel; you may establish at the beginning that there are three major facets of a particular problem and understanding each of those facets becomes an objective. Anyway, workflows and diagrams can help if the words escape you.  

## Give equal weight to different tasks 
You can tell a lot about someone&apos;s background by which tasks they emphasise in the proposal. Every task has to be fairly explained, in terms of the work and how they relate to achieving the objectives. An applicant with mainly wet-lab experience in a proposal that has a laboratory and a computational component may carefully explain the lab work, but then brush over the computational tasks. Likewise, a data analyst could agonise over the analytics without giving much information about the initial sampling. Even if I do not know the subject area very well, when I see this, I immediately know which part of the projects are weak - the lack of clarity on paper reveals the lack of clarity in the mind of the applicant. Maybe that&apos;s mean but it is tough grifting in the marketplace of ideas. 

## Why you? Why now? 
The world is full of problems to solve. Simply stating that there is a problem is not enough. Too often I read proposals where there is no problem stated but simply there is something we do not understand. Why is your problem the one we must tackle, and why right now?

Once it is clear that the problem is indeed timely and important, why are you (and your people/research environment) the ones who should do the work? Are you clearly capable? It&apos;s on you to prove it. It can be difficult to do given the limited amount of space. Some ingenuity is required. Try to make your words serve two purposes throughout, for instance, when presenting preliminary data, this does not only explain the current state of research but if you have been working in this area, it&apos;s an opportunity to highlight your expertise. People tend to write passive statements like, “It has been previously shown that phenomena A is linked to condition Y”, with a citation. The sentence could do a lot more, that is, if it&apos;s your work, then tell us! “Using the X facility here, we have shown phenomena A is linked to condition Y”. 

Be single minded about the problem at hand, even bloody minded. Everything written should be in service to the singular aim of the project. The aspects of the expertise you mention, the preliminary work, and the facilities around you should contribute to the success of this project. There should almost be a feeling of compulsion in the proposal. It should feel as if you care. It&apos;s infectious. And if you don&apos;t care, why should I? 

## My checklist
Here&apos;s my checklist of things you need to ensure before submission. If you can agree strongly with each point, you&apos;re in good shape. 

* I care about the problem and the research work outlined to address it. 
* I can state the overarching aim  as a short freestanding statement (in maybe 40 words).  
* The outcome of this project is more than &quot;adding to human knowledge&quot; by &quot;revealing something we don&apos;t know&quot;. 
* Each work package and task are fairly and equally described. 
* The overall singular aim is broken into objectives which are achieved by a series of tasks. 
* I have shown why I (and my organisation) are capable of delivering this work. 
* I have mentioned a clear contingency for the single biggest risk in the project. 
* I have not made a statement where I acknowledged a risk and then immediately dismissed it. 
* I have only mentioned the aspects of my organisation/work environment that specifically support the work described. 
* It is abundantly clear which objective(s) each task serve. Or that the task is a vital preparatory step towards the objective(s). 
* My costings are realistic and clearly justified. I have shown colleague(s) who have done similar work and they   say these numbers are reasonable.

Good hunting. 

</content>
  </entry>
  <entry>
    <title>Introduction to MLST as it applies to E. coli</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/intro-mlst-ecoli"/>
    <id>https://happykhan.com/posts/intro-mlst-ecoli</id>
    <published>2023-06-04T00:00:00.000Z</published>
    <updated>2023-06-04T00:00:00.000Z</updated>
    <summary type="text">Multi-locus sequence typing (MLST) is a molecular typing method used to characterize bacterial strains, including E. coli. It involves sequencing multiple housekeeping genes and assigning unique allele numbers to variations in these genes. By comparing the allelic profiles, known as sequence types (STs), it becomes possible to infer the genetic relatedness and population structure of E. coli isolates. MLST has been instrumental in understanding the epidemiology, transmission dynamics, and evolut</summary>
    <content type="html">
Multi-locus sequence typing (MLST) is a molecular typing method used to characterize bacterial strains, including _E. coli_. It involves sequencing multiple housekeeping genes and assigning unique allele numbers to variations in these genes. By comparing the allelic profiles, known as sequence types (STs), it becomes possible to infer the genetic relatedness and population structure of _E. coli_ isolates. MLST has been instrumental in understanding the epidemiology, transmission dynamics, and evolution of _E. coli_ strains, aiding in outbreak investigations and surveillance efforts. It provides a standardized and reproducible approach for comparing and sharing data across laboratories and has been widely adopted in _E. coli_ research. There are at least three MLST schemes for E. coli, from [Wirth et al](https://doi.org/10.1111/j.1365-2958.2006.05172.x), [Jaureguy et al](https://doi.org/10.1186/1471-2164-9-560) and [Qi et al](http://shigatox.net/ecmlst/cgi-bin/index). The designations commonly encountered like ST131 or ST95 or ST10 are defined in the [Wirth et al](https://doi.org/10.1111/j.1365-2958.2006.05172.x) scheme.

Below is a reading list of key publications to help understand MLST (in general) and how it applies to _E. coli_. A BibTex file cataloguing of all the publications below is [available here](/bibtex/ecolimlst.bib). The short summaries of each paper were generated by ChatGPT4.

## On typing methods in general

- **Typing methods based on whole genome sequencing data**

  Uelze L, Grützke J, Borowiak M, Hammerl JA, Juraschek K, Deneke C, et al. One Health Outlook. 2020;2: 3. https://doi.org/10.1186/s42522-020-0010-1

  This paper highlights the importance of whole genome sequencing (WGS) in investigating foodborne pathogens. WGS enables detailed genetic analysis, aiding in disease outbreak investigations and risk characterization models. Bioinformatics tools are essential for analyzing WGS data, but standardization of typing tools is needed for data comparison across laboratories and establishing a global surveillance system.

- **Overview of molecular typing methods for outbreak detection and epidemiological surveillance**

  Sabat AJ, Budimir A, Nashev D, Sá-Leão R, van Dijl JM, Laurent F, et al. Eurosurveillance. 2013;18. https://doi.org/10.2807/ese.18.04.20380-en

  This paper discusses the significance of typing methods for differentiating bacterial isolates within a species. It highlights the limitations of traditional methods and the benefits of molecular approaches in improving surveillance and outbreak detection. The text also explores the feasibility of using whole genome sequencing technology and reviews various typing methods for epidemiological purposes.

## On Multilocus sequence typing (MLST) and _E. coli_ MLST schemes

- **Multilocus sequence typing: A portable approach to the identification of clones within populations of pathogenic microorganisms**

  Maiden MCJ, Bygraves JA, Feil E, Morelli G, Russell JE, Urwin R, et al. Proc Natl Acad Sci USA. 1998;95: 3140–3145. https://doi.org/10.1073/pnas.95.6.3140

  This paper introduces multilocus sequence typing (MLST) as a portable and effective method for characterizing pathogenic microorganisms. The study specifically focuses on _Neisseria meningitidis_, determining allele sequences of housekeeping genes and constructing dendrograms to identify clonal groupings. The results demonstrate that MLST, utilizing a subset of six gene fragments, reliably identifies major meningococcal lineages associated with invasive disease. The paper highlights the advantage of MLST&apos;s portability and proposes its application to various bacterial species for global epidemiology through a shared database on the internet.

- **Sex and virulence in _Escherichia coli_: an evolutionary perspective**

  Wirth T, Falush D, Lan R, Colles F, Mensa P, Wieler LH, et al. Mol Microbiol. 2006;60: 1136–1151. https://doi.org/10.1111/j.1365-2958.2006.05172.x

  _This paper describes one of the MLST schemes for E. coli_. This paper also explores the evolutionary pathways of pathogenic _Escherichia coli_ (_E. coli_) by analyzing a global collection of isolates using multilocus sequence typing. It reveals that specific pathogen types have independently emerged in different lineages, with accelerated rates of evolution and frequent genomic alterations. The evolution of virulence is linked to increased rates of homologous recombination, highlighting the role of bacterial sex, and suggests episodic selection for strains capable of evading the host immune response.

- **Population structure and evolutionary dynamics of pathogenic bacteria**

  Smith JM, Feil EJ, Smith NH. Bioessays. 2000;22: 1115–1122. [https://doi.org/10.1002/1521-1878(200012)22:12&lt;1115::AID-BIES9&gt;3.0.CO;2-R](https://tinyurl.com/3mmnpt4p)

  This paper discusses the significance of recombination in bacterial populations using multilocus sequence typing (MLST). It confirms the existence of clones and high rates of recombination in several bacterial pathogens, highlighting the implications for population structure, virulence, antibiotic resistance, and genetically modified organisms.

- **Comparative analysis of core genome MLST and SNP typing within a European Salmonella serovar Enteritidis outbreak**

  Pearce ME, Alikhan N-F, Dallman TJ, Zhou Z, Grant K, Maiden MCJ. International Journal of Food Microbiology. 2018;274: 1–11. https://doi.org/10.1016/j.ijfoodmicro.2018.02.023

  This paper evaluates a core genome multilocus typing (cgMLST) scheme for Salmonella enterica isolates in a European outbreak. The scheme provides high-resolution typing, congruent with SNP-based and epidemiological analyses. It confirms the genetic diversity predating the outbreak, demonstrates scalability, and enables comparative analysis of Salmonella outbreaks across laboratories and jurisdictions.

- **PubMLST database - Multi-Locus Sequence Typing**

  https://pubmlst.org/multilocus-sequence-typing

  PubMLST database, which hosts many MLST schemes. Multilocus sequence typing (MLST) is a method for characterizing bacterial isolates based on the sequences of multiple house-keeping genes. Each isolate is assigned a unique allelic profile or sequence type (ST) based on the alleles at seven loci. MLST allows for unambiguous and direct comparison of isolates using DNA sequencing, enabling precise characterization and comparison of billions of distinct genotypes. MLST&apos;s advantages include unambiguous sequence data, easy comparison via centralized databases, and the ability to characterize isolates from clinical material even without culturing them.

- **Microbinfie podcast - Early days of MLST**

  https://soundcloud.com/microbinfie/early-days-of-mlst

  Microbinfie podcast episode. Ed Feil, a professor of bacterial evolution, and Natacha Couto, a data scientist, discuss multi-locus sequence typing (MLST) in bacterial population genetics. MLST assigns strain identities based on partial sequences and enables comparison of epidemiological databases. While MLST has limitations, it remains widely used, and the Eburst program offers improved visualization. The concept of clonality in bacterial species is explored, and the enduring legacy of MLST&apos;s nomenclature for lineages or clones is acknowledged. The discussion emphasizes the need for continued research in bacterial population genetics.

- **Phylogenetic and genomic diversity of human bacteremic _Escherichia coli_ strains**

  Jaureguy F, Landraud L, Passet V, Diancourt L, Frapy E, Guigon G, et al. BMC Genomics. 2008;9: 560. https://doi.org/10.1186/1471-2164-9-560

  _This paper describes one of the MLST schemes for E. coli_. This paper also investigates the clonal diversity of bacteremic _Escherichia coli_ strains and their association with genomic content and clinical features. The study reveals that bacteremic _E. coli_ isolates are highly diverse and distributed across different phylogenetic lineages. Certain clonal complexes are associated with urinary origin, but no specific complexes are linked to severe sepsis or unfavorable outcomes. Comparative genomic hybridization analysis identifies genomic characteristics associated with different clonal complexes.

- **EcMLST: an Online Database for Multi Locus Sequence Typing of Pathogenic _Escherichia coli_**

  http://shigatox.net/ecmlst/cgi-bin/index

  _This resource describes one of the MLST schemes for E. coli_. EcMLST is a database system for multilocus sequence typing (MLST) of pathogenic _Escherichia coli_. An online database and typing system for MultiLocus Sequence Typing of pathogenic _Escherichia coli_. It provides a portable and accurate method for characterizing _E. coli_ isolates, allowing researchers and public health laboratories to access nucleotide sequence data and allelic profiles for epidemiology and evolutionary studies.

## On _E. coli_ population structure

- **The population genetics of commensal _Escherichia coli_**

  Tenaillon O, Skurnik D, Picard B, Denamur E. Nat Rev Microbiol. 2010;8: 207–217. https://doi.org/10.1038/nrmicro2298

  This paper discusses the ecological and evolutionary factors shaping the population structure of commensal and pathogenic _Escherichia coli_. It explores the clonal nature of _E. coli_, the role of whole-genome sequencing in understanding its phylogenetic history, and the relationships between commensalism, virulence, and antibiotic resistance. The paper also highlights the potential of next-generation sequencing and metagenomics for further research.

- **A comprehensive and high-quality collection of Escherichia coli genomes and their genes**

  Horesh G, Blackwell GA, Tonkin-Hill G, Corander J, Heinz E, Thomson NR. Microbial Genomics. 2021;7. https://doi.org/10.1099/mgen.0.000499

  This paper discusses the compilation and curation of a comprehensive dataset of over 10,000 _Escherichia coli_ and _Shigella_ genomes. It highlights the need for a better understanding of the genetic diversity of _E. coli_ and its implications for studying biological differences and gene distribution within the population.

- **The EnteroBase user&apos;s guide, with case studies on _Salmonella_ transmissions, _Yersinia pestis_ phylogeny, and _Escherichia_ core genomic diversity**

  Zhou Z, Alikhan N-F, Mohamed K, Fan Y, the Agama Study Group, Achtman M. Genome Res. 2020;30: 138–152. https://doi.org/10.1101/gr.251678.119

  This paper introduces EnteroBase, a software environment that utilizes genomics data to identify population structures within bacterial genera. It showcases its capabilities through case studies involving _Salmonella_, _Yersinia_, and _Escherichia_, demonstrating its ability to analyze transmission patterns, track microevolution, and provide a global overview of genomic diversity. See Case study 3, which explores the genetic diversity and population structure of _Escherichia coli_ using core genome multilocus sequence typing (cgMLST) and single nucleotide polymorphism (SNP) analysis. It demonstrates the presence of distinct populations and clustering patterns within _E. coli_ and other _Escherichia_ species, providing valuable insights into their genetic relationships and diversity.

## On _E. coli_ phylogroups

- **Rapid and Simple Determination of the _Escherichia coli_ Phylogenetic Group**

  Clermont O, Bonacorsi S, Bingen E. Appl Environ Microbiol. 2000;66: 4555–4558. https://doi.org/10.1128/AEM.66.10.4555-4558.2000

  This paper presents a fast and simple technique for determining the phylogenetic groups of _Escherichia coli_ using triplex PCR. The method, tested on 230 strains, shows high correlation with complex and time-consuming reference methods, offering a more efficient approach for phylogenetic analysis of _E. coli_.

- **The Clermont _Escherichia coli_ phylo-typing method revisited: improvement of specificity and detection of new phylo-groups: A new _E. coli_ phylo-typing method**

  Clermont O, Christenson JK, Denamur E, Gordon DM. Environmental Microbiology Reports. 2013;5: 58–65. https://doi.org/10.1111/1758-2229.12019

  This paper describes a new PCR-based method for assigning _Escherichia coli_ isolates to one of eight phylo-groups, including the identification of isolates belonging to other cryptic clades. The method is validated and applied to human faecal isolates, revealing the prevalence of newly described phylo-groups and clades in the _E. coli_ population.

## On bioinformatics software for MLST and _E. coli_ phylotyping

- **Easy phylotyping of _Escherichia coli_ via the EzClermont web app and command-line tool**

  Waters NR, Abram F, Brennan F, Holmes A, Pritchard L. Access Microbiology. 2020;2. https://doi.org/10.1099/acmi.0.000143

  This paper introduces EzClermont, an _in silico_ tool for phylotyping _Escherichia coli_ based on the Clermont PCR method. The tool enables easy application of the phylotyping scheme to whole-genome assemblies and is evaluated against phylogenomic classifications, providing a web app and command-line tool for classification.

- **ClermonTyping: an easy-to-use and accurate _in silico_ method for _Escherichia_ genus strain phylotyping**

  Beghain J, Bridier-Nahmias A, Le Nagard H, Denamur E, Clermont O. Microbial Genomics. 2018;4. https://doi.org/10.1099/mgen.0.000192

  This paper introduces the ClermonTyping method and its web-interface, the ClermonTyper, which enables the identification of _Escherichia_ species, _E. coli_ phylogroups, and cryptic _Escherichia_ clades from whole genome sequences. The _in silico_ approach demonstrates high concordance with in vitro PCR assays, providing a valuable resource for strain characterization in epidemiological studies.

- **mlst (Torstyverse)**

  https://github.com/tseemann/mlst

  Scan contig files against traditional PubMLST typing schemes
</content>
  </entry>
  <entry>
    <title>One Health as it pertains to antimicrobial resistance as it pertains to microbial genomics</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/one-health-many-definitions"/>
    <id>https://happykhan.com/posts/one-health-many-definitions</id>
    <published>2023-03-13T00:00:00.000Z</published>
    <updated>2023-03-13T00:00:00.000Z</updated>
    <summary type="text">After reading too many publications and proposals I do not understand the relationship between one health, and antimicrobial resistance and microbial genomics. I write this as an exercise for myself, hoping to clarify these concepts and their interdependence. This may be of interest to you too.</summary>
    <content type="html">
After reading too many publications and proposals I do not understand the relationship between one health, and antimicrobial resistance and microbial genomics. I write this as an exercise for myself, hoping to clarify these concepts and their interdependence. This may be of interest to you too.

# What is One Health?

&gt; One Health is an integrated, unifying approach that aims to sustainably balance and optimize the health of people, animals, and ecosystems. It recognizes the health of humans, domestic and wild animals, plants, and the wider environment (including ecosystems) are closely linked and interdependent. From [https://doi.org/10.1371/journal.ppat.1010537](https://doi.org/10.1371/journal.ppat.1010537)

&quot;One Health&quot; is based on a few observations. Firstly, human health, from the perspective of population scale public health, is influenced by plants, other animals and the wider environment [1]. Secondly, many potential problems in public health, such as some emerging pathogens, are caused by anthropogenic forces [1]. There is a close interdependence between humans and nature, and to understand this to the extent where we can make meaningful public health inventions we need to encourage interdisciplinary collaboration [2]. There are many definitions of One Health, but this focus on interdisciplinary collaboration is always mentioned. Initiatives that subscribed to One Health seem to focus on developing platforms and networks to foster interdisciplinary collaboration and interoperability (e.g. improvement of data sharing) [3,4]. One Health activities do not seem to extend to directly commenting on science (i.e. specifically researching the important mechanisms in natural sciences) [5]. Many topics fall under the One Health banner, as the scope is quite broad, however, in all cases these topics are couched as they apply to human/public health. For instance, understanding zoonoses, which are diseases of animals that can infect humans, requires veterinarians, physicians, and public health officials to understand and combat such disease [6]. Yet, some issues may have a wider scope, such as changes in climate or land use that then provides new opportunities for disease [1].

I stress, again, that descriptions of One Health do not strictly specify particular issues, but there are some topics that are naturally in this space [1, 2], such as:

- Contamination of water and the impact on human health.
- Urbanisation, land use and the effect on the ecological systems, which then in turn changes opportunities for disease.
- The ease of global travel and how that affects disease transmission.
- Farming and food production practices and how it promotes (or demotes) food-borne pathogens.
- Changing climate and the effect on vector-borne diseases
- Human use of antimicrobials and how that impacts antimicrobial resistance in microbes.
- Some sources (e.g. [7]) extend One Health to food security as well. This may be true, but I argue that with such a loose definition One Health basically encompasses all the life sciences.

# What is antimicrobial resistance?

Antimicrobial resistance is the capacity of microbes to tolerate antimicrobials. Microbes can use a number of different mechanisms. The WHO specifically specifies antimicrobial resistance occurs “..when bacteria, viruses, fungi and parasites change over time and no longer respond to medicines ...” [8].This definition is framed in regards to medicines and drugs (made by humans). This is a point of confusion, as microbes also develop resistance to antimicrobials produced by other (non-human) organisms. As an obvious example, Penicillins were originally obtained from _Penicillium_ moulds (_P. chrysogenum_ and _P. rubens_). We have also “borrowed” a number of antibiotics from _Streptomyces_ [9]. Indeed, antimicrobials have been around for a very long time [10] and antimicrobial resistance in turn is ancient [11]. Research into antibiotic resistance is broad and may include:

- Understanding the mechanics of bacteria and how they resistant antimicrobials in their environments.
- The development of new antimicrobials to target resistant microbes.
- Understanding the relationship between microbes and humans - how anthropogenic forces around antimicrobial use shapes adaptation in microbes.

Based on the definition of One Health above, it is only the last topic where studies in antimicrobial resistance intersect with One Health.

# Tying it together with microbial genomics

Microbial genomics is the study of the molecular organisation of microbial genomes, their information content, and the gene products they encode. This is a broad topic and not constrained to human pathogens, antimicrobial resistance or One Health. It is important to keep these distinctions clear. I feel in a rush to be relevant (for grant funding) we conflate our projects with vogue ideas like One Health. This limits the scope of our research – and external parties may observe our movements and make hasty decisions. For instance, they may conclude that non-pathogenic antimicrobial sensitive bacteria are not important. Understanding antimicrobial resistance in of itself, and understanding microbes and their systems (such as plasmids) are both important as understanding the fundamentals of life. It is only through first understanding can we then manipulate to our advantage.

For example (and my apologies to my comrades in plasmid biology for picking on them), a project using long read sequencing to understand the fundamental mechanics of plasmids and how they mobilise is only tangential to antimicrobial resistance, as plasmids are sometimes a vector for antimicrobial resistance genes. And such a project is certainly not related to One Health as the mechanisms at play are likely much older than modern humans. If we accept the narrow focus presented to us, future projects will be deemed out of scope. Ironically, this contradicts the spirit of One Health in the first place – which is encouraging a holistic interdisciplinary view of the world. The trap with a One Health approach is that it is ultimately anthropocentric, which I have expressed as &quot;the One Health Bechdel test&quot;:

&gt; A research project does not take a One Health approach if the phenomenon under investigation would still exist if humans did not.

# References

- [1] Centres for Disease Control and Prevention (2022) &quot;[One Health Basics](https://www.cdc.gov/onehealth/basics/index.html)&quot; [Online]
- [2] One Health High-Level Expert Panel (2022) &quot;[One Health: A new definition for a sustainable and healthy future](https://doi.org/10.1371/journal.ppat.1010537)&quot;. PLoS Pathog 18(6): e1010537.
- [3] One Health Commission, &quot;[Value - Why Support the One Health Commission?](https://www.onehealthcommission.org/en/sponsorship/why_support_the_commission/)&quot; [Online]
- [4] One Health Initiative, (2020) &quot;[History of the One Health Initiative team and website](https://onehealthinitiative.com/history-of-the-one-health-initiative-team-and-website/)&quot; [Online]
- [5] World Health Organisation, (2022) &quot;[One Health High-Level Expert Panel: Meetings and thematic groups](https://www.who.int/groups/one-health-high-level-expert-panel/meetings-and-working-groups)&quot; (Online)
- [6] Kahn (2006) &quot;[Confronting Zoonoses, Linking Human and Veterinary Medicine](https://doi.org/10.3201/eid1204.050956)&quot;. Emerging Infectious Diseases, 12(4), 556-561.
- [7] Garcia et al. (2020) &quot;[One Health for Food Safety, Food Security, and Sustainable Food Production](https://doi.org/10.3389/fsufs.2020.00001)&quot;. Front. Sustain. Food Syst., Sec. Agro-Food Safety 4
- [8] WHO (2021) &quot;[Antimicrobial resistance](https://www.who.int/en/news-room/fact-sheets/detail/antimicrobial-resistance)&quot; [Online]
- [9] de Lima Procopio (2012) &quot;[Antibiotics produced by Streptomyces](https://doi.org/10.1016/j.bjid.2012.08.014)&quot;. The Brazilian Journal of Infectious Diseases 16(5)
- [10] Hall &amp; Barlow (2004) &quot;[Evolution of the serine β-lactamases: past, present and future](https://doi.org/10.1016/j.drup.2004.02.003)&quot;. Drug Resistance Updates 7(2)
- [11] D&apos;Costa et al. (2011) &quot;[Antibiotic resistance is ancient](https://doi.org/10.1038/nature10388)&quot;. Nature 477
</content>
  </entry>
  <entry>
    <title>Comparing Midjourney versions 3 and 4 for science themed images</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/mj3-vs-mj4"/>
    <id>https://happykhan.com/posts/mj3-vs-mj4</id>
    <published>2022-11-13T00:00:00.000Z</published>
    <updated>2022-11-13T00:00:00.000Z</updated>
    <summary type="text">Midjourney is a proprietary artificial intelligence program that creates images from textual descriptions. You interact with the Midjourney bot on Discord. There is a free trial, but ultimately Midjourney is a paid service. There is a choice of plans to choose from. There are alternative software such as the free Craiyon (formerly DALL-E Mini), and freemium DALL-E and DALL-E 2. There is also the open source (and free) Stable diffusion that you can run on your own hardware.</summary>
    <content type="html">
[Midjourney](https://www.midjourney.com/) is a proprietary artificial intelligence program that creates images from textual descriptions. You interact with the Midjourney bot on [Discord](https://discord.com/). There is a free trial, but ultimately Midjourney is a paid service. There is a choice of plans to choose from. There are alternative software such as the free [Craiyon](https://www.craiyon.com/) (formerly DALL-E Mini), and freemium [DALL-E and DALL-E 2](https://openai.com/blog/dall-e/). There is also the open source (and free) [Stable diffusion](https://stability.ai/blog/stable-diffusion-public-release) that you can run on your own hardware.

In Midjourney, you give the bot a prompt, such as `genome pop art` and it gives you a picture.

![mj_genome_pop_art](./mj_genome_pop_art.png)

The software had become famous for producing surreal and moody images, creating beautiful pictures from very short prompts. The AI is described as having its own &apos;style&apos;. One of the critical issues, however, is that it struggled with literal instructions in prompts.

Say, we asked for a picture of `a man and a dog`. It might draw a man and a dog. It might draw a figure that _looks_ like a dog, but with some confusing proportions or extra limbs. It might omit either the man or the dog. Or it may decide to merge the man and the dog in a horrifying way. Midjourney (up to and including version 3) behaved like an artist that thinks they knows better.

![a man and a dog](./mj_a_man_and_a_dog.png)

The creators have been working several months to address this, with a new version that could produce more photo realistic images and understand prompts more literally. They appear to have been successful with the release of version 4. Alpha testing for Midjourney version 4 was announced on the 5th of November 2022. The creators explain that:

&gt; V4 is an entirely new codebase and totally new AI architecture. It&apos;s our first model trained on a new Midjourney AI supercluster and has been in the works for over 9 months. V4 isn&apos;t the final step, but our first step, and we hope you all feel it as the new beginning of something deep and unfathomable.

In this post, I compare the images produced from the new version 4 with the previous version 3. I tried to pick prompts that I might use as quick illustrations in a seminar or here on the blog. These prompts include:

- &quot;A female scientist in a laboratory holding a pipette&quot;
- &quot;population genetics&quot;
- &quot;a conference hall full of scientists&quot;
- &quot;*Salmonella*&quot;
- &quot;laboratory scientist propaganda poster&quot;
- &quot;A painting of graduates by Johannes Vermeer&quot;

Overall, I am very impressed with the output from version 4. It takes prompts more literally and looks gorgeous. It does not have the surreal dreamlike quality of v3 though. It looks almost boring and mass produced, which it is. If you have suggestions for the prompts, feel free to let me know. 

### Some guidance for creating prompts 

There are a number of online helpers for prompt generation:

* [Midjourney Prompt Generator @ hugginface](https://huggingface.co/spaces/doevent/prompt-generator) - Expands given prompts, for something a bit different.
* [Promptomania](https://promptomania.com/midjourney-prompt-builder/) - picking phrases for a specific prompt. Great for finding styles.
* [Phraser.tech](https://phraser.tech/inspiration?text=penguin) - use for inspiration.


## A female scientist in a laboratory holding a pipette

### Version 3

![A_female_scientist_in_a_laboratory_holding_a_pipette](./mj_v3_A_female_scientist_in_a_laboratory_holding_a_pipette.png)

### Version 4

![A_female_scientist_in_a_laboratory_holding_a_pipette](./mj_v4_A_female_scientist_in_a_laboratory_holding_a_pipette.png)

## Population genetics

### Version 3

![population genetics v3](./mj_v3_population_genetics.png)

### Version 4

![population genetics v4](./mj_v4_population_genetics.png)

## A conference hall full of scientists

### Version 3

![A conference hall full of scientists v3](./mj_v3_a_conference_hall_full_of_scientists.png)

### Version 4

![A conference hall full of scientists v4](./mj_v4_a_conference_hall_full_of_scientists.png)

## Salmonella

### Version 3

![Salmonella v3](./mj_v3_Salmonella.png)

### Version 4

![Salmonella v4](./mj_v4_Salmonella.png)

## Laboratory scientist propaganda poster

### Version 3

![Laboratory scientist propaganda poster v3](./mj_v3_laboratory_scientist_propaganda_poster.png)

### Version 4

![Laboratory scientist propaganda poster v4](./mj_v4_laboratory_scientist_propaganda_poster.png)

## A painting of graduates by Johannes Vermeer

### Version 3

![A painting of graduates by Johannes Vermeer v3](./mj_v3_A_painting_of_graduates_by_Johannes_Vermeer.png)

### Version 4

![A painting of graduates by Johannes Vermeer v4](./mj_v4_A_painting_of_graduates_by_Johannes_Vermeer.png)
</content>
  </entry>
  <entry>
    <title>A bioinformatician&apos;s guide to serovars and antigenic formulae in Salmonella</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/binfie-guide-serovar"/>
    <id>https://happykhan.com/posts/binfie-guide-serovar</id>
    <published>2022-10-31T00:00:00.000Z</published>
    <updated>2022-10-31T00:00:00.000Z</updated>
    <summary type="text">A practical guide for bioinformaticians to understand Salmonella serovars, antigenic formulae, and serotyping methods.</summary>
    <content type="html">
In the post, I will describe the basics of _Salmonella_ serovar nomenclature. This post will act as a primer for bioinformaticians starting to work with _Salmonella_ genomes, who are often at a loss.

Serovar designations by the `White-Kauffman-Le Minor` scheme in _Salmonella_ (also known as the `Kauffman-White` scheme) are a standard method for describing groups within _Salmonella enterica_. Serovar designations are often consistent with sequence based typing and genome spanning phylogenies [(Achtman et al., 2012](https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1002776); [Ashton et al., 2016)](https://peerj.com/articles/1752/). Groups defined by _Salmonella_ serovar are indeed meaningful and the serovar names - such as **Typhimurium** (Tie-fi-mu-ri-um) or **Choleraesuis** (Ko-re-la-su-iz) - have fantastic mouth feel when pronounced. These designations will thus persist for the forseeable future.

Serotyping in _Salmonella_ is based mainly on surface antigens with phenotypic characteristics, which can be tested in the laboratory, being used in certain cases. Information about pathogenicity or niche can also give helpful hints. There are over 2,600 known serotype profiles [(Grimont and Weill, 2007](https://www.pasteur.fr/sites/default/files/veng_0.pdf); [Issenhuth-Jeanjean et al., 2014)](https://doi.org/10.1016/j.resmic.2014.07.004). Serotypes are written as a string of numbers and symbols that often break programming scripts that try to read comma delimited files. &apos;`II 4,12:b:1,5`&apos; is one such example. The formulae do mean something, even though they are not immediately interpretable. For simplicity, you can treat the antigenic formulae as a unique and distinct string identifier. If the entire string is identical, it is the same serovar.

There are bioinformatics software to predict the serotype using a genome assembly (i.e. a FASTA file of contigs). These are two I have used often and recommend:

- [The Salmonella In Silico Typing Resource (SISTR)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0147101)
- [SeqSero2](https://pubmed.ncbi.nlm.nih.gov/31540993/)

Both can be run on the command-line, and are available via `conda`. They are also available online at [http://www.denglab.info/SeqSero2](http://www.denglab.info/SeqSero2) and [https://usegalaxy.eu/root?tool_id=sistr_cmd](https://usegalaxy.eu/root?tool_id=sistr_cmd).

## Does the Salmon in _Salmonella_ relate to fish?

No. _Salmonella_ was isolated by Theobald Smith around 1894 while he was looking for the etiological agent of hog cholera, which was a significant problem in the United States at the time. Hence his intial name _Bacillus choleraesuis_. It was later shown that hog cholera was caused by a virus (Classical Swine Fever) and Smith&apos;s bacillus was a constant but secondary invader. The genus was later named after Daniel E. Salmon, Theobald Smith&apos;s supervisor [(Ryan, O&apos;Dywer and Adley, 2017)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5429938/).

_Salmonella_ (Typhi in particular) has been observed beforehand by others, like Karl Eberth and Tadeusz Browicz, and had been cultured before. Georg Gaffky was the first to obtain a pure culture of the &quot;typhoid bacillus&quot;, and in 1884 established that it is the causative agent [(Gaffky, 1884)](https://books.google.co.uk/books?id=Y6lQAAAAYAAJ&amp;pg=PA372&amp;redir_esc=y#v=onepage&amp;q&amp;f=false). The bacteria he cultured we know as _Salmonella enterica_ subspecies _enterica_ serovar Typhi. If history has been a little different, _Salmonella_ could be known today as _Eberthella_ or Gaffky-Eberth bacillus.

## Why do serovars have names like &apos;Typhimurium&apos;?

Many _Salmonella_ serovars have a specific name as well as the serotype. This is in contrast to other organisms like _Escherichia coli_ (e.g. O157:H7 is simply that). The naming system has evolved with our understanding of the organism. Each serotype of _Salmonella_ was originally believed to be a separate species and were given descriptive names, usually describing host specificity or the type of disease [(Ryan, O&apos;Dywer and Adley, 2017)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5429938/). As it became clear that the given names were not always correct, the convention changed to name new serovars after the country or city of isolation [(Carpenter, 1968)](https://doi.org/10.1099/00207713-18-3-191). In 1966, perhaps because there were too many serotypes to name, the International Enterobacteriaceae Subcommittee formally rescinded serovar names for serovars belonging to subspecies other than _S. enterica_ subspecies _enterica_ (although at the time subspecies _enterica_ was called **subgenus** _enterica_) [(Carpenter, 1968)](https://doi.org/10.1099/00207713-18-3-191). Finally in 1987, Le Minor and Popoff noted that studies using DNA-DNA hybridisation and other methods showed that _Salmonella_ was comprised of only two species, and that these and the subspecies within were not consistent with serotype. Practically speaking, the growing number of serovars (2,100 at the time) made the one-serovar-one-species concept -- &apos;untenable&apos; [(Le Minor and Popoff, 1987)](https://doi.org/10.1099/00207713-37-4-465). By this point, however, the names were firmly embedded in the literature and remain in use to this day. Serovars commonly encountered in the literature include Typhi, Typhimurium, Paratyphi A, Paratyphi B, Paratyphi C, Chorelasuis, Infantis, Dublin, Enteritidis, Heidelberg, Javiana, and Newport. All serovars with specific names have an underlying antigenic formulae, for instance, the antigenic formulae for Infantis is `I 6,7,14:r:1,5`.

The table below has some examples of the origins of different serovar names to illustrate the historical and cultural influences on the naming conventions used over time.

| Serovar name | Origin and meaning                                                                           |
| ------------ | -------------------------------------------------------------------------------------------- |
| Agama        | Isolated from the feces of the Agama lizard (_Agama agama_).                                 |
| Agona        | Isolated from cattle in Ghana, presumably in the town Agona, in 1952.                        |
| Anatum       | Isolated from a duck in 1922 in the USA. Epizootic at the time.                              |
| Choleraesuis | Lit. &quot;Swine cholera&quot;, believed to be causive agent of Hog cholera. Later found to be untrue. |
| Dublin       | First isolated from the stool of a patient in Dublin, Ireland in 1929.                       |
| Gallinarum   | Causative agent of fowl typhoid.                                                             |
| Heidelberg   | First isolated from a patient in Heidelberg, Germany in 1933.                                |
| Infantis     | First isolated from an infant in Connecticut, USA in 1943.                                   |
| Typhi        | Causes typhoid fever in humans.                                                              |
| Typhimurium  | Lit. &quot;mouse typhi&quot; . Causes typhoid fever in mice.                                           |

## What are the &apos;O&apos; antigens and &apos;serogroups&apos;?

O antigen (O polysaccharide) is a part of the lipopolysaccharide (LPS) component of the outer membrane found in all _Enterobacteriacae_. It is a highly variable cell constituent, making it a discriminant marker. It consists of oligosaccharide repeats (&apos;O&apos; units), normally containing two to eight sugar residues. The variation is mostly in the types of sugars present, their order in the structure, and the linkages between them. There are 46 O serogroups in described in the `White-Kauffman-Le Minor` scheme, these used to be denoted by letters of the alphabet but they ran out of letters, and the number of the characteristic O factor are now used instead [(Liu et al. 2014)](https://doi.org/10.1111/1574-6976.12034). The letter definitions are still propagated in the literature. For example, Infantis (`I 6,7,14:r:1,5`) is serogroup O:7 (or C1 using the letter defintions). [Wikipedia](https://en.wikipedia.org/wiki/Kauffman%E2%80%93White_classification) has a simple table of the serogroups and some of their members. [Grimont and Weill (2007)](https://www.pasteur.fr/sites/default/files/veng_0.pdf) is a more detailed catalog. Genetic variation within the O-antigene cluster (between _gnd_ and _galF_), genetic variation of other associated genes encoded on mobile genetic elements, and side chains of the lipopolysaccharide have been used to further divide members of different serogroups [(Liu et al. 2014)](https://doi.org/10.1111/1574-6976.12034).

![LPS](./skaa248f0001.jpg)

&gt; Gram-negative bacterial cell-wall structure with emphasis in the lipopolysaccharide (LPS) presence in the outer membrane. From [Monteiro &amp; Faciola (2020)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7455920/).

## The &apos;H&apos; antigen and phase variation in _Salmonella_

H antigens are found in the bacterial flagella and are usually involved in the activation of host immune responses. There are over 114 H antigens described in the `White-Kauffman-Le Minor` scheme.

Many _Salmonella_ have two genes encoding flagella, and these are alternatively expressed (through a process called `phase variation`). The alternation is controlled by inverting a 800-base-pair sequence of DNA. This acts like a switch to turn an encoded promotor on or off. When the promoter is off, the _fliC_ gene, found elsewhere in the genome, is expressed and specifies one specific flagellum. When the promotor is on, the _fljB_ gene that is immediately downstream of the promoter and encodes a different flagellum is expresed instead. At the same time, there is also a transcriptional repressor (_fljA_) expressed, which represses _fliC_ and makes expression of the two flagella encoding genes mutually exclusive. See the diagram below and [Silverman, Hillmen, and Simon (1979)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC382945/). _Salmonella_ are thus either &apos;biphasic&apos;, &apos;monophasic&apos; or &apos;non-motile&apos;, with the capability of expressing two, one or no flagella, respectively. The typing results of both flagella are included as part of the antigenic formulae. When serotyping in the lab, specific growth conditions are used to coerce _Salmonella_ to choose one phase or the other.

![Phase Salmonella](./phase_salmonella.jpeg)

&gt; A schematic representation of flagellar phase variation in _S. enterica_. The promoter for the _fljBA_ operon is located within an invertible DNA segment whereby inversion of the promoter is mediated by the _Hin_ recombinase. In one orientation, the _fljBA_ operon is expressed and FljB flagellin is produced along with FljA, repressor of the unlinked _fliC_ gene that encodes FliC flagellin. In the opposite orientation, the _fljB_ gene is not expressed, nor is the repressor FljA, thus allowing transcription of the _fliC_ gene. From [Bonifield and Hughes (2003)](https://journals.asm.org/doi/10.1128/JB.185.12.3567-3574.2003)

## Not all serovars are defined strictly by surface antigens (O &amp; H)

Serovar specification is not strictly limited to surface antigens (&apos;O&apos; and &apos;H&apos;). Other antigens (e.g. Vi) are also used on occasion and other unrelated features can be used as well. An example of this are the serovars Paratyphi C, Chorelasuis _sensu stricto_, Chorelasuis var. Kuzendorf, Chorelasuis var. Decatur, and Typhisuis. All of these have the same antigenic formulae (`I 6,7:c:1,5`). However, have differential abilities e.g. the ability/inability to ferment Dulcitol, H2S or Mucate. Each of these have different host ranges, and form distinct phylogenetic groups [(Zhou et al. 2018)](https://doi.org/10.1016/j.cub.2018.05.058). There are more exceptions, for instance, Gallinarum lacks flagella, thus has no &apos;H&apos; antigen (the formulae is `I 1,9,12:–:–`) and is differentiated from its biovar Pullorum biochemically [(Grimont and Weill, 2007)](https://www.pasteur.fr/sites/default/files/veng_0.pdf).

## Is it &apos;serovar&apos; or &apos;serotype&apos;?

The terms &apos;serovars&apos; and &apos;serotypes&apos; are interchangeable. The World Health Organisation (WHO)/Institut Pasteur use the term &apos;serovar&apos; [(Grimont and Weill, 2007)](https://www.pasteur.fr/sites/default/files/veng_0.pdf). While the US Centers for Disease Control and Prevention uses the word &apos;serotype&apos; [(Brenner et al. 2000)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC86943/). Serovar seems to be the historic term but serotype is the term used in the study of other organisms.

## _Salmonella_ taxonomy today

The `White-Kauffman-Le Minor` scheme recognises two species within the genus _Salmonella_; _S. enterica_ and _S. bongori_. Within _S. enterica_, the scheme recognises six subspecies [(Grimont and Weill, 2007)](https://www.pasteur.fr/sites/default/files/veng_0.pdf). So _Salmonella_ looks like this:

- _Salmonella enterica_
  - _S. enterica_ subsp. _enterica_
  - _S. enterica_ subsp. _salamae_
  - _S. enterica_ subsp. _arizonae_
  - _S. enterica_ subsp. _diarizonae_
  - _S. enterica_ subsp. _houtenae_
  - _S. enterica_ subsp. _indica_
- _Salmonella bongori_

This does make some of the names very long, for instance, serovar Heidelberg would be _Salmonella enterica_ subsp. _enterica_ ser. Heidelberg.
There are shorthand abbreviations for each of the subspecies, used in antigenic formulae.

| Salmonella subspecies             | Abbreviation |
| --------------------------------- | ------------ |
| _S. enterica_ subsp. _enterica_   | `I`          |
| _S. enterica_ subsp. _salamae_    | `II`         |
| _S. enterica_ subsp. _arizonae_   | `IIIa`       |
| _S. enterica_ subsp. _diarizonae_ | `IIIb`       |
| _S. enterica_ subsp. _houtenae_   | `IV`         |
| _S. enterica_ subsp. _indica_     | `VI`         |

_S. bongori_ used to be classed as _S. enterica_ subspecies _bongori_ and used the abbreviation &apos;`V`&apos; but has been since been promoted, which is why &apos;`V`&apos; does not appear in the table above. There are likely other subspecies beyond what is described in the `White-Kauffman-Le Minor` scheme ([Alikhan et al. 2018](https://doi.org/10.1371/journal.pgen.1007261); [Criscuolo et al. 2019](https://doi.org/10.1099/mgen.0.000284)).

## What do the antigenic formulae actually mean?

At first glance it makes no sense:

&gt; `I 6,7,14:r:1,5`

First is the subspecies abbreviation (`I, II, IIIa`...) according to the table above, and then followed by a colon separated list of 3 (maybe 4) individual lists, in the format of:

&gt; O antigen results **:** flagellar (H1) results **:** flagellar (H2) results **:** Other results (maybe)

If the subspecies abbreviation is missing, then it is implied that strain belongs to subspecies _enterica_ (`I`). For instance, Infantis is sometimes written as simply &apos;`6,7,14:r:1,5`&apos;. This can be misleading as the same antigenic profile can be found in multiple subspecies. The nomenclature system at the US Centers for Disease Control and Prevention includes the subspecies abbreviation (`I, II, IIIa`...) in serotypes [(Brenner et al., 2000)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC86943/).

Each value in the respective sublists is a positive result for different antisera. So in the example above (for Infantis) it means:

| Infantis is: `I` 6,7,14:r:1,5      |
| ---------------------------------- |
| Subspecies _enterica_ (`I`)        |
| Serogroup O:7                      |
| Postive for O antigens 6,7, and 14 |
| Postive for H1 antigens r          |
| Postive for H2 antigens 1 and 5    |

The numbers between lists are not related. So &apos;1&apos; being postive for O antigen has nothing to do with H2 being postive for &apos;1&apos;. A positive in this case is observing agglutination when tested. Each value in the list refers to a pre-defined antiserum. If you are curious about what agglutination looks like, there is [a video here](https://www.youtube.com/watch?v=WsCc5JVU98g). The UKSHA&apos;s laboratory process for identifying _Salmonella_ is described [here](https://bfff.co.uk/wp-content/uploads/2014/12/3.National_SOP_FNES16_F13_Detection_of_Salmonella_Species.pdf), and [here](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/969498/ID_24i4.pdf).

There are additional symbols used as well, which makes things more complicated. For instance, the { } means that the antigens are mutually exclusive. Let&apos;s take serovar Huvudsta, which is 3,\{10}\{15,34\}:b:1,7 as an example.

| Huvudsta is: `I` 3,\{10\}\{15,34\}:b:1,7 |
| ------------------------------------ |
| Subspecies _enterica_ (`I`)          |
| Serogroup O:3,10                     |
| Postive for O antigens 3,10 OR       |
| Postive for O antigens 3,15,and 34   |
| Postive for H1 antigens b            |
| Postive for H2 antigens 1 and 7      |

Other symbols include [ ], which means that O or H factor in question may be present or absent. If the O factor is underlined, it means they are present only if the culture is lysogenized by the corresponding converting phage. When H factors
are in square brackets, this means that they are exceptionally found in wild strains. And finally ( ) means that O or H factor in question is only weakly agglutinable. All in all, it should feel quite similar to regular expressions, if you are familiar with those. When the strain is monophasic, a &apos;`-`&apos; is used to denote the absence of a particular flagellum. Non-motile strains have `-` for both H1 and H2.

Here are some antigenic formulae for different serovars, which should now look more friendly.

| Serovar  | Antigenic formulae |
| -------- | ------------------ |
| Norwich  | `I 6,7:e,h:1,6`    |
| Brisbane | `I 28:z:e,n,z15`   |
| Ipswich  | `I 41:z4,z24:1,5`  |
| Seattle  | `I 28:a:e,n,x`     |

If you would like to learn more, you can read the bible of _Salmonella_ serovars, Grimont and Weill&apos;s [Antigenic Formulae of the Salmonella Serovars (2007)](https://www.pasteur.fr/sites/default/files/veng_0.pdf). Have a look and see if your hometown has a serovar named after it!

## What is &apos;`I 1,4,[5],12:i:-`&apos;?

The antigenic formulae for monophasic variants of _Salmonella enterica_ serovar Typhimurium is `I 1,4,[5],12:i:-`. It seems to be regularly encountered by bioinformaticians, and I am often asked about this serotype in particular. You may see the shorthand, `I 4:i:-`, used by US Centers for Disease Control and Prevention. When the strain is monophasic, a &apos;`-`&apos; is used to denote the absence of a particular flagellum. Many serovars are entirely monophasic, such as Dublin (`I 1,9,12[Vi]:g,p:–`) and Enteritidis (`I 1,9,12:g,m:–`)[(Grimont and Weill, 2007)](https://www.pasteur.fr/sites/default/files/veng_0.pdf).

All `I 1,4,[5],12:i:-` are not monophasic Typhimurium, however, there are a number of serotypes that start with `I 1,4,[5],12:i:...` differing only by H2. When H2 is dropped, the monophasic variants will have the same antigenic formulae. As such, if you see the antigenic formulae `I 1,4,[5],12:i:-` you need other information (such as MLST, where many monophasic Typhimurium are ST34) to determine whether it is Typhimurium or not.

These are the serovars that could collide as `I 1,4,[5],12:i:-` [from Grimont and Weill (2007)](https://www.pasteur.fr/sites/default/files/veng_0.pdf):

| Serovar name | Serogroup | O            | H1  | H2      |
| ------------ | --------- | ------------ | --- | ------- |
| Typhimurium  | O4        | _1_,4,[5],12 | i   | 1,2     |
| Lagos        | O4        | _1_,4,[5],12 | i   | 1,5     |
| Agama        | O4        | 4,12         | i   | 1,6     |
| Farsta       | O4        | 4,12         | i   | e,n,x   |
| Tsevie       | O4        | _1_,4,12     | i   | e,n,z15 |
| Tumodi       | O4        | _1_,4,12     | i   | z6      |

&gt; N.B. O antigens `4,12` are the definitive factors for the examples from serogroup O4. The _1_ is only present when lysogenized by the corresponding converting phage (in the lab), and the [5] means the factor may or may not be there. With this in mind, replacing H2 with &apos;`-`&apos; would make all serotypes above indistinguishable when tested.

I searched [EnteroBase](https://enterobase.warwick.ac.uk) for existing genomes that would fit this case. I looked at genomes with the MLST ST associated with each serovar, and then looked at the serotype prediction from [SISTR](https://github.com/phac-nml/sistr_cmd) for cases where `I 1,4,[5],12:i:-` is reported. I found 16 Agama (eBG 167) and 1 Lagos (ST 2469). Many of these were listed with a clinical/human source.

Strains of _Salmonella enterica_ serovar Typhimurium that lack the first phase are also monophasic variants, having the antigenic formulae `I 1,4,[5],12:-:1,2` [(Bugarel et al., 2012)](https://doi.org/10.1016/j.foodres.2011.06.057). Again, these would collide with other serovars such as Saintpaul (`I 1,4,[5],12:e,h:1,2`) and Stanley (`I 1,4,[5],12,[27]:d:1,2`). Naturally, a Typhimurium lacking both flagella has the same antigenic profile as a strain lacking both flagella from almost any other serovar in the O4 serogroup.

## Why is this so complicated?

The simple serovar names (e.g. Typhi) belies the complex discussion of the _Salmonella_ genus. In my opinion, the `White-Kauffman-Le Minor` scheme attempts to simultaneously solve problems around taxonomy, clinical identification, characterising pathogen potential, and provide a stable nomenclature. Admirable? Yes. Foolhardy? Maybe. For instance, serotypes were expected initially to define species. Later, serogroups reflected a neighbourhood of _Salmonella_. And differences in antigenic formula were thought to imply differences in host association and pathogenicity. The scheme goes well beyond giving stable names, measuring genetic variation (like counting SNP differences) or defining flat clonal complexes (like MLST).

Indeed, it is better to consider the `White-Kauffman-Le Minor` scheme as an addressing system for _Salmonella_ rather than just flat names. The scheme is hand and hand with our understanding of _Salmonella_. Many of the address fields we use for _Salmonella_ were defined by the scheme. Hence, if you received a letter from a _Salmonella_, the return address might read:

```mail
RTN TO:
Ser. Heidelberg
c/o 1,4,[5],12:r:1,2
subsp. enterica (I)
enterica
SALMONELLA
```

![Salmonella on holiday at the beach](./mj_salmonella_on_holiday_postcard.png)

&gt; **&apos;Wish you were here**,&apos; An AI (Midjourney) generated picture with the prompt; &apos;_Salmonella_ on holiday, postcard&apos;.

## References

- Achtman M, Wain J, Weill F-X, Nair S, Zhou Z, Sangal V, et al. Multilocus Sequence Typing as a Replacement for Serotyping in _Salmonella enterica_. PLoS Pathog. 2012;8: e1002776. https://doi.org/10.1371/journal.ppat.1002776
- Alikhan N-F, Zhou Z, Sergeant MJ, Achtman M. A genomic overview of the population structure of _Salmonella_. PLoS Genet. 2018;14: e1007261. https://doi.org/10.1371/journal.pgen.1007261
- Ashton PM, Nair S, Peters TM, Bale JA, Powell DG, Painset A, et al. Identification of _Salmonella_ for public health surveillance using whole genome sequencing. PeerJ. 2016;4: e1752. https://doi.org/10.7717/peerj.1752
- Bonifield HR, Hughes KT. Flagellar Phase Variation in _Salmonella enterica_ Is Mediated by a Posttranscriptional Control Mechanism. J Bacteriol. 2003;185: 3567–3574. https://doi.org/10.1128/JB.185.12.3567-3574.2003
- Brenner FW, Villar RG, Angulo FJ, Tauxe R, Swaminathan B. _Salmonella_ Nomenclature. J Clin Microbiol. 2000;38: 2465–2467. https://doi.org/10.1128/JCM.38.7.2465-2467.2000
- Carpenter KP. Report and minutes of the meeting of the International Enterobacteriaceae Subcommittee, Moscow 1966. International Journal of Systematic Bacteriology. 1968;18: 191–196. https://doi.org/10.1099/00207713-18-3-191
- Bugarel M, Granier SA, Bonin E, Vignaud ML, Roussel S, Fach P, et al. Genetic diversity in monophasic (1,4,[5],12:i:- and 1,4,[5],12:-:1,2) and in non-motile (1,4,[5],12:-:-) variants of _Salmonella enterica_ _S. Typhimurium_. Food Research International. 2012;45: 1016–1024. https://doi.org/10.1016/j.foodres.2011.06.057
- Criscuolo A, Issenhuth-Jeanjean S, Didelot X, Thorell K, Hale J, Parkhill J, et al. The speciation and hybridization history of the genus _Salmonella_. Microbial Genomics. 2019;5. https://doi.org/10.1099/mgen.0.000284
- Grimont PA, Weill F-X. Antigenic formulae of the _Salmonella_ serovars. WHO collaborating centre for reference and research on _Salmonella_. 2007;9: 1–166. https://www.pasteur.fr/sites/default/files/veng_0.pdf
- Issenhuth-Jeanjean S, Roggentin P, Mikoleit M, Guibourdenche M, De Pinna E, Nair S, et al. Supplement 2008–2010 (no. 48) to the White–Kauffmann–Le Minor scheme. Research in Microbiology. 2014;165: 526–530. https://doi.org/10.1016/j.resmic.2014.07.004
- Le Minor L, Popoff MY. Designation of _Salmonella enterica_ sp. nov., nom. rev., as the Type and Only Species of the Genus _Salmonella_: Request for an Opinion. International Journal of Systematic Bacteriology. 1987;37: 465–468. https://doi.org/10.1099/00207713-37-4-465
- Liu B, Knirel YA, Feng L, Perepelov AV, Senchenkova SN, Reeves PR, et al. Structural diversity in _Salmonella_ O antigens and its genetic basis. FEMS Microbiol Rev. 2014;38: 56–89. https://doi.org/10.1111/1574-6976.12034
- Ryan MP, O’Dwyer J, Adley CC. Evaluation of the Complex Nomenclature of the Clinically and Veterinary Significant Pathogen _Salmonella_. BioMed Research International. 2017;2017: 1–6. https://doi.org/10.1155/2017/3782182
- Silverman M, Zieg J, Hilmen M, Simon M. Phase variation in _Salmonella_: genetic analysis of a recombinational switch. Proc Natl Acad Sci USA. 1979;76: 391–395. https://doi.org/10.1073/pnas.76.1.391
- Yoshida CE, Kruczkiewicz P, Laing CR, Lingohr EJ, Gannon VPJ, Nash JHE, et al. The _Salmonella_ In Silico Typing Resource (SISTR): An Open Web-Accessible Tool for Rapidly Typing and Subtyping Draft Salmonella Genome Assemblies. Hensel M, editor. PLoS ONE. 2016;11: e0147101. https://doi.org/10.1371/journal.pone.0147101
- Zhang S, Den Bakker HC, Li S, Chen J, Dinsmore BA, Lane C, et al. SeqSero2: Rapid and Improved _Salmonella_ Serotype Determination Using Whole-Genome Sequencing Data. Dudley EG, editor. Appl Environ Microbiol. 2019;85: e01746-19. https://doi.org/10.1128/AEM.01746-19
- Zhou Z, Lundstrøm I, Tran-Dien A, Duchêne S, Alikhan N-F, Sergeant MJ, et al. Pan-genome Analysis of Ancient and Modern _Salmonella_ _enterica_ Demonstrates Genomic Stability of the Invasive Para C Lineage for Millennia. Current Biology. 2018;28: 2420-2428.e10. https://doi.org/10.1016/j.cub.2018.05.058
</content>
  </entry>
  <entry>
    <title>What is Mastodon?</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/what-is-mastodon"/>
    <id>https://happykhan.com/posts/what-is-mastodon</id>
    <published>2022-10-28T00:00:00.000Z</published>
    <updated>2022-10-28T00:00:00.000Z</updated>
    <summary type="text">(Skip ahead if you know how the internet works)</summary>
    <content type="html">
(Skip ahead if you know how the internet works)

When I was a teenager I used to moderate a [phpBB](https://www.phpbb.com/) web forum that my friend had set up. It was a small instance that just had a few of us from high school. My friend had downloaded the phpBB software and launched it on a webserver he rented. The webserver was just a computer in a data centre somewhere in the world. There was nothing architecturally special about it. He could run the same web services from his local computer, although, in practice it was difficult to keep his local computer &quot;always on&quot; and available. This is how people used to interact with the internet. The internet has and always will be a loose federation of other people&apos;s computers.

![PHBB forum](./phpbb.png)

&gt; A fresh install of a phpBB forum. Hopefully familiar to some!

Whenever you visit a website there is always someone behind the scenes running the site. You can search that directory with sites, like https://whois.domaintools.com/, to find out who. As more and more people joined the internet, we collectively realized that the time and money it takes to keep websites going puts running our own websites in the too hard basket. Thus, people started to gravitate to &quot;free&quot; social media platforms. It was always clear there was a comprise between your own control of the content you put on these websites versus the effort in maintaining your own. For the most part this exchange was acceptable. In those days, the biggest furor was over Facebook changing the page layout.

As social media became less about posting cat pictures on [Caturday](https://knowyourmeme.com/memes/caturday) and more about following breaking news stories, the control we gave away for the convenience of having someone else do the dirty work has become more pointed. For me, I use social media for keeping in touch with family, friends (Facebook) and colleagues (Twitter). I find social media platforms these days are no longer fit for purpose. There is too many advertisements and promoted content along with the poor filtering and searching features. The alternative is one that has always been there - move back to independently-managed (self-hosted) websites.

# What is Mastodon

[Mastodon](https://github.com/mastodon/mastodon) is a free and open web application that runs on a webserver, much like (self-hosted) [Wordpress](https://wordpress.org/) for blogs or [phpBB](https://www.phpbb.com/) for forums. Mastodon is designed for microblogging - similar to Twitter. There is an open instance that you can try out (for free) at https://mastodon.social/. What makes Mastodon different to, say, phpBB, is that the different instances can (and do) communicate with each other. Mastodon uses a standardized, open protocol to implement federation. It is called ActivityPub. Any software that likewise implements federation via ActivityPub can seamlessly communicate with Mastodon, just like Mastodon websites communicate with one another.

Each instance is largely self-contained, although users can follow feeds and interact with users on other instances. A user&apos;s feeds are populated with people they explicitly follow (`Home`), people in the same instance (`Local`) and people in other instances (`Federated`). The character limit for each post is 500 by default. For more information see https://docs.joinmastodon.org/

## How is Mastodon implemented?

Mastodon is written in Javascript and Ruby. It runs as a web application with a PostgreSQL database backend and a Redis cache up front.

## Synchronize Twitter and a Mastodon instance

If you are worried about the effort of posting on yet another social media platform. You can synchronize your posts between Twitter and a Mastodon instance. It can be configured to be be one way (twitter -&gt; mastodon; mastodon -&gt; twitter), or both ways. I am using https://crossposter.masto.donte.com.br/ at the moment. There are others.

## Mobile apps for Mastodon

There are official mobile apps that you can use https://joinmastodon.org/apps. There are also third party ones as well. I am using `Tusky` a mastodon client for android, see https://tusky.app/.

## Does it matter which instance / server that I join

Yes and no. Your `local` feed will be populated by people in the same server as you. When you start, you will initially see a lot of content from these users. There is nothing stopping you from following anyone in any other instance. Hence you have complete freedom in which content you would like to see. Over time you will tailor your feed as you like it.

**The most important thing to check is the server rules**. This is the critical point of difference between instances. Rules are usually around the content or the community, but some can have practical implications. For instance, some instances do not tollerate automatic cross-posting from Twitter. So do read the server rules before joining.

## Use hashtags

Hashtags play a much more important role on mastodon than they do on twitter. There’s no analog of the twitter algorithm scanning post content to determine what to show people. If you want your post to be discovered by people who aren’t following you (which, admittedly, isn’t always the case), make sure to choose the appropriate hashtags.

You can track hashtags too.

# mstdn.science

Some of us in the Microbial genomics community have setup our own instance at https://mstdn.science/. You are welcome to join. It is a place for people our field, scientists in general, and science enthusiasts to discuss research and topics surrounding our work. It is hosted on a small Digitalocean server, and I am still tweaking certain parts of it. The whole thing is in its infancy, and might just crash and burn.

If you want to chip in for running costs, you can [Donate using OpenCollective](https://opencollective.com/mstdnscience). You can make a [one-off donation with PayPal](https://www.paypal.com/donate/?hosted_button_id=PT2Z39GS6NMA2).

All moderation in a mastodon instance is community driven. So as the community grows, we may need help with moderating content.

# Other instances

There are other instances that you may find closer to your interests:

- https://genomic.social/about - Genomic Science community
- https://ecoevo.social/about - biological Ecology and Evolution community
- https://fediscience.org/about - for publishing scientists
- https://scholar.social/ - for researchers, grad students, librarians, archivists, undergrads, academically inclined high schoolers, educators of all levels, journal editors, research assistants, professors, administrators—anyone involved in academia
- https://scicomm.xyz/ - for science students, communicators, and enthusiasts ... and scientists!
</content>
  </entry>
  <entry>
    <title>How to use rMLST and its application to Acinetobacter</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/rmlst-in-acinetobacter"/>
    <id>https://happykhan.com/posts/rmlst-in-acinetobacter</id>
    <published>2022-10-09T00:00:00.000Z</published>
    <updated>2022-10-09T00:00:00.000Z</updated>
    <summary type="text">In the previous post, I describe rMLST (Jolley et al. 2012) as a ready and able alternative for species without existing MLST schemes.</summary>
    <content type="html">
In the [previous post](/posts/support_for_rmlst), I describe rMLST ([Jolley et al. 2012](https://pubmed.ncbi.nlm.nih.gov/22282518/)) as a ready and able alternative for species without existing MLST schemes.

To recap:

&gt; rMLST is a genotyping scheme that uses the genes for the bacterial ribosome protein subunits (_rps_ genes). This is as close as you can get to a universal MLST scheme. rMLST works on a diverse range
&gt; of bacteria (like 16S) but provides deeper resolution beyond 16S in most species. See [Jolley et al. 2012](https://pubmed.ncbi.nlm.nih.gov/22282518/).

I should also mention here that rMLST is not readily available in MLST tools like [Torsten&apos;s mlst](https://github.com/tseemann/mlst), but it is accessible through an [API on the PubMLST website](https://pubmlst.org/bigsdb?db=pubmlst_rmlst_seqdef) for academic use.

I want to show how to run rMLST on a dataset, and assess that it works correctly. To do this, I revisited _Acinetobacter_ based on what we saw in the [previous post](/posts/support_for_rmlst).
It is known that the first _Acinetobacter_ MLST scheme (the &apos;Oxford&apos; scheme) does not work very well. There has been a subsequent scheme (the &apos;Pasteur&apos; scheme) published in [Diancourt et al. 2010](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0010034). This second scheme has been described to work better ([Gaiarsa et al. 2019](https://www.frontiersin.org/articles/10.3389/fmicb.2019.00930/full)). So I have
picked a fairly difficult example, but let&apos;s go through the motions and see how rMLST compares to both schemes, and core genome phylogenies.

# The dataset for our comparison

There is a dataset we can use described in:

&gt; Wallace et al. (2016) &quot;Use of comparative genomics to characterize the diversity of _Acinetobacter baumannii_ surveillance isolates in a health care institution&quot;. Antimicrob Agents Chemother; 60(10):5933-41. doi: [10.1128/AAC.00477-16.](https://journals.asm.org/doi/10.1128/AAC.00477-16)

I chose this one because it has accession codes for assembled contigs in the supplementary information - so I would not have to download sequenced reads and reassemble them. That sort of work would turn this into an actual project and I would rather keep this casual - just me doing random stuff in my pyjamas. In the supplementary materials of this publication, they show phylogenetic trees with MLST calls with the Oxford and Pasteur schemes and say the Pasteur scheme was more consistent with their tree. The figure showing the Oxford scheme is below:

![Oxford acinetobacter does not match genome phylogeny](./Oxford_acineto.png)

&gt; Supplemental Fig. 2. Oxford sequence types overlaid on the whole genome phylogeny
&gt; presented in Figure 1. The isolates are colored by the sequence types (ST) defined by the
&gt; MLST system. The diversity of colors indicates that there is little concordance between the
&gt; whole genome phylogeny and the MLST sequence types.

You can see a strange mix of other STs (e.g. ST281 (blue) is intermingled with &apos;new&apos; STs (red)) and other STs (light blue and dark green) are broken apart. Some genomes appear to be untypable (being blank).
There is room for improvement by using a revised scheme. Although, this might be a sign of a genus that cannot be resolved with MLST.

## Fetching the dataset

If you want to know how I fetch the genome assemblies and set up my working environment for this, I have a [separate post with all the details](/posts/supp-methods-for-rmlst-acineto)

# Calling rMLST using the pubMLST API

I can at least show you how to get easily retrieve rMLST called for your genome of interest using the pubMLST API. The API is free (and anonymous) to use. No registration required. It is described on the website as being free for academic non commercial use only. There are some example scripts of [how to use the API in curl, perl and python](https://pubmlst.org/species-id/species-identification-via-api). I expanded the python example script for our purposes. It takes a folder of assembled contigs (`ncbi_dataset/data`) and submits them one by one to the API. It then pulls out relevant fields from the returned JSON response and creates a table.

```python
#!/usr/bin/env python3
from os import mkdir, path, listdir
import shutil
import sys, requests, base64
from csv import DictWriter

def rmlst_taxon(fasta_file, name):
    uri = &apos;http://rest.pubmlst.org/db/pubmlst_rmlst_seqdef_kiosk/schemes/1/sequence&apos;
    with open(fasta_file, &apos;r&apos;) as x:
        fasta = x.read()
    payload = &apos;{&quot;base64&quot;:true,&quot;details&quot;:true,&quot;sequence&quot;:&quot;&apos; + base64.b64encode(fasta.encode()).decode() + &apos;&quot;}&apos;
    response = requests.post(uri, data=payload)
    if response.status_code == requests.codes.ok:
        data = response.json()
        try:
            taxon = []
            rST = data[&apos;fields&apos;][&apos;rST&apos;]
            for match in data[&apos;taxon_prediction&apos;]:
                new_hit = {&quot;name&quot;: name, &quot;rST&quot;: rST, &quot;rank&quot;:match[&apos;rank&apos;], &quot;taxon&quot;: match[&apos;taxon&apos;], &quot;support&quot;: str(match[&apos;support&apos;]), &quot;taxonomy&quot;: match[&apos;taxonomy&apos;]}
                taxon.append(new_hit)
            return taxon, None
        except KeyError:
            return [{&quot;name&quot;: name}], f&quot;No match for {name}&quot;

    else:
        return None, response.text


taxon_out = DictWriter(open(&apos;taxon.csv&apos;, &apos;w&apos;), fieldnames=[&apos;name&apos;,&apos;rST&apos;, &apos;rank&apos;, &apos;taxon&apos;, &apos;support&apos;, &apos;taxonomy&apos; ])
taxon_out.writeheader()
if not path.exists(&apos;gen_fasta&apos;):
    mkdir(&apos;gen_fasta&apos;)
all_profiles = []
for fasta_path, name in [(path.join(&apos;ncbi_dataset/data&apos;,x), x) for x in listdir(&apos;ncbi_dataset/data&apos;) if x.startswith(&apos;GCA&apos;)]:
    fasta_file = [path.join(fasta_path, x) for x in listdir(fasta_path) if x.endswith(&apos;.fna&apos;)]
    if fasta_file:
        if not path.exists(f&apos;gen_fasta/{name}.fasta&apos;):
            shutil.copy(fasta_file[0], f&apos;gen_fasta/{name}.fasta&apos;)
        print(f&apos;Fetching rmlst for {name}...&apos;)
        taxon, errors  = rmlst_taxon(fasta_file[0], name)
        if taxon:
            print(&apos;Fetched rmlst&apos;)
            taxon_out.writerows(taxon)
        if errors:
            print(errors)
```

It is a quick and dirty script, but you can see there&apos;s nothing earth shattering here. The full specification of the API results [can be found here](https://pubmlst.org/species-id/species-identification-via-api).
This produces a table called [taxon.csv](/example_data/taxon.csv), and I have included a copy for you.

Using the same set of assembled contigs, I call regular MLST with [Torsten&apos;s mlst](https://github.com/tseemann/mlst).

```bash
mlst  gen_fasta/GCA_000162035.1.fasta --scheme abaumannii &gt; mlst # Oxford scheme
mlst  gen_fasta/GCA_000162035.1.fasta --scheme abaumannii_2 &gt; mlst_2 # Pasteur scheme
```

I merged the results from the two schemes, along with the rMLST results from before, into a single table [updated_st_table.csv](/example_data/updated_st_table.csv) so we can compared all the schemes together.
We can measure the concordance and diversity of the schemes with statistical tests available on the [Comparing Partitions website](http://www.comparingpartitions.info/index.php?link=Tool).

![Diveristy index](./diversity.png)

![Adj wallace](./adj_wallace.png)

The diversity index echoes what people have described before; that the Pasteur scheme has fewer STs than the Oxford one. rMLST, however, has more partitions than both. The measure of concordance (Adj. Wallace; above), shows that rMLST is more consistent with the Pasteur scheme (the &apos;right&apos; one), although those overlapping confidence intervals may mean that this is not significant.

This is not definitive. Let&apos;s have a closer look at one species, _A. baumannii_, to understand this better. I separate the _A. baumannii_ genomes into their own folder, and run `parsnp` to generate a core genome alignment and phylogeny.

```bash
parsnp  -p 8   -r !  -d ./baumannii/ -c
```

I then visualize the tree in Microreact and annotate with the sequence types from the three schemes.

![A. baumanii tree](./baumanii_tree.png)

Ah. OK. This does not look that good either. There are inconsistencies between Pasteur and Oxford as previously described. The rMLST designations are mostly OK - like the Pasteur scheme - and do not conflict with the tree topology outright. But, there are examples (e.g. rST 8849 and 9510) appear split across clades. This is bad. If you want to explore the tree further, I have saved an interactive version of the tree at https://microreact.org/project/baumannii-rmlst

Not a conclusive result overall. It is now time to ask an expert why three different schemes can&apos;t get it perfect - it is ok to ask for help, kids! Alternatively, it could be the way I&apos;ve generated the phylogeny that is causing problems.

Great. Looks like I&apos;ve set myself up for a sequel and there _are_ some other existing datasets to play with, including

- [Roberts et al. 2022](&lt;https://www.thelancet.com/journals/lanmic/article/PIIS2666-5247(22)00181-1/fulltext&gt;)
- [Diancourt et al. 2010](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0010034)

Regardless of our mixed results, the process I&apos;ve described here is something you can apply to any other genus.
</content>
  </entry>
  <entry>
    <title>Downloading and installing software for the rMLST comparison</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/supp-methods-for-rmlst-acineto"/>
    <id>https://happykhan.com/posts/supp-methods-for-rmlst-acineto</id>
    <published>2022-10-07T00:00:00.000Z</published>
    <updated>2022-10-07T00:00:00.000Z</updated>
    <summary type="text">These are some notes for how to install software and fetch the data required for the rMLST comparison in Acintobacter.</summary>
    <content type="html">
These are some notes for how to install software and fetch the data required for [the rMLST comparison in _Acintobacter_](/posts/rmlst-in-acinetobacter).

## Setting up conda env (to install software)

Here are steps for setting up a conda to manage your software installations.

```bash
wget https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh
chmod +x ./Miniconda3-py38_4.12.0-Linux-x86_64.sh
./Miniconda3-py38_4.12.0-Linux-x86_64.sh
~/miniconda3/bin/conda init
source ~/.bashrc
conda config --add channels defaults
conda config --add channels conda-forge
conda config --add channels bioconda
conda create -y -c conda-forge -n rmlst mamba
conda activate rmlst
```

## Installing software

Using conda makes it easy to install bioinformatics software.

```bash
mamba install -y -c bioconda rapidnj cgmlst-dists mashtree
mamba install -y -c conda-forge pip notebook  nb_conda_kernels  jupyter_contrib_nbextensions
pip install grapetree
```

## Download and &apos;install&apos; NCBI datasets

You can fetch genome assemblies from NCBI using the `datasets` tool, which is available at https://www.ncbi.nlm.nih.gov/datasets/docs/v1/download-and-install/

To use it, as I have done below, you need a text file of all the accession codes you wish to fetch (I have called it `get_ass.txt`).

```bash
wget https://ftp.ncbi.nlm.nih.gov/pub/datasets/command-line/LATEST/linux-amd64/datasets
chmod +x ./datasets
./datasets download genome accession --inputfile get_ass.txt   --exclude-protein --exclude-rna --include-gbff  --exclude-genomic-cds  --exclude-seq
unzip ncbi_dataset.zip
```

For the _Acintobacter_ dataset I am using, some of the are not available ... for reasons.

```bash
Some of the assemblies provided (&apos;GCA_000580355.1&apos;, &apos;GCA_000580435.1&apos;) are valid NCBI Assembly Accessions,
but are not in scope for NCBI Datasets.
```

You can pull the assemblies out of the downloaded zip file to where ever you want. By default, it be in `ncbi_dataset/data`.

```python
from os import mkdir, path, listdir , getcwd
import shutil
getcwd()
if not path.exists(&apos;gen_fasta&apos;):
    mkdir(&apos;gen_fasta&apos;)
for fasta_path, name in [(path.join(&apos;ncbi_dataset/data&apos;,x), x) for x in listdir(&apos;ncbi_dataset/data&apos;) if x.startswith(&apos;GCA&apos;)]:
    fasta_file = [path.join(fasta_path, x ) for x in listdir(fasta_path) if x.endswith(&apos;.fna&apos;)]
    if fasta_file:
        shutil.copy(fasta_file[0], f&apos;gen_fasta/{name}.fasta&apos;)
```
</content>
  </entry>
  <entry>
    <title>In support of rMLST</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/support_for_rmlst"/>
    <id>https://happykhan.com/posts/support_for_rmlst</id>
    <published>2022-10-01T00:00:00.000Z</published>
    <updated>2022-10-01T00:00:00.000Z</updated>
    <summary type="text">There is a follow up post where I dive into the usage of rMLST and apply it futher to Acinetobacter.</summary>
    <content type="html">
There is a [follow up post](/posts/rmlst-in-acinetobacter) where I dive into the usage of rMLST and apply it futher to _Acinetobacter_.

I am a big fan of ribosomal MLST (rMLST) from [Jolley et al. 2012](https://pubmed.ncbi.nlm.nih.gov/22282518/). We used it extensively in calibrating cgMLST for _Salmonella_ and my then colleague, Zhemin Zhou, used it for designing subsequent EnteroBase cgMLST schemes.

rMLST is a genotyping scheme that uses the genes for the bacterial ribosome protein subunits (_rps_ genes). This is as close as you can get to a universal MLST scheme.
rMLST works on a diverse range of bacteria (like 16S) but provides deeper resolution beyond 16S in most species. See Figure 1 &amp; 2 in [Jolley et al. 2012](https://pubmed.ncbi.nlm.nih.gov/22282518/).

In _Salmonella_, rMLST was consistent with MLST. We performed a head to head comparison of eBGs (_Salmonella_ eBurst groups based on 7 gene MLST) with reBGs (_Salmonella_ eBurst groups based on rMLST)
and found the clustering from both methods consistent (Adj. Rand; 0.992). There were only six cluster groups that had major conflicts - which, on closer inspection, seemed to be consisted of
genomes affected by homologous recombination ([Alikhan et al. 2018](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1007261)).

By the way,

&gt; eBG (eBurst group) is a group of related STs based on single-linkage clustering, in which the distance between nodes is only one allele.
&gt; EnteroBase automatically adds new related STs to the most similar eBG unless they are one or two alleles distant from a second eBG.

eBGs are a simple way of describing natural genetic populations for _Salmonella_, which you can read about in [Achtman et al. 2012](https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1002776)

In every subsequent comparison I have done, rMLST cluster groups have been mostly consistent with core genome SNP phlyogenies. I find rMLST an incredibly useful starting point for exploring a species (or even an entire genus).

At a recent meeting (IMMEM13), I met many people who were looking to apply different approaches to capture population structure for species without MLST (or defective MLST) schemes. Some wanted to use
cgMLST or other complicated methods. I told them they could use any of those methods, but it was perhaps excessive for their purposes. Constructing and validating a cgMLST scheme can be a labourious process.
Although, when I finally suggested rMLST as a ready and able alternative, I was met with blank faces.

I have already described my case for why rMLST is a sensible approach, but I thought I would demonstrate rMLST on three genera without MLST (or with a defective MLST) schemes. These were genera mentioned to me at IMMEM and
include _Legionella_, _Acinetobacter_ and _Serratia_. I may embarrass myself in the process, as I have not worked with these particular genera before. _Acinetobacter_ has two MLST schemes, by the way, and only one of them has major issues as shown in [Gaiarsa et al. 2019](https://www.frontiersin.org/articles/10.3389/fmicb.2019.00930/full).

I should also mention here that rMLST database is not readily available in MLST tools like [Torsten&apos;s mlst](https://github.com/tseemann/mlst), but it is accessible through the [PubMLST website](https://pubmlst.org/bigsdb?db=pubmlst_rmlst_seqdef) for academic non commercial use only. It requires (free) registration and you need to
request access for the rMLST database specifically, but the process is fast and painless.

![Serratia with rMLST](./Serratia.png)

Above is a minimum spanning tree (GrapeTree) of rMLST profiles for the genus _Serratia_. Each node represents an &apos;rEBG&apos;; which is single-linkage clustering applied to rMLST STs. Nodes are collapsed when distance between profiles is two or less alleles. Edges between nodes are shown if the distance is less than 5 alleles.
Nodes are colour coded with species assignments provided by rMLST. Profiles here are a subset of all rMLST profiles available on [PubMLST](https://pubmlst.org/bigsdb?db=pubmlst_rmlst_seqdef). The tree was calculated using MSTree.py from [GrapeTree](https://github.com/achtman-lab/GrapeTree).

Species definition is defined by rMLST in this case, so the fact that it corresponds so well with rMLST is not that impressive. What is important is that there are a good number of rSTs defined in each species e.g. 172 in _S. marcessens_.
There is nothing worse than a genotyping scheme that simply lumps everything in a single sequence type. The fact that each species is clearly seperated is also a good indication that rMLST will be consistent with a robust phylogenetic
analysis. It is curious that _S. marcessens_ is split into at least three sub groups, but this is something for a _Serratia_ expert to comment on.

I repeat the same approach with _Acinetobacter_ below. The process and visualisation is exactly the same.

![Acinetobacter with rMLST](./Acineto.png)

This has similar promising signs as _Serratia_. Perhaps more so, since it looks similar to what I would find in _Salmonella_.

Finally, let us look at _Legionella_. The process and visualisation is exactly the same.

![Legionella with rMLST](legionella.png)

Ah! Now I am out of my depth. This is something I can not interpret. It is odd that the species _L. pneumophila_ is so disperse. I cannot say what this means. A _Legionella_ expert might know.

The figures above (at least the first two) are good suggestions that rMLST would be a ready and able genotyping scheme for these genera. To demonstrate this definitively, we would need to:

- Work with an expert for each of the genera. We need help assessing whether this makes sense.
- Take a representative set of genomes from each genus.
- Construct a core genome SNP phylogeny (and assume this as a gold standard).
- Compare tree topology with groupings from rMLST STs.

None of that is really that hard. **Would you like to get invovled?**

There is a [follow up post](/posts/rmlst-in-acinetobacter) where I dive into the usage of rMLST and apply it futher to _Acinetobacter_.
</content>
  </entry>
  <entry>
    <title>Drawing phylogenetic trees with Microreact</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/drawing-phylogenetic-trees-with-microreact"/>
    <id>https://happykhan.com/posts/drawing-phylogenetic-trees-with-microreact</id>
    <published>2022-08-30T00:00:00.000Z</published>
    <updated>2022-08-30T00:00:00.000Z</updated>
    <summary type="text">I make a lot of phylogenetic trees, and I have used a lot of different programs. In this post, I want to show you how to get the most out of the online visualization tool, Microreact, so you can draw publication ready figures. We will make a figure like this:</summary>
    <content type="html">
I make a lot of phylogenetic trees, and I have used a lot of different programs. In this post, I want to show you how to get the most out of the online visualization tool, [Microreact](https://microreact.org/), so you can draw publication ready figures. We will make a figure like this:

![The final tree](./final_mr_tree.png)

First, let&apos;s get some example data.

## Example data

I prefer to make worked examples from real data. Many common problems I encounter do not appear in simulated/toy datasets. To that end I have chosen some
genomes from _Salmonella enterica_ serovar Minnesota. I just randomly selected a group of genomes from EnteroBase. If you would like to know more, we discussed these in a recent publication: Alikhan et al. (2022)
PLoS Genet 18(6): e1010174. https://doi.org/10.1371/journal.pgen.1010174

The raw data is here if you want to follow along:

- [Table of metadata - tab delimited](/example_data/minne.06.22.tsv)
- [Phylogenetic tree - newick format](/example_data/minne.06.22.nwk)

# A basic tree with some metadata

When you go to the [Microreact website](https://microreact.org/), there is a link at the top to `upload` and from there you can drag and drop your tree (newick or nexus format) and your table of metadata onto the page.

![Drag and drop your files](./mr_drop.png)

It may ask you about which column is the ID. That is, which column should it use to link the labels in the tree file to the rows in the metadata. You do need to have at least one column in the metadata file that has the corresponding tip label in the tree file, otherwise the tree will be shown with no annotation. Once you choose the column the basic tree and metadata table will show up like below.

![The basic tree](./mr_basic_tree.png)

You can remove the map panel by clicking the `pencil` (top right), then `Edit existing panels` and then in the pop-up you can select the map panel and remove it. Some datasets benefit from the map view, but in this case the example data is quite sparse with the geographic information so we will ignore the map view here.

By default, the tree tips (the circles) are coloured by the ID, which is meaningless since they will all be unique. But before we get engrossed with creating our figure, let&apos;s figure out how we can export the images.

## Exporting figures from Microreact

![The top buttons](./the_top_buttons.png)

There is a very obvious download icon (downward arrow and a line) in the top right, and you may think that this is where you can download your figure. Surprise! It isn&apos;t. This button allows you to download the original uploaded files back, i.e. the metadata table and the tree file. This is useful, but not right now. You actually want the grey menu icon (3 lines), within the tree panel (see below).

![The correct download button](./mr_download_image.png)

Now, this only allows you to download the tree image itself. You also want the legend/key as well. This is under the legend panel on the right-hand side. The panel is usually hidden at first, so click `Legend` to show it. Again, like the tree, there is the menu icon and under that is the option to download the legend. So you will have two seperate files downloaded, one of the tree itself and the legend. I recommend that you download both in `.svg` and put the two together in either [Inkscape](https://inkscape.org/) or [Adobe Illustrator](https://www.adobe.com/uk/products/illustrator.html). I will admit that working with either Inkscape or Illustrator can be difficult to learn, so if you are in a rush you can export the two images as `.png` and put the two together in Powerpoint.

![Stitching the two figures together in Inkscape](./mr_tree_inkscape.png)

## Changing colours for the tips

In the example image above, where I am stitching the two figures together in Inkscape, you will notice that I am showing the Country of sample collection rather than the ID. To change this yourself, you click the eye icon in the top right and select `Country` as the `Colour Column`. Under `Colour Palette` you can change the choice of colours.

# The advanced tree

Now, how do we get the detailed tree with those columns of metadata I presented at the beginning? Next to the menu icon in the tree panel, there is another icon with showing sliders. If you click on this, a panel of more options appears.

![Sliders to select metadata blocks](./mr_sliders.png)

Under `Metadata blocks` you can select all the columns you want to show. If you are using the example data, the interesting columns are &apos;Collection Year&apos; and &apos;Lab Contact&apos;. The columns will appear next to the tree as soon as they are checked. The forked icon allows us to change the tree visualization itself, i.e. rectangular dendrogram, circular, radial, or hierarchical.

I have some tips on how to choose the best layout for your tree (based on the number of tips) in the section titled &apos;Choosing a layout&apos; in [Drawing phylogenetic trees in R (ggtree)](/posts/ggtree-start/).

Anyway, if we select hierarchical we get something like this:

![hierarchical tree with columns](./mr_tree_columns.png)

There are lot of options hidden in these new buttons like `Nodes and Labels`. If you want to show the label for each tip it is under `Nodes and labels` &gt; `Leaf labels`. Have fun playing around with all the different options. If you make a mess and want to reset, you can refresh the page and re-upload the original files.

Once you get used to the user interface, you can make a decent figure in a few minutes with what I have shown you.

## Controlling the colour palette

You can have fine control of the colour palette, although it&apos;s not immediately clear how to do this. In the example data, let&apos;s change the collection year to a continuous gradient. First, select &apos;Collection Year&apos; under the `Eye` (top right). Then under the `colour palette` change it to &apos;gradient&apos;, `number of steps`: &apos;continuous&apos; and then choose the colours you like. I chose the greyscale at the bottom. You will notice that by switching the gradient to continuous, the legend has also changed to show a continuous colour gradient rather than discrete boxes for each year.

We repeat the same process for each metadata column we wish to change. We click the `Eye`, choose the colour column, then change the palette. For &apos;Lab contact&apos; I chose &apos;Categorical&apos;, with number of colours as &apos;12&apos; and I picked one of the qualitative options.

![Colour palette options](./mr_palette.png)

As you do this, you&apos;ll notice that you are actually selecting the metadata column as the tip colour as well. It&apos;s a little confusing because you are using the interface that was likely designed to just change the tip colours and the feature of the metadata blocks was added later. It is workable if you just ignore the tip colours and concentrate on the metadata blocks. Once these have been settled, you can select the colour column that you would like for the tip labels and customise that last.

While you are doing this, you will notice the `Custom palette` toggle. If you activate this toggle, the panel will change allowing you to select individual colour for each value. A word of warning, however, _If you change the entire palette later, by untoggling `Custom palette` and choosing a new palette, all your custom colour selections will vanish!_ So, I strongly suggest you leave this step until the very end.

![Custom colour palette](./mr_custom.png)

Using the steps described above, we can create the figure I showed at the start.

![The final tree](./final_mr_tree.png)

Once the figure is as you like, you can save the exact state with the `Save` button in the top right. You have the option to export the whole thing as a JSON file that you can load back in later. Or you can save the project to your account and create a permenant link to the tree that you can put into your pubications. I have done this for the demo tree and if you want to see this interactive version of the final tree, you can visit
[https://microreact.org/project/happykhan-demo](https://microreact.org/project/happykhan-demo)

# Other tree visualization software

If [Microreact](https://microreact.org/) is not quite what you are looking for, then there are other software you can use, such as:

- [iTOL](https://itol.embl.de/)
- [Figtree](http://tree.bio.ed.ac.uk/software/figtree/)
- [GrapeTree](https://achtman-lab.github.io/GrapeTree/MSTree_holder.html)

And there are numerous libraries you can use in `R`, like `ggtree` that [I describe here](/posts/ggtree-start/).
</content>
  </entry>
  <entry>
    <title>The process of transforming data</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/the-process-of-transforming-data"/>
    <id>https://happykhan.com/posts/the-process-of-transforming-data</id>
    <published>2022-08-25T00:00:00.000Z</published>
    <updated>2022-08-25T00:00:00.000Z</updated>
    <summary type="text">Continuing from last time, what is bioinformatics, we are discussing which topics we need to know to understand bioinformatics. As per our definition,</summary>
    <content type="html">
Continuing from last time, [what is bioinformatics](/posts/what-is-bioinformatics), we are discussing which topics we need to know to understand bioinformatics. As per our definition,

&gt; Bioinformatics is the storage, manipulation, and presentation of data about biological systems until it becomes information.

So, it is a process of transforming one thing into another. **Input &gt; Transformation &gt; Output**. It is unlikely that the desired output will come from one round of transformation. For example, say we had a set of five input samples, from which we want to take some measurement of each sample and then produce a final summary. We would do:

![workflow](./z.drawio.png)

There are two things to note here. First, the &quot;measure value&quot; step should be agnostic to each input (input 1-5). It should take any input (given some assumptions) and measure the value. Second, &quot;Aggregate values&quot; does not operate on the raw input, but takes the output from each of the &quot;measure value&quot; steps and performs the required transformation. This seems simple, doesn&apos;t it? But many forget that this is all that ever happens, regardless of how complex the process seems to be. Our computation is never more than transforming input (with assumptions) into a desired output.

## Initial inputs

In bioinformatics, what counts as an initial input? The initial input can come from a range of source instruments. Every instrument has a bias and will introduce artefacts into its measurements. It is important to know these and how they affect your downstream analysis. This does not mean, however, that you need to know the instruments intimately, such that you could build one yourself. For me, I focus on microbial genomes (DNA/RNA). So understanding the machines and mechanisms that produce these types of data are important. These methods have been developed out of the molecular biology so it is helpful to know a little about that field too.  
Initial inputs can be drawn from other molecules (e.g. proteins/amino acids). Each of those in turn have different instruments. For others, spectroscopy or microscopy are the basis of their input data. In the end, regardless of the source, every instrument has a bias and will introduce artefacts into its measurements.

## Outputs

The intermediate outputs result from the input being transfomed. It is hopefully in line with what was expected. The ultimate output should be an answer to the original reason the data is being produced and analysed.

## The transformation process

Describing the transformation process is a difficult. It is not immediately intuitive and required understanding topics in computer science of which many are not familiar. My description of the _transformation_ may have reminded you of algorithms, which I mentioned previously with no explanation. Here is my definition:

&gt; An algorithm is a set of well-defined instructions, which, if followed, will consistently solve a particular problem. This problem is usually a mathematical one.

Deeply understanding mathematics is not a strict requirement for being able to do the computation in bioinformatics. Although, the example I want to show you is mathematical. Let&apos;s dissect a straight forward example of this transformation process.

The problem is to calculate the square root of a given number. This solution is an excellent example of computation and was first recorded by [Heron of Alexandria almost 2,000 years ago](https://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Babylonian_method). This raises an important point. The process of computation is much older than our modern electronic computers. Today, computation on a computer has two parts; first, solving the computation problem itself, and second giving the correct instructions to a computer. Let us concentrate on the first part.

Again, the problem is to calculate the square root of a given number. The solution, in plain language, is:

### How to calculate a square root of number S

- We assume the number (S) is a positive number.
- We guess a number (x) that we think is the square root (I usually just half the number S)
- We divide our original value by this guess (S / x)
- We add the guess to this fraction ( x + (S / x) )
- We divide the total by 2. ( ( x + (S / x ) ) / 2 )
- This value is our new guess, we can compare it to our old guess to see how much it has changed.
- If there is a drastic change, we repeat the procedure using the new guess instead. If the change is negligible, we have more or less converged on the true number and we stop.
- In theory, the more times we repeat this process, the closer we will reach the true value.

The mathematics wizards will write this procedure as:

![sqrt_root](./exp.png)

In the programming language (Python), it could be written as:

```python
def sqrt_heron(s, margin_of_error):
    previous_guess = 1.0
    current_guess =  0.5 * (1 + s)
    while abs(current_guess - previous_guess) &gt; margin_of_error:
        previous_guess = current_guess
        current_guess = 0.5 * (current_guess + s / current_guess)
    return current_guess
# if the change between the previous guess and the current
# guess is lower than the specified margin of error then
# the program halts and returns the best guess. I had
# mentioned this criterion in the written steps above.
```

I followed these steps by hand to calculate the square root of 80. My first guess was that the square root of 80 was 40. A calculator will tell you that the square root of 80 is 8.94427191. Let&apos;s see how the method fairs.

```maths
1. ((80 / 40) + 40) / 2  = 21
2. ((80 / 21) + 21) / 2  = 12.4
3. ((80 / 12.4) + 12.4) / 2  = 9.4
4. ((80 / 9.4) + 9.4) / 2  = 8.95
5. ((80 / 8.95) + 8.95) / 2  = 8.94
```

After five iterations, with some lazy rounding at each step, we have 8.94 as our best guess. The calculator&apos;s value is 8.94427191. That&apos;s a great result. Something that we computed by hand.

The key messages from this example are:

- Computation (algorithms) is about developing well-defined instructions to solve a problem and does not strictly mean working with a modern electronic computer.
- The square root method here takes an input value, transforms it, and produces a desired output. Bioinformatics is a series of such transformations.
- The method has assumptions about the input. For instance, negative numbers will not work. Inputs that are not a number will not work, e.g. What is the square root of the word &quot;eggplant&quot;?

The square root example was to show the process of **input &gt; transformation &gt; output**. Most bioinformaticians, and computer users in general, do not actually write this procedure out themselves. What we do is we look for an existing solution that has the desired output, and will accept our input. We do not actually care how the calculation is done. So perhaps, if we are directly using someone else&apos;s square root method that they later change to be faster somehow. As long as the name of the method that we call and the inputs do not change, we would never know.

We only need to assess the Inputs, assumptions around those inputs, and the Outputs. So more accurate use of the square root method would look like this:

```python
def square_root(input_value):
# Input: A number we wish to find the square root
# Assumptions: input will be a number, the number will be positive.
# Output: The square root of input, as a decimal number.
#
# I actually do not know, nor care, what happens in here.
#

# I just call the method above
square_root(9)
3

square_root(36)
6
```

If I was only interested in the square root of 9 and 36. I could use the program we wrote above or I could use a very flawed version like this one.

```python
def square_root(input_value):
	if input_value == 9:
		return 3
	if input_value == 36:
		return 6
	return None

square_root(9)
3

square_root(36)
6
```

We would argue that the second version is worst because it makes more assumptions about the input. The input for the second version can only be integers 9 and 36. Whereas for the first, applies to any positive number. However, if our input can only ever be 9 or 36, then this second implementation is perfectly suitable.

Concentrating on relevant aspects, such as Input and Output, and ignoring others, such as the specifics of how it is calculated, refers to a fundamental aspect of computer science, called [Abstraction](&lt;https://en.wikipedia.org/wiki/Abstraction_(computer_science)&gt;). Abstraction in computer science is such a critical topic, [I have written a specific section about it](/posts/abstraction-in-computer-science). There is a process of describing methods such that a person can use them without fully understanding what they are doing internally. The description will include, as a minimum, much of what we have already discussed.

- Input(s)
- Assumptions about the input(s)
- The layout of the output(s)
  It may also include an explanation of how long the method will take.

Where there is no such formal specification, a bioinformatician (or computer user generally) will need to take data where the input and corresponding output is known and run this through a method they wish to use. The method should give the expected results for all the test data to be acceptable. If no method can be found, then it may be required to actually program their own solution. It is only at this stage in bioinformatics that knowing how to program well becomes a strict requirement.

In the next section, I will refer all this back to microbial genomics and explain that in detail.
</content>
  </entry>
  <entry>
    <title>Creating AI generated images at home with Stable Diffusion</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/text-to-image-with-stable-diffusion"/>
    <id>https://happykhan.com/posts/text-to-image-with-stable-diffusion</id>
    <published>2022-08-23T00:00:00.000Z</published>
    <updated>2022-08-23T00:00:00.000Z</updated>
    <summary type="text">Stability.ai has just publicly released an open source text to image AI that you can download and run on your local consumer GPU. From the github:</summary>
    <content type="html">
[Stability.ai](https://stability.ai) has just publicly released an open source text to image AI that you can download and run on your local consumer GPU. From the [github](https://github.com/CompVis/stable-diffusion):

&gt; Stable Diffusion is a latent text-to-image diffusion model.

I have no idea what this means. All I know is that you give it some words and it tries to generate an image encorporating those words. This particular technology is limited. It can not render readable text. It cannot achieve true photorealism. It can not do a lot of things. It can, however, produce images that at a glance look suprisingly legitimate.

The [full annoucement is here](https://stability.ai/blog/stable-diffusion-public-release)

# How do I get access to this?

**You first need an account on [huggingface.co](https://huggingface.co/)**. Sign up is free, but you do need to verify your email. In this account, you need to mint a user access token, which you can do from this page [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens). You will use this token later to download the AI models.

If you can get to this point yourself, you&apos;re golden.

![Hugging face token](./huggingface.png)

**The software itself is all available as Python modules.** You need to install the following:

```bash
pip install diffusers transformers scipy
```

**You need to login into huggingface on the command-line**. It will prompt for the token that you just created on the website.

```bash
huggingface-cli login
```

**You can then generate images in python scripts by calling the `StableDiffusionPipeline` from `diffusers`.** In the sample script below, you can see the steps: download the model, switch to using the GPU, then feed in the prompts, and write the output image.

```python
import torch
from diffusers import StableDiffusionPipeline
from PIL import Image
from torch import autocast

prompts = [&quot;a gentleman otter in a 19th century portrait&quot;,
    &quot;Cat penguin&quot;,
    &quot;father speaking to son Fine Art&quot;]


# make sure you&apos;re logged in with `huggingface-cli login`
pipe = StableDiffusionPipeline.from_pretrained(&quot;CompVis/stable-diffusion-v1-4&quot;,
     use_auth_token=True)

print(&apos;Loaded model&apos;)
pipe = pipe.to(&quot;cuda&quot;)
generator = torch.Generator(&quot;cuda&quot;).manual_seed(200)

print(&apos;running...&apos;)
with autocast(&quot;cuda&quot;):
    for prompt in prompts:
      prompt = prompt.strip()
      image = pipe(prompt, num_inference_steps=100, generator=generator )[&quot;sample&quot;][0]
      prompt_filename = (prompt[:30] + &apos;..&apos;) if len(prompt) &gt; 30 else prompt
      output = prompt_filename.replace(&apos; &apos;, &apos;_&apos;).replace(&apos;,&apos;, &apos;&apos;) + &quot;.png&quot;
      print(f&apos;Saving image: {prompt} to {output}&apos;)
      image.save(output)
```

**Some things to note:**

- The `StableDiffusionPipeline.from_pretrained` will download the required models
  at runtime. This will take up ~5GB.
- You need to setup the authenication token at [huggingface.co](https://huggingface.co/).
- You could also feed the token in directly with `pipe = StableDiffusionPipeline.from_pretrained(&quot;CompVis/stable-diffusion-v1-4&quot;, use_auth_token=YOUR_TOKEN)`, rather than giving a boolean as I have done. This would allow you to skip the `huggingface-cli` step above.
- `torch.Generator(&quot;cuda&quot;).manual_seed(200)` allows you to choose the random seed.
- `num_inference_steps` is the number of iterations, the higher the more detail will be added to the resulting picture. This increases the runtime, and it does not mean that the picture will be better. If not specified it will run with the default value of `51`. The maximum number of iterations depends on the amount of GPU memory available.

I had a lot of help from this [Google Collab notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb), which explains more advanced topics like showing images on a grid and creating your own diffusers.

# Some of the glorious output

![A gentleman otter in a 19th century portrait](./a_gentleman_otter_in_a_19th_ce.png)

**prompt: a gentleman otter in a 19th century portrait**

![Cat penguin](./Cat_penguin.png)

**prompt: Cat penguin**

![Father speaking to son, Fine Art](./father_speaking_to_son_Fine_Art.png)

**prompt: father speaking to son, Fine Art**

![an ornate lighthouse rising from the sea](./an_ornate_lighthouse_rising_ou.png)

**prompt: an ornate lighthouse rising from the sea**

![medieval shops and towns](./medieval_shops_and_towns.png)

**prompt: medieval shops and towns**
</content>
  </entry>
  <entry>
    <title>Abstraction in computer science</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/abstraction-in-computer-science"/>
    <id>https://happykhan.com/posts/abstraction-in-computer-science</id>
    <published>2022-08-22T00:00:00.000Z</published>
    <updated>2022-08-22T00:00:00.000Z</updated>
    <summary type="text">You might have heard that the language of computers is binary (zeros and ones). You may have then wondered why when you using any of your devices there is nary a zero or one in sight. How do these devices that take our words and do anything useful? After all, a computer is a machine and has no understanding of anything.</summary>
    <content type="html">
You might have heard that the language of computers is binary (zeros and ones). You may have then wondered why when you using any of your devices there is nary a zero or one in sight. How do these devices that take our words and do anything useful? After all, a computer is a machine and has no understanding of anything.

There is a literal explanation of how your inputs to a computer are handled, which I will not explain here. Conceptually, the key idea is the process of Abstraction.

&gt; In software engineering and computer science, Abstraction is a process to hide details of a system or component that are irrelevant to its usage, to create abstract &quot;models&quot; or &quot;objects&quot; detached from their underlying implementation.

This is not an earth-shattering idea. We make these conceptual models mentally all the time. A common example is driving a car. To use a car to drive around, you do not need to understand the internal mechanics of a combustion engine. There are no cars with a transparent dashboard allowing you to see into the engine all the time. There&apos;s no need for this. This could even be distracting. You are able to drive as long as you understand how to use the input interface, like the steering wheel, pedals and gears, and you understand how to use these inputs to get the car to give your desired output. This process of abstraction is useful in other ways, for instance, we do not need to completely re-learn how to drive if we drive different models of cars.

In computing, this process of abstraction has been embraced so whole heartedly that we can comfortable use abstractions without thinking about the underlying mechanics at all. The process of building additional systems on top of others, without fully understanding them, is deeply embedded in computing. The YouTube channel Codexpanse has a [great explanation of Abstraction](https://youtu.be/_y-5nZAbgt4), expanding on what I have mentioned here. If you would like a more concrete example of how a program is executed, the YouTube channel [Computerphile has a concrete example of abstraction using of one the simplest programs](https://youtu.be/ycl1VL0q1rs). They use the example of &quot;Hello world&quot;, which is to print something to the screen, and show the number of hidden steps underneath required to produce this result.

# DNA Sequencing as an abstraction

These matters around abstraction are explicit in computer science, but we use models and abstractions all the time. As an example, let&apos;s consider DNA (Sanger) sequencing.

DNA sequencing does not directly produce a string of nucleotide characters (ATGC). In the case of Sanger sequencing, the raw measurements are presented in a chromatogram. A chromatogram represents the migration of labeled sequencing products via capillary electrophoresis. Fluorescence is detected at the end of the capillary, and signal intensity from four color channels, each representing a DNA base, is plotted on the y-axis relative to time on the x-axis.

We, aided with software, will take these raw readings and based off the signal intensity make a call on which base is found at each position. Each assigned base will have a quality value (QV), which is a measure of the certainty in that called base. The formula is:

&gt; QV = -10 × log (error probability)

This means that a QV of 20 means that there is a probability of error of 0.01 (1% chance the base is incorrectly called). As the scale is logarithmic, a QV of 10 means that the probability of error is 0.1 (10% chance of error), which is ten times higher than a QV of 20.

![Sequencing Chromatogram](./chromatagram.png)

Again, you can argue (and many have) that reducing the chromatogram to a single base call and a quality value is not enough information to fully convey the raw data. There are certainly edge cases where this level of abstraction can be misleading. Although, in most cases this is representation is sufficient and sequenced reads are often represented as just the base call and quality value.

These days, this format of providing a singular base call with measure of quality (usually reflecting confidence) has been adopted by high-throughput sequencing technologies (Illumina, PacBio, Nanopore). This is regardless of the underlying technology used to produce sequencing data. Again, this is an example of abstraction, and is useful as it makes sequencing data from different instruments interoperable (to some extent).
</content>
  </entry>
  <entry>
    <title>What do we truly need to know to do Bioinformatics</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/what-is-bioinformatics"/>
    <id>https://happykhan.com/posts/what-is-bioinformatics</id>
    <published>2022-08-21T00:00:00.000Z</published>
    <updated>2022-08-21T00:00:00.000Z</updated>
    <summary type="text">I work in the field of microbial genomics; we are interested in the genome of microbes. I specialise in using computers to analyse genomes. They call me a bioinformatician. These days, these skills are in demand. Sometimes people ask me what they would need to know to do what I do. I find it difficult to explain, because I did not do a degree in Bioinformatics. The field changes quickly, so it is difficult to give a firm answer.</summary>
    <content type="html">
I work in the field of microbial genomics; we are interested in the genome of microbes. I specialise in using computers to analyse genomes. They call me a _bioinformatician_. These days, these skills are in demand. Sometimes people ask me what they would need to know to do what I do. I find it difficult to explain, because I did not do a degree in _Bioinformatics_. The field changes quickly, so it is difficult to give a firm answer.

I have many conversations with experts in their own field (medicine, microbiology) who struggle with using Bioinformatics in their work. Giving them a superficial answer does not seem to help. For instance, I may be asked &quot;Which genome assembly program is the best?&quot;. Perhaps, they ask something more sophisticated like &quot;Which metrics do you use to determine a good genome assembly?&quot;. Although in explaining that I find there is some critical piece, they simply do not understand, which blocks them from moving forward - even with trivial tasks. Colleagues have encountered this problem as well, and many argue that the area of Bioinformatics is complex and requires specific training in computing. Some will go so far to argue that a user of Bioinformatics software must learn some level of computer programming. I disagree. I feel that there is some part of my mode of thinking, that if explained clearly, would be enough to help others get their work done.

Yes, of course, there are some areas and topics that truly are difficult. There are some areas that require a deep understanding of the data and the processes used to create them. These would require specialist skills, such as programming. That can be said for most disciplines. It is patronising when people point this out. Let us accept this as a given, but beyond that, there are parts of Bioinformatics that are unnecessarily obtuse. It is these areas I wish to clarify here.

So what are the concepts that a user, who has specific work to be done, needs to know to do Bioinformatics?

## What is Bioinformatics?

Let us start at the beginning. What is Bioinformatics?

Obscure. Bioinformatics is definitely obscure, as there are many definitions of what Bioinformatics actually encompasses. My definition leans on breaking down the word itself. Bio + Informatics. Hence,

&gt; Bioinformatics is the storage, manipulation, and presentation of data about biological systems; transforming data into information.

As far as my audience of microbiologists above, it is this that they really wanted to learn. It is this that I spend most of my time doing.

Some will argue that designing algorithms that facilitate these transformations is part of Bioinformatics, and it is. But being able to create these algorithms is not a mandatory skill for a user using Bioinformatics software. The algorithms just need to be understood well enough to allow the work to be done properly. I would shift such algorithm development under the banner of &quot;computational biology&quot; to make this distinction.

Within this defined scope of Bioinformatics, I will admit, the field is not a _-logy_ in the way biology is. It does not qualify as a major branch of knowledge. Many bioinformaticians will joke that Bioinformatics is just about converting data between file formats. In a reductive way, that&apos;s true, at least for what I do day-by-day. Our focus is engineering an effective solution for that data manipulation rather than, say, trying to test of a scientific hypothesis.

Indeed, anything approaching a _-logy_ in Bioinformatics is framed in the philosophy of other fields. Good Bioinformatics to the biologist is the solution that gives the best explanation to the biological question, regardless of the implementation. Whereas good Bioinformatics to the software engineer is the solution that gives a good explanation in the most computationally elegant way. Both assessments are rooted in the values of the respective field.

I am being deliberately strict with my definition of Bioinformatics because I am gearing this to a specific audience -- people who need to use it to get a specific task done. For a scholar exploring this area (e.g. a PhD student) I would relax my definition and include more topics about the fundermentals of computer science and biology.

With this definition done, we can then discuss the topics that need to be known to serve our specific goal. See the next section, [the process of transforming data](/posts/the-process-of-transforming-data)
</content>
  </entry>
  <entry>
    <title>Advice for PHD students and tips for the rest of us</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/phd-tips"/>
    <id>https://happykhan.com/posts/phd-tips</id>
    <published>2022-07-05T00:00:00.000Z</published>
    <updated>2022-07-05T00:00:00.000Z</updated>
    <summary type="text">When I was a doctoral student, I actively asked anyone I
could for advice about academia and being a scientist. It
has been seven years since my doctorate was awarded and
thinking back, these were the five single most useful
quotable pieces of advice I received. These were either
advice given directly given to me by my professors, or
recounted by fellow students. Many of these topics are very
complex. I will touch on them only briefly here.</summary>
    <content type="html">
When I was a doctoral student, I actively asked anyone I
could for advice about academia and being a scientist. It
has been seven years since my doctorate was awarded and
thinking back, these were the five single most useful
quotable pieces of advice I received. These were either
advice given directly given to me by my professors, or
recounted by fellow students. Many of these topics are very
complex. I will touch on them only briefly here.

These are not the most important things I learnt - but
those cannot be distilled into a single quote. Hopefully,
these single statements will help you.

### Keep firm boundaries

&gt; You&apos;re here from 9 to 5 and if you&apos;re not in the lab
&gt; you should be reading papers.

This was a relayed to a friend on their first day. This was
said to them as a hard reminder that a PhD candidature
should be treated like a job - where there are contracted
hours of work. I believe such boundaries are important to
understand if you are overworking yourself and neglecting
other parts of life. If you follow the nine-to-five advice
above and make it clear to your team that is how you work,
then no one (especially you) can say that you have not
applied the effort. During the work period, you can focus
on the tasks at hand. In your off-period, you can attend to
other matters and relax guilt free.

The exact timings may be different for different people and
will change over the course of a candidature. Have a
regular dialogue about working habits and timings with your
advisory team. Be deliberate with your working hours.
Manage expectations of when work will be completed, given
those timings. Sure, you can work after hours for the final
push of a manuscript or a set of experiments, but if this
workload is very demanding, then consider how to balance
this later. Perhaps you work Sunday morning, so you can
have a later start on Monday. Or perhaps you work hard for
a few weeks, so schedule easier work (or adjust deadlines)
for the week after so you can recover.

### Remember why you do what you do

&gt; The P in PHD means Philosophy, so philosophize.

PhDs start with a single broad question. As we delve deeper
into a PhD, we become more focused on details that serve
answering the broader topic rather than directly working on
the broader question itself. This is necessary to perform tractable
experiments with the project&apos;s time frame. PhD candidates
can spend a lot of time learning all the different
techniques to collect data, which are the best methods for a
situation, and how to optimise different methods in our
research. We usually apply these methods to one specific
facet, which is supposed to act as proxy for the question
at large.

But this leads to a common trap when a candidate writes
their dissertation. They frame their thesis - the singular
idea present in their work - with a narrow view that fits
within their day-to-day experience. Having looked so
closely at the matter for so long they cannot step back and
contextualise their project in the scope of the original,
lofty research question.

Remember, work exists in a wider dialogue about a science and
in the philosophy of a discipline. It is in this on which to
ruminate in the dissertation. It is important to talk to
other people outside your immediate peers and try to
explain your project so that you maintain the
perspective.

### Simplify your message

&gt; In a 15 minutes talk, present just one interesting
&gt; idea

A professor once explained to us how to structure a
scientific talk. Most talks are around 10-15 minutes. He
told us flatly that this is not a lot of time to explain an
entire project. His approach for a presentation was to pick
a single exciting and new result (presented as a figure on
one slide) and then spend the rest of the slides and time
explaining that figure.

It is easiest to frame your result as “if this then that”
or “in this group we see this and in that group we see that
because of something else”. Cause and effect. Or compare
and contrast. This is much easier for an outsider to
understand because, while they might not understand the
nuance, they can appreciate that something is changing and
there is a reason for it.
If your result is “Upregulation of gene X in species Y
causes phenotype Z”. You would have One (or two) slides
showing this result directly. But in presenting those two
slides alone, the audience has no context. You must
contexualise it by explaining the following::

- Introduction: What is species Y?
- Introduction: What is gene X?
- Introduction: What is the phenotype?
- Introduction: Why is this important?
- Introduction: How does this fit with our wider
  understand? (You may couch this in the wider context of your
  PhD project or the field generally)
- Aims: This isn&apos;t a question but you may want a slide to
  sum up all the motivations for the work (i.e. state your aims)
- Methods: How did you achieve this result? What was the
  method (briefly)?
- **The result**
- Discussion and conclusion: What are the limitations or
  caveats to the results and methods?
- Discussion and conclusion: What&apos;s the implication to what
  we know already and what are the next steps?

Answers for each of these questions could each be a slide.
And these answers, with the result itself, will fill your
time.

Anything that does not directly relate understanding the
figure can be cut, and usually has to be cut, to make the
time limit. The worst thing you can do in a presentation is
go over time.

### Make time your ally

&gt; Have you tried time management methods (like
&gt; Pomodoro)? I finished off three manuscripts that I have been stuck on for ages, in three
&gt; months.

One of my professors pointed out the value of time
management. These days, there are infinite distractions
with people and busy work vying for our attention. I feel
time management is crucial in a PhD candidature, where you
are often left to manage the day-to-day of the project. You
are, in effect, a project manager. And there are techniques
from project management that you can use to help. I want to
mention Pomodoro as one of those techniques of being able
to focus on a task and just get it done.

Pomodoro is a specific time management system, where it
breaks work hours into two-hour blocks where you work
solely on a single task for 25 minutes (no interruptions
allowed), then break for five minutes. You can opt to
continue that task or switch to something else. At the end
of two hours, you take a longer break and repeat the
process. This not only keeps you focused, but having the
breaks embedded allow your to give yourself a rest so that
you can sustain working for longer. There is a larger
philosophy to the system. For instance, you can use the
number of Pomodoros to complete a task to schedule how long
it can take, then adjust deadlines according. Over time you
can review the amount of work you have done and review
where your time is being spent. And when you feel you have
not done enough work in a week, you can look at your
Pomodoros and know that is not true.

I find it works well for writing and administrative tasks,
but not so much when you are a deep thought like
programming or deep writing. Those tasks require a certain
momentum (casually I would say that you need to be “in the
zone”) that the Pomodoro timings disrupts.

Time management is an entire discipline with many other
techniques. The field of study is well worth exploring.

### Perfection is the enemy of good

&gt; Have you heard the 90/10 rule? 90% of the work gets done
&gt; in 10% of the time and that last 10% of the work takes 90%
&gt; of the time.

I once attended a talk from a professor who was giving career advice to our student cohort.
As a self-proclaimed perfectionist, he explained that he had come to
accept the “90/10 rule” with reluctance. This realisation came
early in his career as he was engaged in a number of different
concurrent projects. The 90/10 rule basically
posits that the time to elevate something good to excellent
can be an onerous task. We do not have infinite time to
spend on a single piece of work. The more time we spend on
one work, the less time we have for the others. You need to
consider what you will accept as an acceptable first
iteration of the work and how much time you can afford. If
you can complete this with time to spare, then iterate
again to make it better. Setting personal deadlines for
tasks allows us to juggle all our different commitments and
ties back with better time management. Remember, in the
long run, it is better to have a few competent outputs
rather than one perfect one.
</content>
  </entry>
  <entry>
    <title>Conferences for microbial genomics, bioinformatics and microbiology</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/my-wishlist-of-conferences"/>
    <id>https://happykhan.com/posts/my-wishlist-of-conferences</id>
    <published>2022-07-02T00:00:00.000Z</published>
    <updated>2022-07-02T00:00:00.000Z</updated>
    <summary type="text">These are meetings that apply to my area of microbiology, genomics and bioinformatics.
These include meetings I have attended in the past, and recommend. Or other meetings that I have heard that are good.</summary>
    <content type="html">
These are meetings that apply to my area of microbiology, genomics and bioinformatics.
These include meetings I have attended in the past, and recommend. Or other meetings that I have heard that are good.

## Genome sequencing (molecular biology) focus

These meetings focus on the mechanics of sequencing technologies and other aspects of moelcular biology

**Sequencing, Finishing, and Analysis in the Future Meeting (SFA2F)**

An annual meeting dedicated to bringing together experts in the genomics field—including representatives from the
industries that serve this specialized scientific community. The SFA²F conference focuses on Next Generation
Sequencing technologies, applications, and their effect on the rapidly advancing field of genomics.

- Topics: Genome Sequencing, Genome Assembly, Genome Analysis, Applications of NGS
- Location(s): Sante Fe, NM, USA
- Upcoming and past dates: June 21-23, 2022
- URL: https://www.lanl.gov/conferences/sequencing-finishing-analysis-future/index.php

**Advances in Genome Biology and Technology (AGBT) - General meeting**

Genome science and technology conference where top global researchers, leaders and innovators meet to
announce new discoveries, cutting edge breakthroughs and to collaborate.

- Topics: Latest advances in DNA sequencing technologies, experimental and analytical approaches
  for genomic studies, and their myriad applications.
- Location(s): Orlando, FL, USA
- Upcoming and past dates: **February 6–9, 2023**; June 6-9 2022
- URL: https://www.agbt.org/events/general-meeting/

**London Calling**

Oxford Nanopore conference

- Topics: Oxford Nanopore
- Location(s): London, UK
- Upcoming and past dates: 18th - 20th May 2022
- URL: https://nanoporetech.com/lc22

## Computational biology and software engineering focus

These are meetings focusing on pure computational approachs, as they apply to genomics or microbiology.

**nf-core hackathon**

A virtual online hackathon to develop nf-core together

- Topics: nf-core, workflow languages
- Location(s): Virtual
- Upcoming and past dates: March 16-18, 2022
- URL: https://nf-co.re/events/2022/hackathon-march-2022

**Bioinformatics: From algorithms to applications**

Bioinformaticians and biologists to share experience in development and practical application of bioinformatics algorithms.

- Topics: Sequencing technologies, Molecular sequence analysis, Computational genomics, Genome assembly, Transcriptomics, Metagenomics, Agrigenomics, Viromics, CRISPR
- Location(s): Saint Petersburg, Russia
- Upcoming and past dates: July 12–15, 2021
- URL: https://biata2021.spbu.ru/

## Genomics and bioinformatics focus

These are applied meetings focus that focus on genomes and bioinformatics as it applies to microbiology.

**13th International Meeting on Microbial Epidemiological Markers (IMMEM XIII)**

Establishing whole genome sequencing at the core of epidemiological surveillance. Held every three years.

- Topics: Platforms for genome-based typing and epidemiology; Zoonosis, intensive food production and One Health; Genomic epidemiology of neglected pathogens; Metagenomics and Public Health
- Location(s): Bath, UK; Dubrovnik, Croatia (Usually somewhere in Europe)
- Upcoming and past dates: **14–17 September 2022**; 18-21 September 2019
- URL: https://www.escmid.org/dates_events/escmid_conferences/immem_xiii/

**Applied Bioinformatics &amp; Public Health Microbiology (ABPHM)**

A multidisciplinary forum to demonstrate how advances in microbial and viral genomics, bioinformatics, data science, and sequencing technology are being used to meet the needs of public health.
Held every two years.

- Topics: Bioinformatics showcase, COVID: lessons learned and future pandemic preparedness, Digital epidemiology, Environmental genomics for public health, Global public health genomics
- Location(s): Wellcome Genome Campus, Cambridge UK
- Upcoming and past dates: **03–05 May 2023**, 05–07 May 2021
- URL: https://coursesandconferences.wellcomeconnectingscience.org/event/applied-bioinformatics-and-public-health-microbiology-virtual-conference-20210505/

**Rapid Applied Microbial Next-Generation Sequencing and Bioinformatic Pipelines**

Explore how next-generation sequencing technology works and what it can do for you

- Topics: NGS in Clinical and Public Health Microbiology, Collecting and Sharing Microbial Genomic Data, Microbial Ecology, Microbes in Agricultural and Food Systems, Analytical Methods, Bioinformatic Tools and Pipelines ​
- Location(s): Baltimore, MD, USA; Washington, DC, USA
- Upcoming and past dates: **Oct. 16-19, 2022**
- URL: https://asm.org/Events/ASM-NGS/Home

**GA4GH Plenary meeting**

Advancing development work for the immediate data sharing needs of the genomics and health community community

- Topics: Data sharing
- Location(s): Virtual
- Upcoming and past dates: September 29 - September 30
- URL: https://broadinstitute.swoogo.com/ga4gh-8th-plenary

**Galaxy Community Conference**
Addressing common challenges in data intensive science using the Galaxy data integration and analysis platform.

- Topics: Galaxy, bioinformatics Pipelines
- Location(s): Minneapolis, United States
- Upcoming and past dates: July 17-23, 2022
- URL: https://galaxyproject.org/events/gcc2022/

## Microbiology focus

These meetings focus on microbiology (wet lab) and may have a genomics session

**BacPath**

BacPath is the Australian premiere biennial molecular bacteriology meeting that has an exclusive focus on bacterial pathogens.
We explore the full spectrum of molecular microbiology from fundamental research to translational applications. Held every two years.

- Topics: Bacterial pathogenesis
- Location(s): Brisbane, Australia
- Upcoming and past dates: **27- 30 September 2022**
- URL: https://www.bacpath.org/

**International Symposium Salmonella and Salmonellosis**

The attendees are from academic, governmental and industrial areas, all interested in Salmonella issues related to animal, plant, environmental and human health.

- Topics: _Salmonella_
- Location(s): Saint-Malo, France
- Upcoming and past dates: 20 - 22 June 2022
- URL: https://www.i3s2022.com/

**ASM Microbe**

Americian Society for Microbiology (ASM) general meeting

- Topics: Microbiology
- Location(s): Houston, TX, USA; Washington, DC, USA (Usually somewhere in USA)
- Upcoming and past dates: **June 15-19, 2023**; June 9-13,2022
- URL: https://asm.org/Events/ASM-Microbe/Home

**Microbiology Society Annual Conference 2022**

UK Microbiology Society general meeting

- Topics: Microbiology
- Location(s): Belfast, UK (Usually somewhere in UK)
- Upcoming and past dates: 04 - 07 April 2022
- URL: https://microbiologysociety.org/event/annual-conference/annual-conference-2022.html

**International workshop on *Campylobacter*, *Helicobacter* and Related Organisms (CHRO)**

Gather junior and senior investigators worldwide whose research encompassing all aspects of disease due to Campylobacter, Helicobacter and related organisms

- Topics: _Campylobacter_, *Helicobacter*, Host interation, Physiology and regulation, Pathogenesis, Epidemilogy, Evolution and ecology
- Location(s): Yangzhou, China
- Upcoming and past dates: **14-19 Nov 2022**
- URL: http://chro.bomeeting.net/46?lang=en
</content>
  </entry>
  <entry>
    <title>Drawing phylogenetic trees in R (ggtree)</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/ggtree-start"/>
    <id>https://happykhan.com/posts/ggtree-start</id>
    <published>2022-06-27T00:00:00.000Z</published>
    <updated>2022-06-27T00:00:00.000Z</updated>
    <summary type="text">Here are some notes on how to use R (specifically the ggtree package) to draw phylogenetic trees. In this first section, I will show:</summary>
    <content type="html">
Here are some notes on how to use `R` (specifically the `ggtree` package) to draw phylogenetic trees. In this first section, I will show:

- How to draw a basic tree, with coloured tips and tip labels.
- How to add a scale.
- A discussion on the different tree layouts

In other sections, I would like to cover how to make circular figures with heatmaps.

Firstly, what is `ggtree`?

&gt; ‘ggtree’ extends the ‘ggplot2’ plotting system which implemented the grammar of graphics. ‘ggtree’ is designed for visualization and annotation of phylogenetic
&gt; trees and other tree-like structures with their annotation data. https://github.com/YuLab-SMU/ggtree

## Example data

I prefer to make worked examples from real data. Many common problems I encounter do not appear in simulated/toy datasets. To that end I have chosen some
genomes from _Salmonella enterica_ serovar Minnesota. If you would like to know more, we discussed these in a recent publication: Alikhan et al. (2022)
PLoS Genet 18(6): e1010174. https://doi.org/10.1371/journal.pgen.1010174

The raw data is here if you want to follow along:

- [Table of metadata - tab delimited](/example_data/minne.06.22.tsv)
- [Phylogenetic tree - newick format](/example_data/minne.06.22.nwk)

This does not directly correspond to the Minnesota tree in the paper, so do not expect it to match.

# Making a basic tree with coloured tips

The most basic annotate tree with coloured tips for countries with an included key/legend and scale.
In terms of configuring the tree scale on `geom_treescale`:

- Position with x,y.
- Width is the length of the tree scale
- Offset is the relative position of the line and the text

```r
# FOR JUPYTER NOTEBOOKS!
options(repr.plot.width=7, repr.plot.height=7) ; par(oma=c(0,0,0,0))
# Change height/width to rescale your figure

# Load in metadata, it is tab delimited hence we use `sep`
info &lt;- read.csv(&quot;minne.06.22.tsv&quot;, sep=&quot;\t&quot;, header=TRUE)

# Load in the newick file
all_tree &lt;- read.tree(&quot;minne.06.22.nwk&quot;)
all_tree &lt;- root(all_tree, &apos;SAL_AB9236AA_AS&apos;) # This is an outgroup I picked for the tree.

# Just shrinking some long branches so it&apos;s clearer
# Don&apos;t distort your actual data this way without good reason.
all_tree$edge.length[all_tree$edge.length  &gt; 100  ]  &lt;- 100

p1 &lt;- ggtree(all_tree) %&lt;+% info +
    geom_tippoint(aes(color=Country)) + # Colour code the tips with country
    # Adding in a scale
    geom_treescale(x=0, y=45, fontsize=4, linesize=2, offset=2, width=10)

plot(p1)
```

![Basic tree](./basic_tree.png)

## Adding tip labels

Tip labels can be tricky. Some trees, like this example one, can look very cluttered when tip labels are shown. I do not believe
there is an easy fix for this. If you do encounter this problem you can try:

- Increasing the figure scale (**for JUPYTER notebooks**). You can rescale the figure with the repl options i.e. `options(repr.plot.width=7, repr.plot.height=7)`.
- Align the labels to the edge (shown below with `as_ylab`)
- Use a different tree layout. i.e. `ggtree(tree, layout=&quot;circular&quot;)`, see section below on &quot;Choosing a layout&quot;

For rectangular and dendrogram layouts you can use `as_ylab` to align all the labels to the edge.

```r
# FOR JUPYTER NOTEBOOKS!
options(repr.plot.width=7, repr.plot.height=7)

tip_label1 &lt;- p1 + geom_tiplab(size=2)
plot(tip_label1)

tip_label2 &lt;- p1 + geom_tiplab(size=2,  as_ylab=TRUE)
plot(tip_label2)
```

![Basic tree with tips](./basic_tree_tips.png)

![Basic tree with aligned tips](./basic_tree_tips_aligned.png)

# Choosing a layout

Different layouts have different benefits and drawbacks. Layouts can support different number of tips on the figure.
In general, rectangular displays the data most clearly, but circular layouts can fit more tips (and labels) before
it becomes cluttered. In practice I would start with a rectangular layout (like the basic sample above) and if it is too
cluttered, I would then try a circular layout.

There are other layouts, but I avoid these for different reasons. Of these, daylight and equal angle can look very
pretty but cannot show more than tens of tips. They also cannot indicate the root clearly, which can be a problem
for people who insist that all phylogenetic trees must have a root. I do not strictly agree with this. Phylogenies
can be used to just to illustrate which taxa cluster with which, and in that case an unrooted tree is fine.
The author, however, should clearly state they are not trying to determine which clade came first
(evolutionary speaking) but they are just illustrating that the clades are there.

Here are some limits to help you pick the best layout given the number of tips in the tree:

| Layout            | Max number of tips | Max number of tips (with labels) |
| ----------------- | ------------------ | -------------------------------- |
| Equal angle       | 50                 | 20                               |
| Daylight          | 100                | 50                               |
| Rectangle/slanted | 300                | 100                              |
| Circular          | 800                | 300                              |

You can also draw the tree ignoring branch lengths, which might make it easier to show the topology. e.g. `ggtree(tree, layout=&quot;daylight&quot;, branch.length = &apos;none&apos;)`.
In that case, be sure to state clearly that the branch lengths are not to scale.

See https://xiayh17.gitee.io/treedata-book/chapter4.html section 4.2.2 for different layouts you can choose.

## Examples without tip labels - with randomly generate tree data

```r
# FOR JUPYTER NOTEBOOKS!
options(repr.plot.width=7, repr.plot.height=7) ; par(oma=c(0,0,0,0))
# Change height/width to rescale your figure

my_tree = rtree(50)
ggtree(my_tree, layout=&quot;equal_angle&quot;) + geom_tippoint()

my_tree = rtree(100)
ggtree(my_tree, layout=&quot;daylight&quot;) + geom_tippoint()

my_tree = rtree(300)
ggtree(my_tree) + geom_tippoint()

my_tree = rtree(700)
ggtree(my_tree, layout=&quot;circular&quot;)  + geom_tippoint()
```

**Equal angle layout**
![equal angle layout](./eq.png)

**Daylight layout**
![daylight layout](./daylight.png)

**Rectangular layout**
![rectangular layout](./dendro.png)

**Circular layout**
![Circular layout](./circ.png)

## Examples with tip labels - with randomly generate tree data

```r
# FOR JUPYTER NOTEBOOKS!
options(repr.plot.width=7, repr.plot.height=7) ; par(oma=c(0,0,0,0))
# Change height/width to rescale your figure

my_tree = rtree(20)
ggtree(my_tree, layout=&quot;equal_angle&quot;) + geom_tiplab()

my_tree = rtree(50)
ggtree(my_tree, layout=&quot;daylight&quot;) + geom_tiplab()
my_tree = rtree(100)
ggtree(my_tree) + geom_tiplab(size=2)
my_tree = rtree(300)
ggtree(my_tree, layout=&quot;circular&quot;) +
    geom_tiplab(align=T, linetype=NA, size=2)
```

**Equal angle layout with labels**
![equal angle layout with labels](./eq_lab.png)

**Daylight layout with labels**
![daylight layout with labels](./daylight_lab.png)

**Rectangular layout with labels**
![rectangular layout with labels](./dendro_lab.png)

**Circular layout with labels**
![Circular layout with labels](./circ_lab.png)
</content>
  </entry>
  <entry>
    <title>The scientist&apos;s eight surefire steps to self sabotage</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/self-sabotage"/>
    <id>https://happykhan.com/posts/self-sabotage</id>
    <published>2022-06-24T00:00:00.000Z</published>
    <updated>2022-06-24T00:00:00.000Z</updated>
    <summary type="text">I saw an interesting video recently talking about Self Sabotage. It was talking about creative work generally,
but I see a lot of scientists with these habits. They even tell me these are good habits! Without realizing
that they are following the guidebook for &quot;How to Self Sabotage&quot;.</summary>
    <content type="html">
I saw an interesting video recently talking about Self Sabotage. It was talking about creative work generally,
but I see a lot of scientists with these habits. They even tell me these are good habits! Without realizing
that they are following the guidebook for &quot;How to Self Sabotage&quot;.

The video is here: https://www.youtube.com/watch?v=lKM2jE2PygY

And I wound up drafting a version for scientists.

## The scientist&apos;s eight surefire steps to self sabotage

1. For all you do: **be original, start from scratch**, never read the literature or talk to anyone. You might get scooped before you begin!. You cant plagiarize if you never read anything.
2. **Feel guilty**; Set the expectations so high with a time frame so impossible that you can feel guilty forever. That&apos;s how aspiration works!
3. **Perfection in Everything you do!** Things are only done when it&apos;s perfect. Not before. Even if it cripples your young collaborator&apos;s career (because they get no outputs).
4. **Do ALL the literature research first**, and then do more. If you don&apos;t know everything in the literature, How Dare you even attempt to write the introduction.
5. **Go big!** Forget that science is iterative and derivative. You have to work on the biggest challenge that is well outside your wheelhouse. This is the only way you can impress anyone. People only care how big your dreams are, and not on what you can deliver.
6. **Work in secret, do things completely by yourself**, and don&apos;t get feedback early on! Don&apos;t want to get scooped, right? Asking for help is a sign of weakness. Maintain creative control. You have to be an expert in everything to be successful.
7. **Compare yourself to the very best and successful**. Survival of the &quot;fittest&quot; right? If you&apos;re not number one, you&apos;re number none.
8. **Postpone gratification**, never celebrate the little things. Got to stay hungry. And whatever you achieved could have been better or done faster anyway, right?
</content>
  </entry>
  <entry>
    <title>The dark secret about containers in Bioinformatics</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/dark-secret-about-containers"/>
    <id>https://happykhan.com/posts/dark-secret-about-containers</id>
    <published>2022-06-23T00:00:00.000Z</published>
    <updated>2022-06-23T00:00:00.000Z</updated>
    <summary type="text">If you talk to your friendly neighbourhood bioinformatician (Binfie) these days, you might hear them mention &quot;containers&quot;, &quot;docker&quot;, and &quot;singularity&quot;.
They&apos;ll talk about these as if these are the greatest things since PCR. I am not different; we&apos;ve talked about containers at length on the Micro Binfie Podcast</summary>
    <content type="html">
If you talk to your friendly neighbourhood bioinformatician (Binfie) these days, you might hear them mention &quot;containers&quot;, &quot;[docker](https://www.docker.com/)&quot;, and &quot;[singularity](https://docs.sylabs.io/guides/2.6/user-guide/introduction.html#welcome-to-singularity)&quot;.
They&apos;ll talk about these as if these are the greatest things since PCR. I am not different; we&apos;ve talked about containers at length on the [Micro Binfie Podcast](https://soundcloud.com/microbinfie/staph-b-stable-containers)

What are we/they on about?

I will explain all here in this post, and reveal our deep dark secret about bioinformatics software development.

## Containers are designed for rapid software deployment

To fully understand what&apos;s going on, we need to talk about trends in software development generally, and then cross back to how that applies to bioinformatics.

There has been a growing trend in software development to use a rapid and iterative development cycle. It is [generally accepted](https://en.wikipedia.org/wiki/Rapid_application_development)
that it is easier to quickly create a prototype, test it, show it to a client for feedback and revisions, and then repeat the cycle. You might have heard cute phrases like &quot;Fail fast, succeed faster&quot; or &quot;aim for iteration,
not perfection&quot;. Agree or disagree, this is widely embraced in software engineering and any process that can help speed up this cycle of rapid deployment is considered a great boon.

This is where Containers come in. Containerisation is a form of virtualisation where you bundle the software you are working on, the development environment, and all the dependancies in a singular black box. The
container is run on top of a runtime engine that translate the inner working of the container to a range of different environments. Where ever the runtime engine can run, my
software can also run _regardless of the enviroment I have used for development_. For instance, if I write a piece of software on my Linux laptop and put it into a container,  
through the container runtime engine it can be run on someone else&apos;s computer whether it be a compute cluster, a MacOSX laptop or someone&apos;s
Windows machine. Yes, if you&apos;re thinking ahead, that means you could run bioinformatics software (developed solely for Linux) on a Windows machine.

![Container flowchart](./container.drawio.s.png)

For software developers this is very useful. It allows them to quickly stand up their software for clients to use and recieve rapid feedback. This could be an incredibly complex application
written with legacy code that can run anywhere; or it could be a web application that can could be automatically updated on a thousand different servers all over the world.
Most technology companies are internally using some form of containerisation / virutalisation somewhere in their development cycle. It is just too useful not to.

## Bioinformatics software is fragile and poorly designed

Now, how does that fit into bioinformatics? This comes back to our deep, dark secret - _Most Bioinformatics software is poorly written, relying on a complex and fragile stack of dependencies_.
These dependencies could be in any number of languages. A single pipeline could use a program written in C for the actual calculations, have some python scripts to shuffle the data around,
and then use some R for final plots and statistics. This is an incredible amount of bloated software to install for a singular task. If you&apos;ve ever asked yourself &quot;Does this really have
to be so hard to install? Am I just stupid?&quot;, the answer is No, it doesn&apos;t have to be this hard, and you are not stupid.

Indeed, we should streamline our software and make usability a priority. Software installation should be an easy &quot;point and click&quot; executable. There is a growing movement in
the field to address these issues, but it is slow going. We are rarely funded to improve software usability.

In the meantime, containers allows us Binfies to hid all of that ugly and fragile &quot;academic&quot; code we write in a neat singular black box for you to enjoy.

![Container slide](./container_slide.jpg)

## Further reading

If you want to learn more about containers and how to use them there is material from a recent workshop I co-chaired, BIOINFORMATICS SKILLS
FOR MICROBIAL GENOMICS, about `conda`, containers and workflow languages: https://www.climb.ac.uk/bioinformatics-skills-microbial-genomics/

If you want to use (docker) containers, STAPH-B has a great set of pre-built ones ready for you: https://github.com/StaPH-B/docker-builds
</content>
  </entry>
  <entry>
    <title>Variations on map projections in R</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/map-projections-in-r"/>
    <id>https://happykhan.com/posts/map-projections-in-r</id>
    <published>2022-05-20T00:00:00.000Z</published>
    <updated>2022-05-20T00:00:00.000Z</updated>
    <summary type="text">In this example we will:</summary>
    <content type="html">
In this example we will:

- Use some crazy projections
- Do some themeing for our maps

Inspired by https://xkcd.com/977/

**Requirements:**

- `R`
- `ggplot2`
- `sf`
- `rnaturalearth`
- `lwgeom`
- `cowplot`
- `rnaturalearthhires`
- `rnaturalearthdata`

If you have difficulties installing `rnaturalearth` and `sf` natively on your system,
I have found it possible by installing `R` and the packages in a `conda` environment.
I explain [how to do this, here](/posts/conda-install-r).

This post is part of a series about making maps in R:

- [Making a map in R](/posts/making-a-map-in-r)
- [Advanced map making in R](/posts/advanced-map-making-in-r)
- [Variations on map projections in R](/posts/map-projections-in-r)

# Getting started

```r
library(&quot;rnaturalearth&quot;)
library(&quot;ggplot2&quot;)
library(sf)
library(lwgeom)
library(cowplot)

# You also need to install rnaturalearthhires for this to work.
# devtools::install_github(&quot;ropensci/rnaturalearthhires&quot;)
# devtools::install_github(&quot;ropensci/rnaturalearthdata&quot;)

# Get some data to put on the map

label_frame &lt;- data.frame(&quot;Label&quot; = c(&quot;Brisbane&quot;, &quot;Perth&quot;), &quot;Lat&quot; = c(-27.4705, -31.9523), &quot;Lon&quot; = c(153.0260, 115.8613))
label_frame &lt;- st_as_sf(x=label_frame, coords = c(&quot;Lon&quot;, &quot;Lat&quot;), crs = &quot;EPSG:4326&quot;)
```

# Projections in R

I will post the projection and the R script stuff below it.

## Van der Grinten (4)

![Van der Grinten](./vandergrinten.png)

```r
options(repr.plot.width=12, repr.plot.height=8)

world_sf &lt;- ne_countries(returnclass = &quot;sf&quot;)

# Themed with minimal grid from cowplot

world &lt;- ggplot() +
    geom_sf(data = world_sf )  +
    ggtitle(&quot;van der Grinten IV&quot;)+
  theme_minimal_grid()+
    coord_sf(crs= &quot;+proj=vandg4&quot;)
world
```

## Robinson Projection

![Robinson projection](./robinson.png)

```r
world_sf &lt;- ne_countries(returnclass = &quot;sf&quot;)

world &lt;- ggplot() +
    geom_sf(data = world_sf, fill= &quot;antiquewhite&quot;)  +
    geom_sf_label(data = label_frame, aes(label = Label)) +
    coord_sf(crs= &quot;+proj=robin&quot;) +
    theme_minimal_grid() +
    ggtitle(&quot;Robinson projection&quot;)
world
```

## Winkel triple projection

![Winkel triple projection](./winkel.png)

From: https://wilkelab.org/practicalgg/articles/Winkel_tripel.html

```r

crs_wintri &lt;- &quot;+proj=wintri +datum=WGS84 +no_defs +over&quot;
world_wintri &lt;- st_transform_proj(world_sf, crs = crs_wintri)

grat_wintri &lt;-
  st_graticule(lat = c(-89.9, seq(-80, 80, 20), 89.9)) %&gt;%
  st_transform_proj(crs = crs_wintri)


ggplot(world_wintri) +
  geom_sf(size = 0.5/.pt) +
  geom_sf(data = grat_wintri, color = &quot;gray30&quot;, size = 0.25/.pt) +
  coord_sf(datum = NULL) +
  theme_map() +
    ggtitle(&quot;Winkel tripel projection&quot;)
```

## Interrupted Goode Homolosine projection

![Interrupted Goode Homolosine projection](./goode.png)

From https://wilkelab.org/practicalgg/articles/goode.html

```r

options(repr.plot.width=12, repr.plot.height=8)

world_sf &lt;- ne_countries(returnclass = &quot;sf&quot;)
crs_goode = &quot;+proj=igh&quot;

# projection outline in long-lat coordinates
lats &lt;- c(
  90:-90, # right side down
  -90:0, 0:-90, # third cut bottom
  -90:0, 0:-90, # second cut bottom
  -90:0, 0:-90, # first cut bottom
  -90:90, # left side up
  90:0, 0:90, # cut top
  90 # close
)
longs &lt;- c(
  rep(180, 181), # right side down
  rep(c(80.01, 79.99), each = 91), # third cut bottom
  rep(c(-19.99, -20.01), each = 91), # second cut bottom
  rep(c(-99.99, -100.01), each = 91), # first cut bottom
  rep(-180, 181), # left side up
  rep(c(-40.01, -39.99), each = 91), # cut top
  180 # close
)

goode_outline &lt;-
  list(cbind(longs, lats)) %&gt;%
  st_polygon() %&gt;%
  st_sfc(
    crs = &quot;+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs&quot;
  )

goode_outline &lt;- st_transform(goode_outline, crs = crs_goode)

# get the bounding box in transformed coordinates and expand by 10%
xlim &lt;- st_bbox(goode_outline)[c(&quot;xmin&quot;, &quot;xmax&quot;)]*1.1
ylim &lt;- st_bbox(goode_outline)[c(&quot;ymin&quot;, &quot;ymax&quot;)]*1.1

# turn into enclosing rectangle
goode_encl_rect &lt;-
  list(
    cbind(
      c(xlim[1], xlim[2], xlim[2], xlim[1], xlim[1]),
      c(ylim[1], ylim[1], ylim[2], ylim[2], ylim[1])
    )
  ) %&gt;%
  st_polygon() %&gt;%
  st_sfc(crs = crs_goode)

# calculate the area outside the earth outline as the difference
# between the enclosing rectangle and the earth outline
goode_without &lt;- st_difference(goode_encl_rect, goode_outline)

world &lt;- ggplot(data = world_sf) +
  geom_sf(size = 0.5/.pt) +
  geom_sf(data = goode_without, fill = &quot;white&quot;, color = &quot;NA&quot;) +
  coord_sf(crs = crs_goode) +
  theme_minimal_grid()+
    ggtitle(&quot;Interrupted Goode Homolosine projection&quot;)
world
```

# Hobo Dyer projection

A lot of these projections like Gall Peters and Hobo Dyer are Equal Area Cylindrical projections with specific settings.

![Hobo Dyer projection](./hobo.png)

```r
options(repr.plot.width=12, repr.plot.height=8)

world_sf &lt;- ne_countries(returnclass = &quot;sf&quot;)

world &lt;- ggplot() +
    geom_sf(data = world_sf, color = &quot;grey&quot;, fill = &quot;black&quot;)  +
    ggtitle(&quot;Hobo Dyer projection&quot;)+
  theme_map()+
    coord_sf(crs= &quot;+proj=cea +lon_0=0 +lat_ts=37.5 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs&quot;)
world

```

## Equidistant Cylindrical (Plate Carrée)

![Equidistant Cylindrical (Plate Carrée)](./plate.png)

```r
options(repr.plot.width=12, repr.plot.height=8)

world_sf &lt;- ne_countries(returnclass = &quot;sf&quot;)

world &lt;- ggplot() +
    geom_sf(data = world_sf)  +
    ggtitle(&quot;Equidistant Cylindrical (Plate Carrée)&quot;) +
  theme_minimal_grid()+
    coord_sf(crs= &quot;+proj=eqc&quot;) +
    theme(panel.grid.major = element_line(color = gray(.5), linetype = &quot;dashed&quot;, size = 0.5),
          panel.background = element_rect(fill = &quot;aliceblue&quot;))
world
```

## Globes!

A lot of options for a globe Orthographic (`+proj=ortho`) works fine but the proportions look a bit flat.

- Geostationary Satellite View : `+proj=geos +h=35785831.0 +lon_0=-70 +sweep=y`
- There&apos;s also Near-sided perspective: `+proj=nsper +h=3000000 +lat_0=-23 +lon_0=130`
- Lambert azimuthal equal-area projection is another option

![Near-sided perspective](./near.png)

![Geostationary Satellite View](./geo.png)

![Lambert azimuthal equal-area projection](./lambert.png)

```r
options(repr.plot.width=12, repr.plot.height=8)

world_sf &lt;- ne_countries(returnclass = &quot;sf&quot;)

world &lt;- ggplot() +
    geom_sf(data = world_sf)  +
    ggtitle(&quot;Near-sided perspective&quot;) +
  theme_minimal_grid()+
    coord_sf(crs= &quot;+proj=nsper +h=3000000 +lat_0=-23 +lon_0=130&quot;)

world


world &lt;- ggplot() +
    geom_sf(data = world_sf)  +
    ggtitle(&quot;Geostationary Satellite View&quot;) +
  theme_minimal_grid()+
    coord_sf(crs= &quot;+proj=geos +h=35785831.0 +lon_0=20 +sweep=y &quot;)

world

world &lt;- ggplot() +
    geom_sf(data = world_sf)  +
    ggtitle(&quot;Lambert azimuthal equal-area projection&quot;) +
  theme_minimal_grid()+
    coord_sf(crs= &quot;+proj=laea +x_0=0 +y_0=0 +lon_0=-74 +lat_0=40&quot;)
world
```

# Peirce Quincuncial &amp; Waterman butterfly

Doesn&apos;t really work, I don&apos;t think it is supported.
Someone implemented something for R here: https://github.com/cspersonal/peirce-quincuncial-projection

Waterman butterfly is also not implemented either.

![Peirce Quincuncial](./pierce.png)

```r
world &lt;- ggplot() +
    geom_sf(data = world_sf)  +
    ggtitle(&quot;Peirce Quincuncial&quot;) +
    coord_sf(crs= &quot;+proj=peirce_q +lon_0=25 +shape=square&quot;)

world
```

## Gall Peters projection

A lot of these projections like Gall Peters and Hobo Dyer are Equal Area Cylindrical projections with specific settings.

![Gall-Peters projection](./gall.png)

```r
world &lt;- ggplot() +
    geom_sf(data = world_sf)  +
    ggtitle(&quot;Gall Peters projection&quot;) +
  theme_minimal_grid()+
    coord_sf(crs= &quot;+proj=cea +lon_0=0 +x_0=0 +y_0=0 +lat_ts=45 +ellps=WGS84 +datum=WGS84 +units=m +no_defs&quot;)

world
gall.png
```
</content>
  </entry>
  <entry>
    <title>Advanced map making tricks for R (projections, choropleths and showing specific regions)</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/advanced-map-making-in-r"/>
    <id>https://happykhan.com/posts/advanced-map-making-in-r</id>
    <published>2022-05-18T00:00:00.000Z</published>
    <updated>2022-05-18T00:00:00.000Z</updated>
    <summary type="text">In this example we will:</summary>
    <content type="html">
In this example we will:

- Look at `rnaturalearth`
- Make a choropleth
- Play with projections a bit more.

**Requirements:**

- `R`
- `ggplot2`
- `sf`
- `rnaturalearth`
- `ggrepel`
- `dplyr`
- `ggsflabel`
- `rnaturalearthhires`
- `rnaturalearthdata`

If you have difficulties installing `rnaturalearth` and `sf` natively on your system,
I have found it possible by installing `R` and the packages in a `conda` environment.
I explain [how to do this, here](/posts/conda-install-r).

This post is part of a series about making maps in R:

- [Making a map in R](/posts/making-a-map-in-r)
- [Advanced map making in R](/posts/advanced-map-making-in-r)
- [Variations on map projections in R](/posts/map-projections-in-r)

# Pulling out a specific country/region with rnaturalearth

```r
library(&quot;rnaturalearth&quot;)
# You also need to install rnaturalearthhires for this to work.
# devtools::install_github(&quot;ropensci/rnaturalearthhires&quot;)
# devtools::install_github(&quot;ropensci/rnaturalearthdata&quot;)
au_sf &lt;- ne_states(geounit = &quot;australia&quot;,
                   returnclass = &quot;sf&quot;)
plot(au_sf)

```

![rnaturalearth output](./natural_data.png)

# Some example data to show on our map

I found some numbers for the percentage of people in Australia who live in the capital
for each state. If you didn&apos;t know, despite Australia being so big, most people live in
one of the state capitals.

```r
options(repr.plot.width=10, repr.plot.height=6)
states &lt;- c(&quot;Australian Capital Territory&quot; ,&quot;New South Wales&quot;,
            &quot;Northern Territory&quot;, &quot;Queensland&quot;, &quot;South Australia&quot;, &quot;Tasmania&quot;,
            &quot;Victoria&quot;, &quot;Western Australia&quot;)

pop_in_cap &lt;- c(99.6, 63.0, 54.0, 46.0, 73.5, 41.0, 71.0, 73.4)
df &lt;- data.frame(states, pop_in_cap)
df
# Let&apos;s plot it just to see what we are working with.
ggplot(data=df, aes(x=states, y=pop_in_cap, fill=states)) +
    geom_bar(stat=&quot;identity&quot;) +
    ylab(&quot;Population in capital&quot;) +
    xlab(&quot;State&quot;) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

![Au population in cities for each state](./au_pop_table.png)

![Au population in cities for each state](./au_pop_chart.png)

# Chrolopeth map

From Wiki:

&gt; A choropleth map is a type of statistical thematic map that uses intensity of color to
&gt; correspond with an aggregate summary of a geographic characteristic within spatial enumeration units,
&gt; such as population density or per-capita income.

So this is basically, a map with a heatmap. You would have seen these before. One of the ones I&apos;ve been looking at a lot (because of Covid19) is the [lineage map from Sanger](https://covid19.sanger.ac.uk/lineages/raw)

Let&apos;s try to make one with our sample data.

```r
library(&quot;ggplot2&quot;)
library(&quot;rnaturalearth&quot;)
library(&quot;dplyr&quot;)
library(ggrepel)
library(sf)
options(repr.plot.width=15, repr.plot.height=8)
in_sf &lt;- ne_states(geounit = &quot;australia&quot;,
                   returnclass = &quot;sf&quot;)

in_sf_label &lt;- in_sf  %&gt;% filter(name != &quot;Lord Howe Island&quot;, name != &quot;Macquarie Island&quot;, name != &quot;Jervis Bay Territory&quot;)
# Let&apos;s ignore some small regions

in_sf &lt;- in_sf %&gt;% select(name) %&gt;%
  left_join(. , df, by=c(&quot;name&quot;=&quot;states&quot;))

in_sf$pop_in_cap[ is.na(in_sf$pop_in_cap)] = 0

australia &lt;- ggplot() +
    geom_sf(data = in_sf, aes(fill = pop_in_cap))  +
  geom_label_repel(data = in_sf_label,
                   aes(x=longitude,y = latitude, label = name),
                   size = 3, force = 5, force_pull = 5)
australia
```

![Au population in cities for each state](./au_cho.png)

# Map projections in R

[Previously we used the baked in map projections](/posts/making-a-map-in-r) from `ggplot` using `coord_map()`. Now I will try to customise it as we like.
Map projections are intensely complicated, and I frankly have no idea what I am doing.

The trick here is that internally everything we are looking at is just a vector graphic and to add in something like a map projection we need to transform the shapes to fit that projection. In the next few examples I will use `coord_sf()` to take our ggplots and transform them to show a projected map.

## Standardised projections with EPSG

Rather than having to figure out all the settings yourself, people have created templates you can use.
These have been picked to be the best compromise between showing something sensible while being true
to the proportions of the different land masses. It is quite difficult to show something that is
round - like the Earth - on a flat plane.

The one I found to be useful is the EPSG:

&gt; The EPSG is a structured dataset of CRS and
&gt; Coordinate Transformations. It was originally compiled by
&gt; the, now defunct, European Petroleum Survey Group. Here
&gt; are some websites: https://epsg.io/ &gt; http://spatialreference.org/

There are different projections for different regions all over the world. There are many options
depending on which region you want to show, and the type of projection you would like to use.

For Australia, for instance, I found these to be common:

- EPSG:3857 &quot;WGS 84 (ensemble) / Pseudo-Mercator (Web Mercator)&quot; https://epsg.io/3857 - Most common!
- EPSG:3577 &quot;GDA94 / Australian Albers&quot; (My favourite) https://epsg.io/3577
- EPSG:4203 &quot;AGD84&quot; https://epsg.io/4203-1236

Let&apos;s see what the difference would be.
This is your standard Mercator (should look like google maps)

```r
australia &lt;-  ggplot() +
    geom_sf(data = in_sf, aes(fill = pop_in_cap)) +
    coord_sf(crs= 3857)
australia
```

![Au population in cities for each state](./au_merc.png)

This next one is with a bit curvature, but you can still recognize all the states. I like it.
Can you see the difference to the one above?

```r
australia &lt;-  ggplot() +
    geom_sf(data = in_sf, aes(fill = pop_in_cap)) +
    coord_sf(crs= 3577)
australia
```

![Au population in cities for each state](./au_proj.png)

This last one is supposed to be a &quot;Geocentric translations (geog2D domain)&quot; centering on Western Australia (right).

```r
australia &lt;-  ggplot() +
    geom_sf(data = in_sf, aes(fill = pop_in_cap)) +
    coord_sf(crs= 8017)
australia
```

![Au population in cities for each state](./au_weird_proj.png)

## Custom settings and PROJ

You can fully customise the map and the projection using the &quot;PROJ&quot; strings. https://proj.org/index.html

This is a deep rabbit hole though, and it can get weird. So I would recommend
sticking to the standards above. Let&apos;s look at a few custom projections.

```r
australia &lt;-  ggplot() +
    geom_sf(data = in_sf, aes(fill = pop_in_cap)) +
  geom_label_repel(data = in_sf_label,
                   aes(x=longitude,y = latitude, label = name),
                   size = 3, force = 5, force_pull = 5) +
  coord_sf( crs= &quot;+proj=ortho  +lat_0=-30 +lon_0=133&quot;)
australia
```

![Au population in cities for each state](./custom_proj.png)

Nothing too special here, orthographic like above and The lat long settings are basically centring on the middle of the nation
Let&apos;s look at a another one.

```r
australia &lt;-  ggplot() +
    geom_sf(data = in_sf, aes(fill = pop_in_cap)) +
  coord_sf( crs= &quot;+proj=latlong  +lat_0=-30 +lon_0=133&quot;)
australia
```

![Au population in cities for each state](./proj_flat.png)

This is the same map like before but it has a normal (flat) conversion of lat and long.
Let&apos;s try a strange one.

```r
australia &lt;-  ggplot() +
    geom_sf(data = in_sf, aes(fill = pop_in_cap)) +
  coord_sf( crs= &quot;+init=epsg:3577 +proj=ortho +ellps=GRS80
+datum=GGRS87&quot;)
australia
```

![Au population in cities for each state](./proj_weird.png)

This is _EPSG:3577, orthographic projection and an Ellipsoid specified_

Here are all the parameters you can feed through the proj string

| Param   | Description                                      |
| ------- | ------------------------------------------------ |
| +a      | Semimajor radius of the ellipsoid axis           |
| +b      | Semiminor radius of the ellipsoid axis           |
| +datum  | Datum name                                       |
| +ellps  | Ellipsoid name                                   |
| +lat_0  | Latitude of origin                               |
| +lat_1  | Latitude of first standard parallel              |
| +lat_2  | Latitude of second standard parallel             |
| +lat_ts | Latitude of true scale                           |
| +lon_0  | Central meridian                                 |
| +over   | Allow longitude output outside -180 to 180 range |
| +proj   | Projection name                                  |
| +south  | Denotes southern hemisphere UTM zone             |
| +units  | meters                                           |
| +x_0    | False easting                                    |
| +y_0    | False northing                                   |
| +zone   | UTM zone                                         |

See https://proj.org/index.html for details

# Adding labels and annotations

Let&apos;s use the weird map projection from before and try to pin some cities on the map.

It&apos;s not clearly explained in a lot of tutorials how to do this. Usually they do not apply any projection - the map is a flat mercator map - and if that is the case you can just feed in the lat/lon as X, Y co-ords and everything works out (like the first map I made).

When we do work with projections, things change. When we specify a set of co-ordinates we also need to specify what projection those co-ordinates are based on. After playing around with it for a while, it seems that is it best to ALWAYS be explicit about the projection settings, which means that when you import or create any set of co-ordinates to put on a map you should also specify the `crs`.

I have rationalised it as such; If I tell you that Brisbane&apos;s longitude is 153.0260, what is that in reference to? For instance, where is 0\* in this case? We usually mean Grenwich is 0 but that is not always the case, and when ever we use projections in R all those assumptions are thrown out the window. I will try to illustrate that below:

```r
label_frame &lt;- data.frame(&quot;Label&quot; = c(&quot;Brisbane&quot;, &quot;Perth&quot;), &quot;Lat&quot; = c(-27.4705, -31.9523), &quot;Lon&quot; = c(153.0260, 115.8613))

label_frame &lt;- st_as_sf(x=label_frame, coords = c(&quot;Lon&quot;, &quot;Lat&quot;), crs = &quot;EPSG:4326&quot;)
st_is_longlat(label_frame)

label_frame$geometry

# This is our weird projection from above.
this_crs = &quot;+init=epsg:3577 +proj=ortho +ellps=GRS80
+datum=GGRS87&quot;

st_transform(label_frame, this_crs)

```

![Tranforming our coords](./transform_geom.png)

Let us step through it. First, I have created a crude dataframe of two city locations.

The `st_as_sf` takes our raw co-ord numbers and converts it into a geometry point.
This not only has our lat / long info, but also the projection infomation (`crs`).
Because these are _normal_ lat/longs I have used a standard EPSG specification
which is &quot;EPSG:4326, WGS 84 -- WGS84 - World Geodetic System 1984, used in GPS&quot;.
A _normal_ map; Grenwich is 0 etc. etc.

To check everything is ok, we can use `st_is_longlat` to check if it is the correct format.
Sometimes if the `crs` is invalid, it will silently fail and keep lon/lat the same,
you then run into problems when you try to plot the values.

If we see what this looks like before we transform, the geometry information is still recognisable as a `normal` lat/long.

We then use `st_transform` to convert the co-ordinates into our weird projection.

When we look at the new co-ords, the x, y coords are now totally different, e.g. Brisbane&apos;s co-ords
go from `POINT (153.026 -27.4705)` to `POINT (2031772 -2924851)`.

In practice we don&apos;t need to do the `st_transform` ourselves when we are plotting.
`coord_sf` will apply the transformations to every layer in the ggplot. We just need to be careful about
making sure that the data points we give are in the correct format, and have a projection specified. See the example below.

```r
this_crs = &quot;+init=epsg:3577 +proj=ortho +ellps=GRS80+datum=GGRS87&quot;

label_frame &lt;- data.frame(
    &quot;Label&quot; = c(&quot;Brisbane&quot;, &quot;Perth&quot;),
    &quot;Lat&quot; = c(-27.4705, -31.9523),
    &quot;Lon&quot; = c(153.0260, 115.8613))

label_frame &lt;- st_as_sf(x=label_frame, coords = c(&quot;Lon&quot;, &quot;Lat&quot;), crs = &quot;EPSG:4326&quot;)

australia &lt;-  ggplot(data = in_sf) +
   geom_sf(aes(fill = pop_in_cap)) +
   geom_sf(data = label_frame, size = 6, shape = 23, fill = &quot;darkred&quot;) +
   coord_sf(crs=this_crs)
australia
```

![Tranforming our coords](./proj_weird_diamond.png)

Again we create the dataframe and convert it to the correct geometry object - as above.
Then we plot. I am using city co-ords to make red diamonds on the map.
We can pass it through like normal, no need to transform explicitly. `coord_sf` applies to the whole figure.

## So what happens if we do it wrong?

`crs` is required for `st_as_sf`, it will not work otherwise but let&apos;s say we give the correct lat long but give a weird `crs`.

```r
this_crs = &quot;+init=epsg:3577 +proj=ortho +ellps=GRS80
+datum=GGRS87&quot;

label_frame &lt;- data.frame(&quot;Label&quot; = c(&quot;Brisbane&quot;, &quot;Perth&quot;), &quot;Lat&quot; = c(-27.4705, -31.9523), &quot;Lon&quot; = c(153.0260, 115.8613))

label_frame &lt;- st_as_sf(x=label_frame, coords = c(&quot;Lon&quot;, &quot;Lat&quot;), crs = this_crs)

australia &lt;-  ggplot(data = in_sf) +
    geom_sf(aes(fill = pop_in_cap)) +
    geom_sf(data = label_frame, size = 6, shape = 23, fill = &quot;darkred&quot;) +
    coord_sf(crs=this_crs)
australia
```

![Broken points](./au_bad_diamond.png)

Oops. Let&apos;s try this again, without the tranformation step and feeding it to geom_label_repel (exactly like we did in the map at the start).

```r
this_crs = &quot;+init=epsg:3577 +proj=ortho +ellps=GRS80
+datum=GGRS87&quot;

label_frame &lt;- data.frame(&quot;Label&quot; = c(&quot;Brisbane&quot;, &quot;Perth&quot;), &quot;Lat&quot; = c(-27.4705, -31.9523), &quot;Lon&quot; = c(153.0260, 115.8613))

australia &lt;-  ggplot(data = in_sf) +
    geom_sf(aes(fill = pop_in_cap)) +
      geom_label_repel(data = label_frame,
                   aes(x=Lon,y = Lat, label = Label),
                   size = 3, force = 5, force_pull = 5) +
    coord_sf(crs=this_crs)
australia

# The labels repel, but the placement is broken.
```

![Labels are broken](./au_bad_label.png)

A lot tutorials do not explain the transformation properly. They usually create their data from some other library or resource that has all the correct information baked in, so they often import the map, the data, make the plot and then apply the projection transform to the plot i.e. with `coord_sf` and everything works fine.

Let&apos;s do one example where the labels are correct.

```r
this_crs = &quot;+init=epsg:3577 +proj=ortho +ellps=GRS80
+datum=GGRS87&quot;

label_frame &lt;- data.frame(&quot;Label&quot; = c(&quot;Brisbane&quot;, &quot;Perth&quot;), &quot;Lat&quot; = c(-27.4705, -31.9523), &quot;Lon&quot; = c(153.0260, 115.8613))
label_frame &lt;- st_as_sf(x=label_frame, coords = c(&quot;Lon&quot;, &quot;Lat&quot;), crs = &quot;EPSG:4326&quot;)


australia &lt;-  ggplot(data = in_sf) +
    geom_sf(aes(fill = pop_in_cap)) +
    geom_sf_label(data = label_frame, aes(label = Label)) +
    coord_sf(crs=this_crs)
australia
```

![Labels are fixed](./au_good_label.png)

# Adding repl labels

`geom_sf_label` in the example above can be tranformed by `coord_sf`, which is why the labels show up in the correct place. But the labels will not automatically adjust themselves if your figure has many crowded labels. That&apos;s why I used `geom_label_repel` at the start - but `geom_label_repel` cant be transformed by `coord_sf`!

So how can we have both the automcatic label adjustment and the projection correction
(without having to calculate all the positioning ourselves)? We have to use something else:
`geom_sf_label_repel` that will give us both features.

The geom_sf_label_repel is in a separate library. Install using `devtools::install_github(&quot;yutannihilation/ggsflabel&quot;)`

```r
library(ggsflabel)

# The geom_sf_label_repel is in a seperate library
# install using
# devtools::install_github(&quot;yutannihilation/ggsflabel&quot;)

australia &lt;-  ggplot(data = in_sf) +
    geom_sf(aes(fill = pop_in_cap)) +
    geom_sf(data = label_frame, size = 4, shape = 23, fill = &quot;darkred&quot;) +
    geom_sf_label_repel(
        data = label_frame,
        aes(geometry = geometry, label = Label),
        size = 6, force = 5, force_pull = 5) +
    coord_sf(crs=this_crs)
australia
```

![Au map with repl labels](./au_map_repl_labels.png)
</content>
  </entry>
  <entry>
    <title>How to make a map in R</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/making-a-map-in-r"/>
    <id>https://happykhan.com/posts/making-a-map-in-r</id>
    <published>2022-05-15T00:00:00.000Z</published>
    <updated>2022-05-15T00:00:00.000Z</updated>
    <summary type="text">I recently made a map in R showing our SARS-CoV-2 collaborations. I thought
that it came out really well and maybe other people might want to make a map
(about anything). Here I will show you how to make a map in R that shows which
countries have a monarchy, as a simple illustrative example.</summary>
    <content type="html">
I recently made a map in R showing our SARS-CoV-2 collaborations. I thought
that it came out really well and maybe other people might want to make a map
(about anything). Here I will show you how to make a map in R that shows which
countries have a monarchy, as a simple illustrative example.

Here is what the final map looked like:

![The output map](./sc2map.png)

**Requirements:**

- `R`
- `ggplot2`
- `sf`
- `dplyr`
- `ggrepel`
- `cowplot`
- `maps`

I had some difficulties installying `cowplot` and `sf` natively on my laptop,
I only found it possible by installing `R` and the packages in a `conda` environment.
I explain [how to do this, here](/posts/conda-install-r).

This post is part of a series about making maps in R:

- [Making a map in R](/posts/making-a-map-in-r)
- [Advanced map making in R](/posts/advanced-map-making-in-r)
- [Variations on map projections in R](/posts/map-projections-in-r)

The Full `R` script is here:

```r file=map.R
library(ggplot2)
library(sf)
# install sf via conda, esp. if you have installed R through conda.
library(dplyr)
library(ggrepel)
library(cowplot)
require(maps)

# Resize the final preview figure.
options(repr.plot.width=15, repr.plot.height=10)

# Countries with a Monarchy. A list from the internet.
my_countries &lt;- c( &quot;Andorra&quot;, &quot;Antigua&quot;, &quot;Australia&quot;,  &quot;Bahamas&quot;, &quot;Bahrain&quot;, &quot;Belgium&quot;,
&quot;Belize&quot;, &quot;Bhutan&quot;, &quot;Cambodia&quot;,  &quot;Canada&quot;, &quot;Denmark&quot;, &quot;Swaziland&quot;,
&quot;Grenada&quot;, &quot;Jamaica&quot;, &quot;Japan&quot;, &quot;Jordan&quot;, &quot;Kuwait&quot;, &quot;Lesotho&quot;, &quot;Liechtenstein&quot;,
&quot;Luxembourg&quot;,  &quot;Malaysia&quot;, &quot;Monaco&quot;, &quot;Morocco&quot;, &quot;Netherlands&quot;,
&quot;New Zealand&quot;, &quot;Norway&quot;, &quot;Oman&quot;, &quot;Papua New Guinea&quot;, &quot;Qatar&quot;, &quot;Saint Kitts&quot;,
&quot;Saint Lucia&quot;, &quot;Saint Vincent&quot;, &quot;Saudi Arabia&quot;, &quot;Solomon Islands&quot;,
&quot;Spain&quot;, &quot;Sweden&quot;, &quot;Thailand&quot;, &quot;Tonga&quot;, &quot;Tuvalu&quot;, &quot;United Arab Emirates&quot;, &quot;UK&quot;,
&quot;Vatican City&quot;)

# Retrieve the map data
country.maps &lt;- map_data(&quot;world&quot;)

# Mutation to indicate which countries to highlight
country.maps &lt;- mutate(country.maps ,
    Monarch = ifelse(region %in% my_countries,
        &quot;Countries with a Monarch&quot;, NA))

# This is to position the region name labels
country.maps.labels &lt;- country.maps %&gt;%
   group_by(region) %&gt;%
   filter(region %in% my_countries) %&gt;%
   summarise(long = mean(long), lat = mean(lat))

# Now to plot
p &lt;- ggplot(country.maps, aes(x = long, y =lat)) +
  ggtitle(&quot;Countries with a Monarch&quot;) +
  # We fill according to the value in the Monarch field. See mutation above,
  # Differnt values in the Monarch field (e.g. the Monarch&apos;s name) would give
  # different colour coding
  geom_polygon(aes( group = group, fill = Monarch)) +
  # geom_label_repel to automatically spread out the labels
  geom_label_repel(data = country.maps.labels, aes(x = long, y = lat, label = region),
                  nudge_x = .1, nudge_y = 0.1,
                  point.padding = unit(0.1, &quot;lines&quot;),
                  size = 6,
                  force_pull = 5,
                  segment.alpha = 0.3,
                  min.segment.length = 0.5,
                  alpha = 0.7, show.legend = F,
                  box.padding = 0.5,
                  segment.curvature = -0.01,
                  segment.ncp = 1,
                  segment.angle = 30,
                  max.overlaps = 50,
                  force = 5) +
  scale_fill_viridis_d(na.value=&apos;grey70&apos;, alpha = .9) +
  theme_minimal_grid() +
  theme(legend.position = &quot;bottom&quot;,
    # Remove all the axis around the edges
       axis.title.y=element_blank(),
       axis.ticks.y=element_blank(),
       axis.text.y=element_blank(),
       axis.ticks.x=element_blank(),
       axis.text.x=element_blank(),
       axis.title.x=element_blank()) +
      theme(panel.background = element_rect(fill = &quot;aliceblue&quot;))
      # Colour the background/ocean
p
```

You may want zoom in on a certain part of the world. You can do so by giving specific latitudes and longitudes
to `coord_sf`. The example below takes our previous map and clips out Antarctica and New Zealand.
Because it is not a real map if it does not clip out New Zealand.

```r
 # coord_sf specifies the lat/long boundaries to zoom in.
 # Value are picked manually looking at google maps.
p &lt;- p +     coord_sf(ylim = c(70, -60), xlim = c(-125 , 160), expand = FALSE)

p
```

![Map of monarchy no kiwis](./sc2map-no-kiwi.png)

BTW, as a final reminder; You can save the output with `ggsave`

```r
ggsave(p, filename = &quot;map.png&quot;,  width = 15, height = 5)
ggsave(p, filename = &quot;map.svg&quot;,  width = 15, height = 5)
```

If you want to play around with the map projection, use `coord_map` like below.
To do this, you may need to install `r-mapproj` as well.

```r
if (require(&quot;maps&quot;)) {
newmap &lt;- ggplot(country.maps, aes(x = long, y =lat)) +
  geom_polygon(aes( group = group, fill = Monarch)) +
    coord_map(&quot;orthographic&quot;) +

      scale_fill_viridis_d(na.value=&apos;grey70&apos;, alpha = .9) +
  theme_minimal_grid()
newmap
}
```

![Map of monarchy curved](./sc2map-curved.png)
</content>
  </entry>
  <entry>
    <title>What is Mamba</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/what-is-mamba"/>
    <id>https://happykhan.com/posts/what-is-mamba</id>
    <published>2022-04-10T00:00:00.000Z</published>
    <updated>2022-04-10T00:00:00.000Z</updated>
    <summary type="text">If you use conda, you should use mamba. What is mamba then? The website describes it as:</summary>
    <content type="html">
If you use `conda`, you should use `mamba`. What is `mamba` then? The website describes it as:

&gt; A Python-based CLI conceived as a drop-in replacement for conda, offering higher speed and more reliable environment solutions

So you install `mamba` into your `conda` environment and for certain commands where you would
use `conda` you use `mamba` instead. The parameters are effectively the same.

So when you want to **Create an enviroment:**

```bash
conda create  -n myenv -c bioconda samtools
# becomes
mamba create -n myenv  -c bioconda  samtools
```

**Install software:**

```bash
conda install bqplot
# becomes
mamba install bqplot
```

**Remove software:**

```bash
conda remove bqplot
# becomes
mamba remove bqplot
```

As you can see, it&apos;s pretty much substitute `conda` for `mamba`. The outcome is
exactly the same, except the install time is **much** faster.

I usually keep seperate enviroments for each project, so I first create the
enviroment with `conda` with `mamba` installed and then I switch to using mamba
like the examples above. e.g.

```bash
conda create  -n myenv mamba
conda activate myenv
mamba install prokka
```
</content>
  </entry>
  <entry>
    <title>How to install (with Conda) jupyter, R and R packages</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/conda-install-r"/>
    <id>https://happykhan.com/posts/conda-install-r</id>
    <published>2022-03-25T00:00:00.000Z</published>
    <updated>2022-03-25T00:00:00.000Z</updated>
    <summary type="text">Installing and controlling R and jupyter notebooks through conda is a much easier than installing it natively.
I give a full explanation at the end as to why I do this way, but here&apos;s the method to start with.</summary>
    <content type="html">
Installing and controlling R and jupyter notebooks through conda is a much easier than installing it natively.
I give a full explanation at the end as to why I do this way, but here&apos;s the method to start with.

You can naturally change the name of the conda env (I used `mapdemo` here) to anything you like. I use
`mamba` here to speed up the install process. I highly recommend `mamba`! I explain `mamba` in [more detail here](/posts/what-is-mamba).

The first `mamba install` line is to install `jupyter notebook`, the second is for R, the R kernel for jupyter and
common R packages `dplyr` and `ggplot`. The third `mamba install` line is for more specific R packages I want to use,
these are not required for the ggplot example below, but I have included them here just to give you an idea.
I use these packages in the post about [making maps with R](/posts/making-a-map-in-r).

Requirements:

- [Conda](https://docs.conda.io/projects/conda/en/latest/index.html)

```bash
conda create -n mapdemo mamba
conda activate mapdemo
mamba install -y -c conda-forge pip notebook  nb_conda_kernels  jupyter_contrib_nbextensions
mamba install -y -c conda-forge r r-irkernel r-ggplot2 r-dplyr
mamba install -y -c conda-forge r-sf  r-ggrepel  r-cowplot r-maps
```

# Starting the notebook

Once these are all installed you can start the `jupyter notebook` from a diretory of your choosing. Here I just
make a demo directory

```bash
mkdir demo
jupyter notebook
```

You will then see the jupyter service start up and it will tell you where you can access it i.e. `http://localhost:8888/`

```bash
(mapdemo) ubuntu@chomp:~/code/demo$ jupyter notebook
[I 10:36:03.954 NotebookApp] [nb_conda_kernels] enabled, 8 kernels found
[I 10:36:04.186 NotebookApp] [jupyter_nbextensions_configurator] enabled 0.4.1
[I 10:36:04.188 NotebookApp] Serving notebooks from local directory: /home/ubuntu/code/demo
[I 10:36:04.188 NotebookApp] Jupyter Notebook 6.4.11 is running at:
[I 10:36:04.188 NotebookApp] http://localhost:8888/
[I 10:36:04.188 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
```

If everything is working you will see the dashboard like below.

![Your fresh jupyter notebook session](./new_notebook.png)

The _key thing to remember is to start your notebooks with the right kernel_. In this case we want to R kernel from the
conda environment we created - `mapdemo`.

![Creating a new kernel](./new_kernel.png)

# A quick example plot

You can write your R code as normal. Below is a simple example using ggplot.

```r file=demo_plot.R
library(ggplot2)

df &lt;- data.frame(condition=c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;),
                value=c(42, 30, 15))

p&lt;-ggplot(data=df, aes(x=condition, y=value)) +
  geom_bar(stat=&quot;identity&quot;)
p

```

![Basic plot output](./ggplot_demo.png)

# Why do I do it this way?

People who regularly use R will say that what I have described is too complicated. They
will say:

&gt; This is very complicated, I never had a problem installing anything in R (natively).

They will also say:

&gt; If the problem is around keep seperate versions of R and R packages for different projects
&gt; why not use renv? https://rstudio.github.io/renv/index.html

Or even:

&gt; jupyter sucks, use Rstudio

I am not a regular R user, and I do not like the language. But I cannot deny that the figures
it can generate are fantastic and I use it regularly for that purpose. I mainly use python,
and `jupyter notebooks` are a comfortable way to do interactive data analysis. By installing
the `R kernel` to `jupyter` I can use the same environment to do things in R. Installing
the r-kernel and R itself usually is not too difficult, but I have always had problems installing
more niche R packages. So this method described here, allows me, a non-R person to get all the R
goodness without too much hassle.

My overall bioinformatics analysis &quot;stack&quot; looks like:

- Nextflow for running heavy computation
- Python for munging the raw results
- R for final figures.

The **NPR** stack. All of these packages are easy to manage in a single conda environment. With one
environment for each project.
</content>
  </entry>
  <entry>
    <title>Easy resources researchers can use to promote a better online presence</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/digital-platforms-for-reseacher"/>
    <id>https://happykhan.com/posts/digital-platforms-for-reseacher</id>
    <published>2022-02-13T00:00:00.000Z</published>
    <updated>2022-02-13T00:00:00.000Z</updated>
    <summary type="text">Building an online presence can sound all very daunting, and you may think this means that you need to write a website, and start blogging, do social media, and spend lots of time on your digital persona. You do not. As scientists, we are lucky that there are a number of existing platforms that help us present the information I described (in the last post) as part of a digital introduction. I will outline the resources I feel are the most useful. They might require some effort to set-up but once</summary>
    <content type="html">
Building an online presence can sound all very daunting, and you may think this means that you need to write a website, and start blogging, do social media, and spend lots of time on your digital persona. You do not. As scientists, we are lucky that there are a number of existing platforms that help us present the information I described ([in the last post](/posts/better-online-presence-for-researchers)) as part of a digital introduction. I will outline the resources I feel are the most useful. They might require some effort to set-up but once created they are painless to maintain. All services are free.

The platforms, at a glance, are:

- [Your organization’s website](https://quadram.ac.uk/people/nabil-fareed-alikhan/)
- [Google scholar](https://scholar.google.com/citations?user=BpzrleYAAAAJ&amp;hl=en)
- [ORCiD.org](https://orcid.org/0000-0002-1243-0767)
- [Twitter](https://twitter.com/happy_khan)
- [Publons.com](https://publons.com/researcher/1737725/nabil-fareed-alikhan/)
- [Personal website](https://happykhan.com)

## Your organization’s website

This is the best place to give a general introduction. Most research organizations have a website where they automatically generate a “staff page” about you. The information here is considered reputable by any person reading them because the information is backed by a large organisation. For that reason, you will find that these pages tend to be the first result on search engines. The problem is that because these are automatically generated they are usually quite sparse, with only your name, position and email listed. You should expand this information with a short biography about yourself, your research interests, a professional picture and a contact method. You can usually have links to other websites like your social media accounts, portfolio of your publications and so on. Your organization has spent a lot of time developing the website and building their “brand”, why not leverage this for yourself?

These pages, however, can be tricky to modify. You as a staff or student probably do not have the power to just change the content and often you will need to send the desired text to someone for it to be updated. On the other hand, you don’t have to worry about formatting the website yourself.

## Google scholar

If you have at least one publication or preprint, Google Scholar is your next port of call. It provides a clean and sleek website with a list of all your publications with links to all the sources. It also includes useful options like exporting citations. You can also make minor corrections, like merging identical publications and preprints into one entry. The signup is very easy and you do not have to add publications to it yourself as it crawls all the information from elsewhere. I have noticed that when people create a Google Scholar profile, their profile will rank highly in the Google search results. Having a Google Scholar profile is not an annoyance and the service rarely emails me. I often use someone’s Google Scholar profile to understand what they work on just by skimming the abstracts and titles.

## ORCiD.org

ORCiD.org is an online service that provides a unique identifier for authors of scientific articles. This helps detangle issues where author’s names are not unique. It is similar to Google scholar as it catalogues all your publications but you can add extra information like your education, work history, awards/funding, and peer review contributions. It works like a short CV, and it is useful to link to in your staff profile as I mentioned above or in your email signature. Like Google Scholar it automatically updates your publication history so it is not difficult to keep up to date.

Most journals allow you to specify an ORCiD when you submit a manuscript to them, and they provide a link to the ORCiD profile on the website for the paper. This allows people to see you as an author and click through to your portfolio. Some publishing groups have made providing ORCiD a mandatory part of their submission process.

## Twitter

In my field of microbial bioinformatics, twitter is the social media of choice. Tweets from users are usually public so this allows conversations between researchers who may not have an opportunity to interact elsewhere. You can have people with a shared interest come together with minimal effort, like using a hashtag for a conference. You can promote research and ideas, job opportunities, and memes as you like. It is not widely adopted across all scientific fields, so check with colleagues if they use Twitter.

## Publons.com

Publons fills out the trifecta of online portfolios. Again, this catalogues your publications like Google Scholar and ORCiD but this provides two major benefits that the other two do not. Firstly, this site is linked to Web of Science, a database of scientific literature and analytics. The people behind Web of Science are the ones who calculate a journal’s Impact Factor. Having this account allows you to make minor changes to your publication record, like if you’ve published under slightly different names and want to link them all together. The second benefit is that you can input your peer-review activities here. If you link your ORCiD here, then this information will be synchronized across both sites.

## Personal website

These are websites entirely maintained by yourself. These days they seem to get ranked poorly on search engines and require significant effort to create and maintain. This is the last thing to consider after you’re comfortable with the resources above. Here you can put any content you like and the presentation will depend on how you want to present yourself. I will leave that to you. If you are looking for a platform to use, Wordpress is probably the easiest to get started. I suggest the section below on what to do if you have no publications if you are looking for ideas for content beyond an online CV.

## What to do if you have no publications

Publications are our main currency in research. It is a good way to show your interests and what you are capable of doing, aside from communicating scientific knowledge. I admit that most of my suggestions so far expect you to have some publications to show, but there are still options for you even if you do not have any publications (yet).

You can publish your slides from presentations or posters online via services like figshare. Or you can create some blog content about something you are working on. It can be something non controversial like talking about a particular method. If you have an interesting protocol you’ve created, you can publish it on protocols.io. Protocols.io submissions are indexed on your ORCiD. If you’ve written a programming script, you can put it up on github or similar. Perhaps your project is sensitive and you can’t actually talk about it at all. In that case, you may want to try writing short reviews of publications you’ve read.

What is important here is to create something visible so people can see what you are all about. I would be careful not to release anything blantly wrong but it doesn’t have to be perfect.

These options can be linked on the “staff profile” or on a personal website. In anything I’ve suggested, you should check with your supervisor or organisation if they are happy with you releasing it online.

If you want to hear more about this with different points of view, we talk about this on the [microbinfie podcast in episode 66 - scholarly communications for bioinformaticians ](https://soundcloud.com/microbinfie/66-scholarly-communications-for-bioinformaticians?utm_source=clipboard&amp;utm_medium=text&amp;utm_campaign=social_sharing)
</content>
  </entry>
  <entry>
    <title>Promoting a better online presence for researchers</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/better-online-presence-for-researchers"/>
    <id>https://happykhan.com/posts/better-online-presence-for-researchers</id>
    <published>2022-02-02T00:00:00.000Z</published>
    <updated>2022-02-02T00:00:00.000Z</updated>
    <summary type="text">Over the years I have attended a number of seminars and courses that talk about online marketing, networking and personal branding. I have so far found that although these methods are effective, they are based on a presumption - There is an ultimate transaction that occurs between you and your audience/client/customer. This can be to buy something, refer us to someone else, endorse us, love us, “like-comment-subscribe.” This is at odds with how scientists interact.</summary>
    <content type="html">
Over the years I have attended a number of seminars and courses that talk about online marketing, networking and personal branding. I have so far found that although these methods are effective, they are based on a presumption - There is an ultimate transaction that occurs between you and your audience/client/customer. This can be to buy something, refer us to someone else, endorse us, love us, “like-comment-subscribe.” This is at odds with how scientists interact.

We in the research community only occasionally court our peers. We are usually employed full time on a project already, and do not have time to work on many extra projects. We work in large organisations with people in a similar field of study so we should have access to potential collaborators. We can meet like-minded people through scientific conferences. Our organisations try to actively publicise the work we do. In essence our immediate marketing requirements should already be covered by these more traditional resources. Outside of that, we are not really trying to “sell” anything. Our bread and butter is not encouraging people to constantly interact with us. This makes some of the canonical advice for developing visibility online seem extreme, even obnoxious. As a scientist, what is the value of promoting yourself online? It seems like a lot of work for very little gain.

## The value of being visible online

I believe there is scope in an “Online presence” for every researcher no matter what career stage they are in but the priorities are not the same as a standard digital marketing campaign. Here is my general guidance on what one should try to achieve and some practical advice on how to achieve it.

People do look for you online! Whether you are a professor or a PhD student. Certainly if you have publications/presentations/posters then people interested in that work will look for more information about what you do. But we as scientists are special, we are presented both as an individual and as a part of a collective. People might find you through association as well, like through your lab group or institution website. In any of these cases, people’s motivation is to find out more about you professionally. What have you worked on? What can you do? When people do look for you, they will make one or two attempts but they will not go to the ends of the Earth to reach you. If the information is not forthcoming, they will likely move onto someone else.

## Provide the minimal information

Our first step, therefore, in building an “Online presence” is to have the minimal information about ourselves readily available when people look. As an aside, having this information organised is also helpful for you when you need to fill in applications for funding or positions. Providing this information is not boasting, it is a statement of fact. It is giving information to someone who requests it. Think of it as a digital introduction. The way you introduce yourself in person is the same kind of information you want to convey when someone searches for you online. If I have a short conversation with someone at a conference, I may ask about things like: Their current institution, their major research interests, their former institutions, where they did their PhD, what they are technically good at, some way to contact them (email, twitter, etc.), and I might later look for an easy list of their publications/posters/presentations. All this helps me understand who they are professionally. Maybe in learning all of that we find that we actually do not have very much in common and that’s fine. I will remember you regardless.

## How people search for you

As a final point, I will talk about how people actually perform their online searches. Consider; how do you find out more about a researcher you only know OF? What steps do you take? Try that on yourself and see the results. Are you happy with the way you are presented? Does it represent you honestly and effectively?

Working from my experience, I become aware of someone through one of the more established discovery methods - list of speakers at a conference, a CV of someone applying for a job with my institute, a poster posted online, an author on a publication I like. This is the starting point, stage 1, I see the name and I likely see the affiliation. I do not do an online search for “Experts in microbial genomics looking to collaborate”.

So I see this name, I copy it into a search engine, and look at the first six or so results. If this person has a common name, or a name that collides with someone famous, I may not see what I want so I will try to refine it with some extra keywords like the institution or the field of study. So in my case someone might try “nabil alikhan”, “nabil alikhan salmonella”, “nabil alikhan QIB” for instance. This is stage 2. What do your search results look like for you? Aside from websites, what images, videos or news articles are associated with these results? The third step is usually I would click on one of these top six sites and quickly skim what I see. What do you see for yourself?

It’s worth noting that my intent will dictate the information that I am looking for. If I am operating as a recruiter for a job I want to know if they meet the requirements for the role I am recruiting for. If I saw this person presenting a talk, I might be looking for more details of their methods in a particular publication of theirs. There are many more complicated scenarios, but I maintain that being able to understand you better will encourage me to approach you for collaboration, job offers, funding allocations or anything else.

In the [next post](/posts/digital-platforms-for-reseacher) I will discuss the platforms best suited to researchers, particularly those that are easy to setup and maintain.

If you want to hear more about this with different points of view, we talk about this on the [microbinfie podcast in episode 66 - scholarly communications for bioinformaticians ](https://soundcloud.com/microbinfie/66-scholarly-communications-for-bioinformaticians?utm_source=clipboard&amp;utm_medium=text&amp;utm_campaign=social_sharing)
</content>
  </entry>
  <entry>
    <title>Dirty python script to merge fasta files</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/fasta-quick-cat"/>
    <id>https://happykhan.com/posts/fasta-quick-cat</id>
    <published>2021-07-24T00:00:00.000Z</published>
    <updated>2021-07-24T00:00:00.000Z</updated>
    <summary type="text">Here is a Dirty python script to look in a directory, find fasta files (ext. &quot;.fa&quot;), and modify the header and merge them into a single fasta file.
This will only look one directory down. It is not recursive. It won&apos;t even check if the directory records are directories, so it is pretty fragile.</summary>
    <content type="html">
## Motivation &amp; Requirements

Here is a Dirty python script to look in a directory, find fasta files (ext. &quot;.fa&quot;), and modify the header and merge them into a single fasta file.
This will only look one directory down. It is not recursive. It won&apos;t even check if the directory records are directories, so it is pretty fragile.

I wrote this in a HURRY.

**Requires:**

- Python 3.7
- Biopython module

## Code

```python file=fasta_merge.py
import os
from Bio import SeqIO, Seq

input_dir = &quot;/home/ubuntu/output_dir&quot;

all_fasta = []
for dir_name in os.listdir(input_dir):
    if dir_name.startswith(&apos;EBRE&apos;):
        output_dir = os.path.join(input_dir, dir_name)
        fasta_consensus = [os.path.join(output_dir, y)
            for y in os.listdir(output_dir) if y.endswith(&apos;.fa&apos;)]
        if len(fasta_consensus) == 1:
            rec = SeqIO.parse(open(fasta_consensus[0]), &apos;fasta&apos;)
            for fas in rec:
                fas.id = fas.id.split(&apos;_&apos;)[1]
                fas.decription = &apos;&apos;
                all_fasta.append(fas)

with open(&quot;merged_output.fasta&quot;, &quot;w&quot;) as output_handle:
    SeqIO.write(all_fasta, output_handle, &quot;fasta&quot;)
```
</content>
  </entry>
  <entry>
    <title>How zip up a folder of loose FASTQ files</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/zip-on-hpc"/>
    <id>https://happykhan.com/posts/zip-on-hpc</id>
    <published>2020-07-16T00:00:00.000Z</published>
    <updated>2020-07-16T00:00:00.000Z</updated>
    <summary type="text">The problem is to find all fastq files, and submit each one, one by one as a job to be gzipped.</summary>
    <content type="html">
The problem is to find all fastq files, and submit each one, one by one as a job to be gzipped.

### Local machine

```bash
ls *.fastq | xargs -I {} gzip {}
```

**Multicore version**

You will need to have `pigz` installed.

```bash
ls *.fastq | xargs -I {} pigz {}
```

### Compute cluster - HPC

This really applies if you are working on a computing cluster (SLURM).

```bash
ls *.fastq | xargs -I {} sbatch --wrap=&quot;gzip {}&quot;
```

**Multicore version**

You will need to have `pigz` installed.

```bash
ls *.fastq | xargs -I {} sbatch --wrap=&quot;pigz {}&quot;
```
</content>
  </entry>
  <entry>
    <title>How to fix Singularity build has run out of space</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/build-no-space"/>
    <id>https://happykhan.com/posts/build-no-space</id>
    <published>2019-10-23T00:00:00.000Z</published>
    <updated>2019-10-23T00:00:00.000Z</updated>
    <summary type="text">You see an error message like this:</summary>
    <content type="html">
You see an error message like this:

```bash
[alikhan@NBI-HPC bactdating]$ sudo singularity build  bactdating.sif bactdating.def
Using container recipe deffile: bactdating.def
Sanitizing environment
Adding base Singularity environment to container
Docker image path: index.docker.io/rocker/tidyverse:latest
Cache folder set to /root/.singularity/docker
[1/3] ||----------------------------------|   0.0% ERROR Error writing to /root/.singularity/docker/sha256:a1023bc917615cdb255c64fadbb2d8f78e8b0340fc6c11a8ea25e1020c475feb.tar.gz.LyNsUD.V1prNL: [Errno 28] No space left on device exiting
ERROR Error writing to /root/.singularity/docker/sha256:0c48f908dc6318e7ca082c5718e4fea9ef8c49809242b823587f452f73956b3e.tar.gz.D3S0er.Y8nPFj: [Errno 28] No space left on device exiting
ERROR Error writing to /root/.singularity/docker/sha256:a5729b5b4853988e207a18047cf059f520eea2a08a91d3bbcfc21554a5f98f0b.tar.gz.T88Q_a.UMjpkX: [Errno 28] No space left on device exiting
```

This tells you there is **not enough space for Singularity to build your container**.

### What can you do?

You can disable the Singularity cache, or get it to write somewhere else. There are two variables to play with:

- `SINGULARITY_DISABLE_CACHE` If you want to disable the cache, this means is that
  the layers are written to a temporary directory. Thus, if you want to disable cache
  and write to a temporary folder, simply set `SINGULARITY_DISABLE_CACHE` to any
  true/yes value. By default, the cache is not disabled.
- `SINGULARITY_CACHEDIR` Is the base folder for caching layers and singularity
  hub images. If not defined, it uses default of $HOME/.singularity. If defined,
  the defined location is used instead.

Either of these could help avoid writing docker layers to `/root/.singularity/docker`.
</content>
  </entry>
  <entry>
    <title>Timed phylogenies with BactDating</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/timed-phylo-with-bactdating"/>
    <id>https://happykhan.com/posts/timed-phylo-with-bactdating</id>
    <published>2019-08-16T00:00:00.000Z</published>
    <updated>2019-08-16T00:00:00.000Z</updated>
    <summary type="text">You want to calculate the time to most recent common ancestor (tMRCA) and dates for internal splits for a given phylogeny.
BactDating is an R package available at: https://github.com/xavierdidelot/BactDating</summary>
    <content type="html">
You want to calculate the time to most recent common ancestor (tMRCA) and dates for internal splits for a given phylogeny.
BactDating is an R package available at: https://github.com/xavierdidelot/BactDating

### The basics

This example assumes you&apos;ve removed recombination using ClonalFrameML. The output from ClonalFrameML is imported into Bactdating with the command `loadCFML`.
BactDating will generate a number of plots:

- **trace**: Will show the parameters for each iteration, these should look like they&apos;re converging (stabilizing). Otherwise increase number of iterations (nbIts)
- **treeroot**: Will plot the tree, and estimate which branch is the root.
- **TreeCI**: Timed phylogeny with confidence intervals.
- **t**: Just the tree itself - no funny business.

```r
&gt; library(BactDating)
&gt; library(ape)
&gt; set.seed(0)
&gt; t=loadCFML(&apos;/mnt/clonal/clonal&apos;)
&gt; meta &lt;- read.csv(file=&apos;/mnt/clonal/years&apos;, sep=&apos;\t&apos;)
&gt; res = bactdate(t, meta$Year, useRec = T, nbIts=1e5)
&gt; plot(res,&apos;trace&apos;)
&gt; plot(res,&apos;treeRoot&apos;,show.tip.label=F)
&gt; plot(res,&apos;treeCI&apos;)
&gt; plot(t)
```

The timed phylogeny will look like this, where the blue bars indicate the 95% confidence interval:

![timed phylogeny](./bact_1.png &quot;timed phylogeny&quot;)

### Has it converged?

You can tell looking at the `plot( res, &apos;trace&apos;)` output. You are looking for cases where the parameters have a similar mean and variance.

**NO**

![timed phylogeny](./bact_2.png &quot;timed phylogeny&quot;)

**YES**

![timed phylogeny](./bact_3.png &quot;timed phylogeny&quot;)

### Root to tip

Plots the root to tip. This won&apos;t adjust for any recombination (unlike bactdate &gt; res result above). You want to see an even spread of points within the dotted lines.

```r
&gt; root_t = initRoot(t, meta$Year)
&gt; roottotip(root_t, meta$Year)
```

![timed phylogeny](./bact_4.png &quot;timed phylogeny&quot;)

### Is the clock signal significant?

One way to test this is to repeat the analysis but give every node the same date or giving a random set of dates (the aim is to feed the program nonsense). The results generated by the real dating should be clearly better than results generated with the nonsense dating.

The sample below shows you how to set every tip to have the same date and compare the results via the Deviance information criterion (DIC). This measures the simplicity of the model and how well it fits the data. The lower the DIC the better. It is a quantitative way to see if your result with the real dates is really significant.

```r
&gt; res2 = bactdate(t, rep(2015, length(meta$Year)), useRec = T, nbIts=1e4)
&gt; modelcompare(res,res2)
The first model has DIC=819.48 and the second model has DIC=1186.85.
Model 1 is definitely better.
```

Because the DIC is taking into account model complexity, it is important to make sure that both the random nonsense result and the real result have actually converged.

Further tests of convergence
For further testing of convergence, you can export the BactDating result to the format required by the `coda` package using the command:

```r
mcmc=as.mcmc(res)
```

You can then compute for example the effective sample size of the parameters using:

```r
&gt;effectiveSize(mcmc)
      mu    sigma    alpha
13.81568 13.99970 82.08765  # BAD
&gt; effectiveSize(mcmc)
   mu sigma alpha
  501   501   501   # GOOD
```

The more samples the better but you should have at least 100 before you take your results seriously.
</content>
  </entry>
  <entry>
    <title>Shortest passwordless ssh tutorial</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/shortest-passwordless-ssh-tutorial"/>
    <id>https://happykhan.com/posts/shortest-passwordless-ssh-tutorial</id>
    <published>2013-08-23T00:00:00.000Z</published>
    <updated>2013-08-23T00:00:00.000Z</updated>
    <summary type="text">I&apos;ve used this thrice in three days, so I&apos;m just keeping a copy for
myself.</summary>
    <content type="html">
I&apos;ve used this thrice in three days, so I&apos;m just keeping a copy for
myself.

Sourced (i.e. blatant copy-paste) from:
&lt;http://arbib.it/tag/shortest-passwordless-ssh-tutorial/&gt;

That in turn got it from
&lt;http://blogs.translucentcode.org/mick/archives/000230.html&gt;

**Begin:**

```bash
local$ ssh-keygen -t dsa
local$ scp ~/.ssh/id_dsa.pub remote:~/
local$ ssh username@remote
remote$ cat ~/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
remote$ chmod 644 ~/.ssh/authorized_keys
remote$ exit
local$ ssh username@remote
```

Now instead of the normal password you should be asked for the password
you entered for your dsa key. This isn&apos;t passwordless yet but shows that
ssh is using the key.

Note: Leave Key password blank to have passwordless authentication

Fixes for possible problems:

```bash
chmod 0600
authorized_keys
ln -s authorized_keys2 authorized_keys (or viceversa)
```
</content>
  </entry>
  <entry>
    <title>BRIG in Action</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/brig-in-action"/>
    <id>https://happykhan.com/posts/brig-in-action</id>
    <published>2011-08-23T00:00:00.000Z</published>
    <updated>2011-08-23T00:00:00.000Z</updated>
    <summary type="text">These are some of my favourite BRIG figures from recent Open Access
publications. They are all really amazing and go far beyond what I
thought was possible with the tool. I did not make these figures; all
credit (and kudos) belong to the respective authors.</summary>
    <content type="html">
These are some of my favourite [BRIG](http://brig.sourceforge.net/) figures from recent Open Access
publications. They are all really amazing and go far beyond what I
thought was possible with the tool. I did not make these figures; all
credit (and kudos) belong to the respective authors.

![&quot;Visualization of the reads selected for each strain mapped onto the
S. pyogenes MGAS6180 reference genome. The innermost circles represent
the GC content (black), GC skew (purple/green), and rRNA operons of
MGAS6180 (pink boxes). BRIG (1) shows the distribution of the number of
reads for each individual strain mapped onto the central reference using
a window size of 500, arranged from inner to outer colored circles as
follows: resequenced reference MGAS6180 (pink), PS001 (yellow), PS006
(orange), PS005 (red), PS007 (maroon), and PS008 (purple). Additional
strain-specific regions of difference (RODs) (ϕPS008 and ICESpPS008) are
represented as insertions. The outermost circle represents previously
reported regions of difference in MGAS6180, namely, prophage elements
6180.1 and 6180.2, prophage remnants 6180.3 and 6180.4, and regions of
difference 6180.RD1 and 6180.RD2 (15)
(black).&quot;](./zjm9990917380002.jpg)

&gt; &quot;Visualization of the reads selected for each strain mapped onto the
&gt; S. pyogenes MGAS6180 reference genome. The innermost circles represent
&gt; the GC content (black), GC skew (purple/green), and rRNA operons of
&gt; MGAS6180 (pink boxes). BRIG (1) shows the distribution of the number of
&gt; reads for each individual strain mapped onto the central reference using
&gt; a window size of 500, arranged from inner to outer colored circles as
&gt; follows: resequenced reference MGAS6180 (pink), PS001 (yellow), PS006
&gt; (orange), PS005 (red), PS007 (maroon), and PS008 (purple). Additional
&gt; strain-specific regions of difference (RODs) (ϕPS008 and ICESpPS008) are
&gt; represented as insertions. The outermost circle represents previously
&gt; reported regions of difference in MGAS6180, namely, prophage elements
&gt; 6180.1 and 6180.2, prophage remnants 6180.3 and 6180.4, and regions of
&gt; difference 6180.RD1 and 6180.RD2 (15) (black).&quot;

From [Ben Zakour et al.](https://journals.asm.org/doi/10.1128/JCM.00675-12) (2012) &apos;Analysis of a Streptococcus pyogenes
Puerperal Sepsis Cluster by Use of Whole-Genome Sequencing&apos;, J. Clin.
Microbiol 50(7). doi: 10.1128/JCM.00675-12

![&quot;Distribution of CU fimbrial gene clusters among E. coli pathotypes.
The inner ring represents the concatenated nucleotide sequences of the
38 fimbrial operons. Each segment is labelled in the outer ring
according to the name and clade [3] of the corresponding fimbrial
usher type with the intervening 36 rings displaying the presence of
intact CU fimbrial gene clusters in each of the strains analysed. The
legend on the right lists the colour of each strain that we included in
our study, grouped according to pathogenicity class. Circular comparison
was generated using BLAST ring image generator (BRIG) [69]. 1CFT073
contains two copies of the P fimbriae
operon.&quot;](./pone.0052835.g004.png)

&gt; &quot;Distribution of CU fimbrial gene clusters among E. coli pathotypes.
&gt; The inner ring represents the concatenated nucleotide sequences of the
&gt; 38 fimbrial operons. Each segment is labelled in the outer ring
&gt; according to the name and clade \[3\] of the corresponding fimbrial
&gt; usher type with the intervening 36 rings displaying the presence of
&gt; intact CU fimbrial gene clusters in each of the strains analysed. The
&gt; legend on the right lists the colour of each strain that we included in
&gt; our study, grouped according to pathogenicity class. Circular comparison
&gt; was generated using BLAST ring image generator (BRIG) \[69\]. CFT073
&gt; contains two copies of the P fimbriae operon.&quot;

From [Wurpel et al.](https://doi.org/10.1371/journal.pone.0052835) (2013) &apos;Chaperone-Usher Fimbriae of Escherichia
coli.&apos;, PLoS ONE 8(1): e52835.

![&quot;BlastP comparison of the Janthinobacterium sp. HH01 genome compared
against genomes of closely related species. The innermost rings indicate
the GC content (black) and GC skew (purple/green). The outer rings
represent the genomes of the following microbes in different colorings:
Janthinobacterium sp. Marseille, blue; Janthinobacterium sp. PAMC 25724,
red; Janthinobacterium sp. GC3, green; and C. violaceum ATCC 12472,
black.&quot;](./pone.0055045.g002.png)

&gt; &quot;BlastP comparison of the Janthinobacterium sp. HH01 genome compared
&gt; against genomes of closely related species. The innermost rings indicate
&gt; the GC content (black) and GC skew (purple/green). The outer rings
&gt; represent the genomes of the following microbes in different colorings:
&gt; Janthinobacterium sp. Marseille, blue; Janthinobacterium sp. PAMC 25724,
&gt; red; Janthinobacterium sp. GC3, green; and C. violaceum ATCC 12472, black.&quot;

From [Hornung et al.](https://doi.org/10.1371/journal.pone.0055045) (2013) &apos;The _Janthinobacterium_ sp. HH01 Genome Encodes
</content>
  </entry>
  <entry>
    <title>Getting tRNAscan to work on Linux</title>
    <link rel="alternate" type="text/html" href="https://happykhan.com/posts/getting-trnascan-to-work-on-linux"/>
    <id>https://happykhan.com/posts/getting-trnascan-to-work-on-linux</id>
    <published>2011-08-21T00:00:00.000Z</published>
    <updated>2011-08-21T00:00:00.000Z</updated>
    <summary type="text">A friend/collaborator was having problems getting
tRNAscan-SE to work on his
Debian machine (I think it was Debian). We came up with a fix for it
that I&apos;d like to share.</summary>
    <content type="html">
A friend/collaborator was having problems getting
[tRNAscan-SE](http://lowelab.ucsc.edu/tRNAscan-SE/) to work on his
Debian machine (I think it was Debian). We came up with a fix for it
that I&apos;d like to share.

tRNAScan-SE predicts transfer RNA genes in a nucleotide sequence. It was
written by Todd Lowe &amp; Sean Eddy ([The
paper](http://nar.oxfordjournals.org/content/25/5/0955)) and it&apos;s very,
very good at what it does but there is a glitch with compiling it on my
Fedora 14 installation &amp; my buddy&apos;s Debian machine. This is what happens
when we try to compile it:

```bash
[nabil@tinkerbell tRNAscan-SE-1.3]$ make gcc -O -c trnascan.c gcc -O
-DTSCANDIR=/home/nabil/lib/tRNAscan-SE -o trnascan-1.4 trnascan.c gcc
-O -c align.c
.... blah blah blah blah blah....
scorestack.c: In function &apos;free_hitstack&apos;: scorestack.c:247:54:
warning: comparison between pointer and integer
gcc -O -c sqio.c sqio.c:238:1:
error: conflicting types for &apos;getline&apos; /usr/include/stdio.h:673:20:
note: previous declaration of &apos;getline&apos; was here
make: *** [sqio.o] Error 1``
```

So, apparently on some linux distros, &apos;getline&apos; function is an
environment variable and creates a conflict during tRNAscan-SE
installation. (This is basically what&apos;s written in the compile error).

**BUT to fix this problem, run this command in the tRNAscan-SE
directory**:

```bash
perl -pi -e &quot;s/getline/getline2/g&quot; sqio.c
```

This command will change all getline variables on the file sqio.c to
getline2, avoiding conflicts.

**Problem solved\!**
</content>
  </entry>
</feed>